[
["index.html", "Data Skills Overview 0.1 Course Aims 0.2 Intended Learning Outcomes 0.3 Course Outline 0.4 Formative Exercises 0.5 Packages used in this book 0.6 Resources", " Data Skills Lisa DeBruine &amp; Dale Barr 2019-07-01 Overview This course provides an overview of skills needed for reproducible research and open science using the statistical programming language R. Students will learn about data visualisation, data tidying and wrangling, archiving, iteration and functions, probability and data simulations, general linear models, and reproducible workflows. Learning is reinforced through weekly assignments that involve working with different types of data. 0.1 Course Aims This course aims to teach students the basic principles of reproducible research and to provide practical training in data processing and analysis in the statistical programming language R. 0.2 Intended Learning Outcomes By the end of this course students will be able to: Draw on a range of specialised skills and techniques to formulate a research design appropriate to various kinds of questions in psychology and neuroscience Write scripts in R to organise and transform data sets using best accepted practices Explain basics of probability and its role in statistical inference Critically analyse data and report descriptive and inferential statistics in a reproducible manner 0.3 Course Outline The overview below lists the beginner learning outcomes only. Some lessons have additional learning outcomes for intermediate or advanced students. Getting Started Understand the components of the RStudio IDE Type commands into the console Understand function syntax Install a package Organise a project Appropriately structure an R script or RMarkdown file Create and compile an Rmarkdown document Working with Data Understand the use the basic data types Understand and use the basic container types (list, vector) Create vectors and store them as variables Understand vectorized operations Create a data table Import data from CSV and Excel files Data Visualisation Understand what types of graphs are best for different types of data Create common types of graphs with ggplot2 Set custom labels Represent factorial designs with different colours or facets Save plots as an image file Tidy Data Understand the concept of tidy data Be able to use the 4 basic tidyr verbs: gather(), separate(), spread(), unite() Be able to chain functions using pipes Data Wrangling Be able to use the 6 main dplyr one-table verbs: select(), filter(), arrange(), mutate(), summarise(), group_by() Data Relations Be able to use the 4 mutating join verbs: left_join(), right_join(), inner_join(), full_join() Use the by argument to set the join columns Iteration &amp; Functions Work with iteration functions: rep(), seq(), and replicate() Use arguments by order or name Write your own custom functions with function() Set default values for the arguments in your functions Probability &amp; Simulation Understand what types of data are best modeled by different distributions: uniform, binomial, normal, poisson Generate and plot data randomly sampled from the above distributions Test sampled distributions against a null hypothesis using: exact binomial test, t-test (1-sample, independent samples, paired samples), correlation (pearson, kendall and spearman) Define the following statistical terms: p-value, alpha, power, false positive (type I error), false negative (type II error), confidence interval Introduction to GLM Prove to yourself the correspondence among two-sample t-test, one-way ANOVA, and linear regression with dummy coding Given data and a GLM, generate a decomposition matrix and calculate sums of squares, mean squares, and F ratios Reproducible Workflows Create a reproducible script in R Markdown Edit the YAML header to add table of contents and other options Include a table Include a figure Use source() to include code from an external file Report the output of an analysis using inline R 0.4 Formative Exercises Exercises are available at the end of each lesson’s webpage. These are not marked or mandatory, but if you can work through each of these (using web resources, of course), you will easily complete the marked assessments. Download all exercises and data files below as a ZIP archive. 01 intro: Intro to R, functions, R markdown 02 data: Vectors, tabular data, data import, pipes Essential Skills: You must be able to complete these exercises to advance in the class beyond the first two lectures 03 ggplot: Data visualisation 04 tidyr: Tidy Data 05 dplyr: Data wrangling 06 joins: Data relations 07 functions: Functions and iteration 08 simulation: Simulation 09 glm: GLM 0.5 Packages used in this book tidyverse cowsay goodshirt ukbabynames cowplot plotly MASS 0.6 Resources Miscellanous materials added throughout the semester, such tips on installation, or the results of live-coding demos, can be found in the Miscellaneous section. Glasgow Psychology RStudio Learning Statistics with R by Navarro R for Data Science by Grolemund and Wickham 0.6.1 Online tutorials swirl R for Reproducible Scientific Analysis codeschool.com datacamp Improving your statistical inferences on Coursera 0.6.2 Cheat sheets You can access several cheatsheets in RStudio under the Help menu Or get the most recent RStudio Cheat Sheets 0.6.3 Other Style guide for R programming #rstats on twitter highly recommended! "],
["intro.html", "Chapter 1 Getting Started 1.1 Learning Objectives 1.2 Resources 1.3 What is R? 1.4 Getting Started 1.5 Add-on packages 1.6 Organising a project 1.7 Exercises", " Chapter 1 Getting Started 1.1 Learning Objectives Understand the components of the RStudio IDE Type commands into the console Understand function syntax Install a package Organise a project Appropriately structure an R script or RMarkdown file Create and compile an Rmarkdown document 1.2 Resources Chapter 1: Introduction in R for Data Science RStudio IDE Cheatsheet Introduction to R Markdown R Markdown Cheatsheet R Markdown Reference 1.3 What is R? R is a programming environment for data processing and statistical analysis. We use R in Psychology at the University of Glasgow to promote reproducible research. This refers to being able to document and reproduce all of the steps between raw data and results. R allows you to write scripts that combine data files, clean data, and run analyses. There are many other ways to do this, including writing SPSS syntax files, but we find R to be a useful tool that is free, open source, and commonly used by research psychologists. See Appendix (???)(installing-r) for more information on on how to install R and associated programs. 1.3.1 The Base R Console If you open up the application called R, you will see an “R Console” window that looks something like this. Figure 1.1: The R Console window. You can close R and never open it again. We’ll be working entirely in RStudio in this class. ALWAYS REMEMBER: Launch R though the RStudio IDE 1.3.2 RStudio RStudio is an Integrated Development Environment (IDE). This is a program that serves as a text editor, file manager, and provides many functions to help you read and write R code. Figure 1.2: The RStudio IDE RStudio is arranged with four window panes. By default, the upper left pane is the source pane, where you view and edit source code from files. The bottom left pane is usually the console pane, where you can type in commands and view output messages. The right panes have several different tabs that show you information about your code. You can change the location of panes and what tabs are shown under Preferences &gt; Pane Layout. Your browser does not support the video tag. 1.3.3 Configure RStudio In this class, you will be learning how to develop reproducible scripts. This means scripts that completely and transparently perform some analysis from start to finish in a way that yields the same result for different people using the same software on different computers. Transparency is a key value of science, as embodied in the “trust but verify” motto. When you do things reproducibly, others can understand and check your work. This benefits science, but there is a selfish reason, too: the most important person who will benefit from a reproducible script is your future self. When you return to an analysis after two weeks of vacation, you will thank your earlier self for doing things in a transparent, reproducible way, as you can easily pick up right where you left off. There are two tweaks that you should do to your RStudio installation to maximize reproducibility. Go to the preferences/settings menu, and uncheck the box that says Restore .RData into workspace at startup;. If you keep things around in your workspace, things will get messy, and unexpected things will happen. You should always start with a clear workspace. This also means that you never want to save your workspace when you exit, so set this to Never. The only thing you want to save are your scripts. Figure 1.3: Alter these settings for increased reproducibility. Your settings should have: Restore .RData into workspace at startup: Checked Not Checked Save workspace to .RData on exit: Always Never Ask 1.4 Getting Started 1.4.1 Console commands We are first going to learn about how to interact with the console. In general, you will be developing R scripts or R markdown files, rather than working directly in the console window. However, you can consider the console a kind of sandbox where you can try out lines of code and adapt them until you get them to do what you want. Then you can copy them back into the script editor. Mostly, however, you will be typing into the script editor window (either into an R script or an R Markdown file) and then sending the commands to the console by placing the cursor on the line and holding down the Ctrl key while you press Enter. The Ctrl+Enter key sequence sends the command in the script to the console. One simple way to learn about the R console is to use it as a calculator. Enter the lines of code below and see if your results match. Be prepared to make lots of typos (at first) :/ 1 + 1 ## [1] 2 The R console remembers a history of the commands you typed in the past. Use the up and down arrow keys on your keyboard to scroll backwards and forwards through your history. It’s a lot faster than re-typing. 1 + 1 + 3 ## [1] 5 You can break up math expressions over multiple lines; R waits for a complete expression before processing it. ## here comes a long expression ## let&#39;s break it over multiple lines 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 ## [1] 55 Text inside quotes is called a string. &quot;Good afternoon&quot; ## [1] &quot;Good afternoon&quot; You can break up text over multiple lines; R waits for a close quote before processing it. If you want to include a double quote inside this quoted string, escape it with a backslash. africa &lt;- &quot;I hear the drums echoing tonight But she hears only whispers of some quiet conversation She&#39;s coming in, 12:30 flight The moonlit wings reflect the stars that guide me towards salvation I stopped an old man along the way Hoping to find some old forgotten words or ancient melodies He turned to me as if to say, \\&quot;Hurry boy, it&#39;s waiting there for you\\&quot; - Toto&quot; cat(africa) # cat() prints the string ## I hear the drums echoing tonight ## But she hears only whispers of some quiet conversation ## She&#39;s coming in, 12:30 flight ## The moonlit wings reflect the stars that guide me towards salvation ## I stopped an old man along the way ## Hoping to find some old forgotten words or ancient melodies ## He turned to me as if to say, &quot;Hurry boy, it&#39;s waiting there for you&quot; ## ## - Toto 1.4.2 Variables Often you want to store the result of some computation for later use. You can store it in a variable. A variable in R: contains only letters, numbers, full stops, and underscores starts with a letter or a full stop and a letter distinguishes uppercase and lowercase letters (rickastley is not the same as RickAstley) The following are valid and different variables: songdata SongData song_data song.data .song.data never_gonna_give_you_up_never_gonna_let_you_down The following are not valid variables: _song_data 1song .1song song data song-data Use the assignment operator &lt;- to assign the value on the right to the variable named on the left. ## use the assignment operator &#39;&lt;-&#39; ## R stores the number in the variable x &lt;- 5 Now that we have set x to a value, we can do something with it: x * 2 ## R evaluates the expression and stores the result in the variable boring_calculation &lt;- 2 + 2 ## [1] 10 Note that it doesn’t print the result back at you when it’s stored. To view the result, just type the variable name on a blank line. boring_calculation ## [1] 4 Once a variable is assigned a value, its value doesn’t change unless you reassign the variable, even if the variables you used to calculate it change. Predict what the code below does and test yourself: this_year &lt;- 2019 my_birth_year &lt;- 1976 my_age &lt;- this_year - my_birth_year this_year &lt;- 2020 After all the code above is run: this_year = 43 44 1976 2019 2020 my_birth_year = 43 44 1976 2019 2020 my_age = 43 44 1976 2019 2020 1.4.3 The environment Anytime you assign something to a new variable, R creates a new object in the global environment. Objects in the global environment exist until you end your session; then they disappear forever (unless you save them). Look at the Environment tab in the upper right pane. It lists all of the variables you have created. Click the broom icon to clear all of the variables and start fresh. You can also use the following functions in the console to view all variables, remove one variable, or remove all variables. ls() # print the variables in the global environment rm(&quot;x&quot;) # remove the variable named x from the global environment rm(list = ls()) # clear out the global environment In the upper right corner of the Environment tab, change List to Grid. Now you can see the type, length, and size of your variables, and reorder the list by any of these attributes. 1.4.4 Whitespace When you see &gt; at the beginning of a line, that means R is waiting for you to start a new command. However, if you see a + instead of &gt; at the start of the line, that means R is waiting for you to finish a command you started on a previous line. If you want to cancel whatever command you started, just press the Esc key in the console window and you’ll get back to the &gt; command prompt. # R waits until next line for evaluation (3 + 2) * 5 ## [1] 25 It is often useful to break up long functions onto several lines. cat(&quot;3, 6, 9, the goose drank wine&quot;, &quot;The monkey chewed tobacco on the streetcar line&quot;, &quot;The line broke, the monkey got choked&quot;, &quot;And they all went to heaven in a little rowboat&quot;, sep = &quot; \\n&quot;) ## 3, 6, 9, the goose drank wine ## The monkey chewed tobacco on the streetcar line ## The line broke, the monkey got choked ## And they all went to heaven in a little rowboat 1.4.5 Function syntax A lot of what you do in R involves calling a function and storing the results. A function is a named section of code that can be reused. For example, sd is a function that returns the standard deviation of the vector of numbers that you provide as the input argument. Functions are set up like this: function_name(argument1, argument2 = &quot;value&quot;). The arguments in parentheses can be named (like, argument1 = 10) or you can skip the names if you put them in the exact same order that they’re defined in the function. You can check this by typing ?sd (or whatever function name you’re looking up) into the console and the Help pane will show you the default order under Usage. You can also skip arguments that have a default value specified. Most functions return a value, but may also produce side effects like printing to the console. To illustrate, the function rnorm() generates random numbers from the standard normal distribution. The help page for rnorm() (accessed by typing ?rnorm in the console) shows that it has the syntax rnorm(n, mean = 0, sd = 1) where n is the number of randomly generated numbers you want, mean is the mean of the distribution, and sd is the standard deviation. The default mean is 0, and the default standard deviation is 1. There is no default for n, which means you’ll get an error if you don’t specify it: rnorm() ## Error in rnorm(): argument &quot;n&quot; is missing, with no default If you want 10 random numbers from a distribution with mean of 0 and standard deviation, you can just use the defaults. rnorm(10) ## [1] -1.06799077 0.21859353 0.02752006 1.06212096 1.19848107 ## [6] 1.27090533 -0.68834972 -0.07934186 0.34677210 -1.33664813 If you want 10 numbers from a distribution with a mean of 100: rnorm(10, 100) ## [1] 100.11765 99.67253 100.98941 99.46105 101.78003 100.97037 101.52439 ## [8] 100.72061 99.97754 100.44733 This would be an equivalent but less efficient way of calling the function: rnorm(n = 10, mean = 100) ## [1] 99.62188 100.18686 100.68920 101.28491 99.01409 101.06874 99.42712 ## [8] 100.00873 98.99459 101.25831 We don’t need to name the arguments because R will recognize that we intended to fill in the first and second arguments by their position in the function call. However, if we want to change the default for an argument coming later in the list, then we need to name it. For instance, if we wanted to keep the default mean = 0 but change the standard deviation to 100 we would do it this way: rnorm(10, sd = 100) ## [1] 3.7691472 77.5796516 -19.5130400 20.2349009 -96.1679018 ## [6] 9.2896782 -28.2873658 46.1905871 -21.6780387 0.7609686 Some functions give a list of options after an argument; this means the default value is the first option. The usage entry for the power.t.test() function looks like this: power.t.test(n = NULL, delta = NULL, sd = 1, sig.level = 0.05, power = NULL, type = c(&quot;two.sample&quot;, &quot;one.sample&quot;, &quot;paired&quot;), alternative = c(&quot;two.sided&quot;, &quot;one.sided&quot;), strict = FALSE, tol = .Machine$double.eps^0.25) What is the default value for sd? NULL 1 0.05 two.sample What is the default value for type? NULL two.sample one.sample paired Which is equivalent to power.t.test(100, 0.5)? power.t.test(100, 0.5, sig.level = 1, sd = 0.05) power.t.test() power.t.test(n = 100) power.t.test(delta = 0.5, n = 100) 1.4.6 Getting help Start up help in a browser using the function help.start(). If a function is in base R or a loaded package, you can use the help(&quot;function_name&quot;) function or the ?function_name shortcut to access the help file. If the package isn’t loaded, specify the package name as the second argument to the help function. # these methods are all equivalent ways of getting help help(&quot;rnorm&quot;) ?rnorm help(&quot;rnorm&quot;, package=&quot;stats&quot;) When the package isn’t loaded or you aren’t sure what package the function is in, use the shortcut ??function_name. What is the first argument to the mean function? trim na.rm mean x What package is read_excel in? readr readxl base stats 1.5 Add-on packages One of the great things about R is that it is user extensible: anyone can create a new add-on software package that extends its functionality. There are currently thousands of add-on packages that R users have created to solve many different kinds of problems, or just simply to have fun. There are packages for data visualisation, machine learning, neuroimaging, eyetracking, web scraping, and playing games such as Sudoku. Add-on packages are not distributed with base R, but have to be downloaded and installed from an archive, in the same way that you would, for instance, download and install a fitness app on your smartphone. The main repository where packages reside is called CRAN, the Comprehensive R Archive Network. A package has to pass strict tests devised by the R core team to be allowed to be part of the CRAN archive. You can install from the CRAN archive through R using the install.packages() function. There is an important distinction between installing a package and loading a package. 1.5.1 Installing a package This is done using install.packages(). This is like installing an app on your smartphone: you only have to do it once and the app will remain installed until you remove it.For instance, if you want to use PokemonGo on your phone you install it once from the App Store or Play Store, and you don’t have to re-install it each time you want to use it. Once you launch the app, it will run in the background until you close it or restart your phone. Likewise, when you install a package, the package will be available (but not loaded) every time you open up R. You may only be able to permanently install packages if you are using R on your own system; you may not be able to do this on public workstations because you will lack the appropriate privileges. Install the fortunes package on your system: install.packages(&quot;fortunes&quot;) If you don’t get an error message, the installation was successful. 1.5.2 Loading a package This is done using library(packagename). This is like launching an app on your phone: the functionality is only there where the app is launched and remains there until you close the app or restart. Likewise, when you run library(packagename) within a session, the functionality of the package referred to by packagename will be made available for your R session. The next time you start R, you will need to run the library() function again if you want to access its functionality. You can load the functions in fortune for your current R session as follows: library(fortunes) Once you have typed this, you can run the function fortune(), which spouts random wisdom from one of the R help lists: fortune() ## ## RAM is cheap and thinking hurts. ## -- Uwe Ligges (about memory requirements in R) ## R-help (June 2007) Note that we will use the convention package::function() to indicate in which add-on package a function resides. For instance, if you see readr::read_csv(), that refers to the function read_csv() in the readr add-on package. 1.5.3 Install from GitHub Many R packages are not yet on CRAN because they are still in development. Increasingly, datasets and code for papers are available as packages you can download from github. You’ll need to install the devtools package to be able to install packages from github. install.packages(&quot;devtools&quot;) devtools::install_github(&quot;adam-gruer/goodshirt&quot;) library(goodshirt) # quotes from The Good Place chidi() eleanor() ## ## I have what doctors call &quot;directional insanity&quot;. I once got lost on an escalator. ## ## ~ Chidi ## Girl, you are a messy bench who loves drama and I am into it! ## ## ~ Eleanor 1.6 Organising a project Projects in RStudio are a way to group all of the files you need for one project. Most projects include scripts, data files, and output files like the PDF version of the script or images. Make a new directory where you will keep all of your materials for this class. If you’re using a lab computer, make sure you make this directory in your network drive so you can access it from other computers. Choose New Project… under the File menu to create a new project called 01-intro in this directory. 1.6.1 Structure Here is what an R script looks like. Don’t worry about the details for now. # load add-on packages library(tidyverse) # set variables ---- n &lt;- 100 # simulate data ---- data &lt;- data.frame( id = 1:n, dv = c(rnorm(n/2, 0), rnorm(n/2, 1)), condition = rep(c(&quot;A&quot;, &quot;B&quot;), each = n/2) ) # plot data ---- ggplot(data, aes(condition, dv)) + geom_violin(trim = FALSE) + geom_boxplot(width = 0.25, aes(fill = condition), show.legend = FALSE) # save plot ---- ggsave(&quot;sim_data.png&quot;, width = 8, height = 6) It’s best if you follow the following structure when developing your own scripts: load in any add-on packages you need to use define any custom functions load or simulate the data you will be working with work with the data save anything you need to save Often when you are working on a script, you will realize that you need to load another add-on package. Don’t bury the call to library(package_I_need) way down in the script. Put it in the top, so the user has an overview of what packages are needed. You can add comments to an R script by with the hash symbol (#). The R interpreter will ignore characters from the hash to the end of the line. ## comments: any text from &#39;#&#39; on is ignored until end of line 22 / 7 # approximation to pi ## [1] 3.142857 1.6.2 Reproducible reports with R Markdown We will make reproducible reports following the principles of literate programming. The basic idea is to have the text of the report together in a single document along with the code needed to perform all analyses and generate the tables. The report is then “compiled” from the original format into some other, more portable format, such as HTML or PDF. This is different from traditional cutting and pasting approaches where, for instance, you create a graph in Microsoft Excel or a statistics program like SPSS and then paste it into Microsoft Word. We will use R Markdown to create reproducible reports, which enables mixing of text and code. A reproducible script will contain sections of code in code blocks. A code block starts and ends with backtick symbols in a row, with some infomation about the code between curly brackets, such as {r chunk-name, echo=FALSE} (this runs the code, but does not show the text of the code block in the compiled document). The text outside of code blocks is written in markdown, which is a way to specify formatting, such as headers, paragraphs, lists, bolding, and links. Figure 1.4: A reproducible script. If you open up a new RMarkdown file from a template, you will see an example document with several code blocks in it. To create an HTML or PDF report from an R Markdown (Rmd) document, you compile it. Compiling a document is called knit in RStudio. There is a button that looks like a ball of yarn with needles through it that you click on to compile your file into a report. Create a new R Markdown file from the File &gt; New File &gt; R Markdown… menu. Change the title and author, then click the knit button to create an html file. 1.6.3 Working Directory Where should I put all my files? When developing an analysis, you usually want to have all of your scripts and data files in one subtree of your computer’s directory structure. Usually there is a single working directory where your data and scripts are stored. Your script should only reference files in three locations, using the appropriate format. Where Example on the web “https://psyteachr.github.io/msc-data-skills/data/disgust_scores.csv” in the working directory “disgust_scores.csv” in a subdirectory “data/disgust_scores.csv” Never set or change your working directory in a script. If you are working with an R Markdown file, it will automatically use the same directory the .Rmd file is in as the working directory. If you are working with R scripts, store your main script file in the top-level directory and manually set your working directory to that location. You will have to reset the working directory each time you open RStudio, unless you create a project and access the script from the project. For instance, if on a Windows machine your data and scripts are in the directory C:\\Carla's_files\\thesis2\\my_thesis\\new_analysis, you will set your working directory in one of two ways: (1) by going to the Session pull down menu in RStudio and choosing Set Working Directory, or (2) by typing setwd(&quot;C:\\Carla's_files\\thesis2\\my_thesis\\new_analysis&quot;) in the console window. It’s tempting to make your life simple by putting the setwd() command in your script. Don’t do this! Others will not have the same directory tree as you (and when your laptop dies and you get a new one, neither will you). When manually setting the working directory, always do so by using the Session &gt; Set Working Directory pull-down option or by typing setwd() in the console. If your script needs a file in a subdirectory of new_analysis, say, data/questionnaire.csv, load it in using a relative path: dat &lt;- read_csv(&quot;data/questionnaire.csv&quot;) # right way Do not load it in using an absolute path: dat &lt;- read_csv(&quot;C:/Carla&#39;s_files/thesis22/my_thesis/new_analysis/data/questionnaire.csv&quot;) # wrong Also note the convention of using forward slashes, unlike the Windows-specific convention of using backward slashes. This is to make references to files platform independent. 1.7 Exercises Download the first set of exercises and put it in the project directory you created earlier for today’s exercises. See the answers only after you’ve attempted all the questions. "],
["data.html", "Chapter 2 Working with Data 2.1 Learning Objectives 2.2 Resources 2.3 Basic data types 2.4 Basic container types 2.5 Importing data 2.6 Exercises", " Chapter 2 Working with Data 2.1 Learning Objectives Understand the use the basic data types Understand and use the basic container types (list, vector) Create vectors and store them as variables Understand vectorized operations Create a data table Import data from CSV and Excel files 2.2 Resources Chapter 11: Data Import in R for Data Science RStudio Data Import Cheatsheet Scottish Babynames Developing an analysis in R/RStudio: Scottish babynames (1/2) Developing an analysis in R/RStudio: Scottish babynames (2/2) 2.3 Basic data types There are five main basic data types in R (there are more, but these are the critical ones you need to know about). type description example double floating point value .333337 integer integer -1, 0, 1 numeric any real number (int,dbl) 1, .5, -.222 boolean assertion of truth/falsity TRUE, FALSE character text string &quot;hello world&quot;, 'howdy' There is also a specific data type called a factor which will probably give you a headache sooner or later, but we can get by for now without them. Character strings can include basically anything, including quotes, but if you want a quote to be included you have to ‘escape’ it using a backslash: my_string &lt;- &quot;The instructor said, \\&quot;R is cool,\\&quot; and the class agreed.&quot; my_string ## [1] &quot;The instructor said, \\&quot;R is cool,\\&quot; and the class agreed.&quot; Note that if you just type a plain number such as 10 it is stored as a double, even if it doesn’t have a decimal point. If you want it to be an exact integer, use the L suffix (10L). If you ever want to know the data type of something, use the class function. There is also the mode function which is specifically for vectors. class(10) # numeric class(10L) # integer class(&quot;10&quot;) # string class(10L == 11L) # logical mode(TRUE) ## [1] &quot;numeric&quot; ## [1] &quot;integer&quot; ## [1] &quot;character&quot; ## [1] &quot;logical&quot; ## [1] &quot;logical&quot; 2.4 Basic container types 2.4.1 Vectors Vectors are one of the key data structures in R. A vector in R is like a vector in math: a set of ordered elements. All of the elements in a vector must be of the same data type (numeric, character, factor). You can create a vector by enclosing the elements in c(...), as shown below. ## put information into a vector using c(...) c(1, 2, 3) c(&quot;this&quot;, &quot;is&quot;, &quot;cool&quot;) ## what happens when you mix types? c(2, &quot;good&quot;, 2, &quot;b&quot;, &quot;true&quot;) ## [1] 1 2 3 ## [1] &quot;this&quot; &quot;is&quot; &quot;cool&quot; ## [1] &quot;2&quot; &quot;good&quot; &quot;2&quot; &quot;b&quot; &quot;true&quot; OK, here’s a question. When you type a single number in the console, it spits it back out to you, like this: 3L ## [1] 3 Why is there a [1] there? i.e., what does the [1] in the [1] 3 refer to? We’ll eventually get to the answer, but let’s see if you can discover it yourself through experiment. There is an operator : that, when placed between two integers x and y like so: x:y will yield the sequence of integers from x to y inclusive. Let’s make a big long vector of numbers and print it out. vec &lt;- 200:400 vec ## [1] 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 ## [18] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 ## [35] 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 ## [52] 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 ## [69] 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 ## [86] 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 ## [103] 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 ## [120] 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 ## [137] 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 ## [154] 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 ## [171] 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 ## [188] 387 388 389 390 391 392 393 394 395 396 397 398 399 400 Note the number in square brackets on the left hand side of the output. Note that vec is a vector: an ordered container of 200 elements, in this case, the integers from 200 to 400. The bracked number on the left hand side tells you the numeric index (i.e., element number) corresponding to the first value in that row. So the first value is 200, the 19th value is 218, the 37th value is 236, etc. Recall from the last class that another way to create a vector is to use the c() operator. (This is the easiest way, but you can also use the vector() function.) If we wanted to pick specific values out of the vector by position, we can make a vector of numbers like so: c(1L, 19L, 37L, 55L) ## [1] 1 19 37 55 And then pull them out using the [] operator, which is the extraction operator, on the variable vec. vec[c(1L, 19L, 37L, 55L)] ## note also: index &lt;- c(1L, 19L, 37L, 55L) vec[index] vec[c(1L, 1L, 19L, 19L, 19L, 19L)] ## [1] 200 218 236 254 ## [1] 200 218 236 254 ## [1] 200 200 218 218 218 218 OK let’s return to our original question: why did we get [1] 3 when we just typed 3L? The answer should now be clear: when we entered a single number, R created a vector with a single element. You can also create ‘named’ vectors, where each elements has a name. For example: vec2 &lt;- c(first = 77.9, second = -13.2, third = 100.1) vec2 ## first second third ## 77.9 -13.2 100.1 We can then access elements by name using a character vector within the square brackets. We can put them in any order we want, and we can repeat elements: vec2[c(&quot;third&quot;, &quot;second&quot;, &quot;second&quot;)] ## third second second ## 100.1 -13.2 -13.2 We can get the vector of names using the names() function, and we can set or change them using something like names(vec2) &lt;- c(&quot;n1&quot;, &quot;n2&quot;, &quot;n3&quot;). Another way to access elements is by using a logical vector within the square brackets. This will pull out the elements of the vector for which the corresponding element of the logical vector is TRUE. The logical vector must have the same length as the original. You can find out how long a vector is using the length() function. length(vec2) vec2[c(TRUE, FALSE, TRUE)] ## [1] 3 ## first third ## 77.9 100.1 Here are some useful tricks to save typing when creating vectors. Recall that in the command x:y the : operator would give you the sequence of integers from x:y. What if you want to repeat a vector many times? You could either type it out (painful) or use the rep() function, which can repeat vectors in different ways. # ten zeroes rep(0, 10) # alternating 1 and 3, 7 times rep(c(1L, 3L), 7) rep(c(TRUE, FALSE), 2) ## [1] 0 0 0 0 0 0 0 0 0 0 ## [1] 1 3 1 3 1 3 1 3 1 3 1 3 1 3 ## [1] TRUE FALSE TRUE FALSE What if you want to create a sequence but with something other than integer steps? You can use the seq() function. You can learn about this in the exercises below. # Repeat a vector # See the ?rep function rep(c(TRUE, FALSE), 3) # Get every other (odd) element of vec vec[rep(c(TRUE, FALSE), 100)] # We can also store the logical vector in a variable and use that evens &lt;- rep(c(FALSE, TRUE), 100) ## [1] TRUE FALSE TRUE FALSE TRUE FALSE ## [1] 200 202 204 206 208 210 212 214 216 218 220 222 224 226 228 230 232 ## [18] 234 236 238 240 242 244 246 248 250 252 254 256 258 260 262 264 266 ## [35] 268 270 272 274 276 278 280 282 284 286 288 290 292 294 296 298 300 ## [52] 302 304 306 308 310 312 314 316 318 320 322 324 326 328 330 332 334 ## [69] 336 338 340 342 344 346 348 350 352 354 356 358 360 362 364 366 368 ## [86] 370 372 374 376 378 380 382 384 386 388 390 392 394 396 398 400 You can’t mix data types in a vector; all elements of the vector must be the same data type. If you mix them, R will coerce them so that they are all the same. 2.4.1.1 Vectorized Operations R performs calculations on vectors in a special way. Let’s look at an example using \\(z\\)-scores. A \\(z\\)-score is a deviation score (a score minus a mean) divided by a standard deviation. Let’s say we have a set of four IQ scores. ## example IQ scores: mu = 100, sigma = 15 iq &lt;- c(86, 101, 127, 99) If we want to subtract the mean from these four scores, we just use the following code: iq - 100 ## [1] -14 1 27 -1 This subtracts 100 from each element of the vector. R automatically assumes that this is what you wanted to do; it is called a vectorized operation and it makes it possible to express operations more efficiently. To calculate \\(z\\)-scores we use the formula: \\(z = \\frac{X - \\mu}{\\sigma}\\) where X are the scores, \\(\\mu\\) is the mean, and \\(\\sigma\\) is the standard deviation. We can expression this formula in R as follows: ## z-scores (iq - 100) / 15 ## [1] -0.93333333 0.06666667 1.80000000 -0.06666667 You can see that it computed all four \\(z\\)-scores with a single line of code. Very efficient! 2.4.1.2 Exercises The built-in vector letters contains the letters of the English alphabet. Use an indexing vector of integers to extract the letters that spell ‘cat’. The function colors() returns all of the color names that R is aware of. What is the length of the vector returned by this function? (Use code to find the answer.) The function call runif(1000, 0, 1) will draw 1000 numbers from a uniform distribution from 0 to 1, which simulates the p-values that you would get from 1000 experiments where the null hypothesis is true. Store the result of this call in pvals. Create a logical vector called is_sig that is TRUE if the corresponding element of pvals is less than .05, FALSE otherwise (hint: vectorized operations from the last lession), then use this logical vector to pull out those p-values. Finally, calculate the proportion of those p-values that were significant. 2.4.2 Lists Recall that vectors can contain data of only one type. What if you want to store a collection of data of different data types? For that purpose you would use a list. Define a list using the list() function. albums &lt;- list( Michael_Jackson = c( &quot;Off the Wall&quot;, &quot;Thriller&quot;, &quot;Bad&quot;, &quot;Dangerous&quot; ), Nirvana = c( &quot;Bleach&quot;, &quot;Nevermind&quot;, &quot;In Utero&quot; ) ) names(albums) length(albums) You can refer to elements of a list by Fun fact: tabular data, stored in data.frame or tibble objects, which you will learn about in the next section, are a special type of list. That means you can access the columns of one of these object using tablename$column syntax, which is sometimes useful. 2.4.3 Tabular data Most of what you will be working with in this course is tabular data, data arranged in the form of a table. Tabular data structures, like lists, allow for a collection of data of different types (characters, integers, logical, etc.) but subject to the constraint that each “column” of the table (element of the list) must have the same number of elements. The base R version of a table is called a data.frame while the ‘tidyverse’ version is called a tibble. Tibbles are far easier to work with, so we’ll be using those. To learn more about differences between these two data structures, see vignette(&quot;tibble&quot;). Tabular data becomes especially important for when we talk about tidy data in lesson 4, which consists of a set of simple principles for structuring data. If we are creating a tibble from scratch, we can use the tibble() function, and type the data right in. Note that if we want a value to repeat multiple times, we only have to specify a one-element vector; R will expand out the vector to fill out the table. All columns in the tibble must have the same lengths or be of length 1. If we want to use the tibble() function, we either need to load the tibble package or the tidyverse package (which will itself load tibble in addition to other packages). Let’s do the latter. library(&quot;tidyverse&quot;) We can get information about the table dimensions using the functions ncol() (number of columns), nrow() (number of rows), or dim() (a vector with the number of rows and number of columns). months &lt;- tibble(ID = 1:12, name = c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;)) # print it months # how many rows? nrow(months) # how many columns? ncol(months) 2.4.3.1 Viewing your tibble Always, always, always, look at your data once you’ve created the table and load it in. Also look at it after each step that transforms your tibble. There are three ways to look at your tibble: View() [*NB: capital ‘V’], print(), and glimpse(). Note that it is also rare that you want to print your data in a script; that is something you usually are doing for a sanity check, and you should just do it in the console. The print() method can be run explicitly, but is more commonly called by just typing the variable name on the blank line. Usually we only call print() if we want fine control of how the information is displayed. Note that the default is not to print the entire table, but just the first 10 rows. Let’s look at the starwars table that is built into the tidyverse. starwars ## # A tibble: 87 x 13 ## name height mass hair_color skin_color eye_color birth_year gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Luke… 172 77 blond fair blue 19 male ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; ## 4 Dart… 202 136 none white yellow 41.9 male ## 5 Leia… 150 49 brown light brown 19 female ## 6 Owen… 178 120 brown, gr… light blue 52 male ## 7 Beru… 165 75 brown light blue 47 female ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA &lt;NA&gt; ## 9 Bigg… 183 84 black light brown 24 male ## 10 Obi-… 182 77 auburn, w… fair blue-gray 57 male ## # … with 77 more rows, and 5 more variables: homeworld &lt;chr&gt;, ## # species &lt;chr&gt;, films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; You can see that this is a 87 rows by 13 column table, and we can only see the first 10 rows and first 8 columns. If I want to see all 87 rows for some reason, I would use an explicit call to print(), and set the argument n to the number of rows I want to see. If I want all of them, just use +Inf, the symbol for ‘infinite’ rows. print(starwars, n = +Inf) # try this in the console But we still can’t see all the columns. If this is important to us, we can use glimpse(), which gives a sideways version of the tibble. glimpse(starwars) ## Observations: 87 ## Variables: 13 ## $ name &lt;chr&gt; &quot;Luke Skywalker&quot;, &quot;C-3PO&quot;, &quot;R2-D2&quot;, &quot;Darth Vader&quot;, &quot;L… ## $ height &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, … ## $ mass &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.… ## $ hair_color &lt;chr&gt; &quot;blond&quot;, NA, NA, &quot;none&quot;, &quot;brown&quot;, &quot;brown, grey&quot;, &quot;bro… ## $ skin_color &lt;chr&gt; &quot;fair&quot;, &quot;gold&quot;, &quot;white, blue&quot;, &quot;white&quot;, &quot;light&quot;, &quot;lig… ## $ eye_color &lt;chr&gt; &quot;blue&quot;, &quot;yellow&quot;, &quot;red&quot;, &quot;yellow&quot;, &quot;brown&quot;, &quot;blue&quot;, &quot;… ## $ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, … ## $ gender &lt;chr&gt; &quot;male&quot;, NA, NA, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;, N… ## $ homeworld &lt;chr&gt; &quot;Tatooine&quot;, &quot;Tatooine&quot;, &quot;Naboo&quot;, &quot;Tatooine&quot;, &quot;Alderaa… ## $ species &lt;chr&gt; &quot;Human&quot;, &quot;Droid&quot;, &quot;Droid&quot;, &quot;Human&quot;, &quot;Human&quot;, &quot;Human&quot;,… ## $ films &lt;list&gt; [&lt;&quot;Revenge of the Sith&quot;, &quot;Return of the Jedi&quot;, &quot;The … ## $ vehicles &lt;list&gt; [&lt;&quot;Snowspeeder&quot;, &quot;Imperial Speeder Bike&quot;&gt;, &lt;&gt;, &lt;&gt;, &lt;… ## $ starships &lt;list&gt; [&lt;&quot;X-wing&quot;, &quot;Imperial shuttle&quot;&gt;, &lt;&gt;, &lt;&gt;, &quot;TIE Advanc… The other way to look at the table is a more graphical spreadsheet-like version given by View() (capital ‘V’). It can be useful in the console, but don’t ever put this one in a script because it will create an annoying pop-up window when the user goes to run it. Note that data.frame objects are printed out in different ways from tibble objects. If you print a data.frame object with thousands or millions of rows, you won’t just get a preview… you will spam your console with row upon row of data. If you want to make a data.frame into a tibble so that it prints out nicely, just use the as_tibble() function. mtcars # prints out way too many rows; TMI as_tibble(mtcars) # much cleaner mtcars2 &lt;- as_tibble(mtcars) # store it 2.4.3.2 Accessing rows and columns There are various base R ways of accessing specific columns or rows from a table that are useful to know about, but you’ll be learning easier (and more readable) ways when we get to the lecture on data wrangling. Examples of these base R accessing functions are provided here for reference. months[1, ] # first row months[, 2] # second column (position) months[1:3, ] # first 3 months months[, c(&quot;Month&quot;)] # access column by name months$month # by column name You’ll learn about data frame operations in the tidyr and dplyr lessons. 2.4.3.3 Exercises Create a tibble with the name, age, and sex of 3-5 people whose names, ages, and sex you know. Convert the built-in base R iris dataset to a tibble, and store it in the variable iris2. Create a tibble that has the structure of the table below, using the minimum typing possible. (Hint: rep()). Store it in the variable my_tbl. ## # A tibble: 8 x 4 ## ID A B C ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 A1 B1 C1 ## 2 2 A1 B2 C1 ## 3 3 A1 B1 C1 ## 4 4 A1 B2 C1 ## 5 5 A2 B1 C1 ## 6 6 A2 B2 C1 ## 7 7 A2 B1 C1 ## 8 8 A2 B2 C1 2.5 Importing data There are many different types of files that you might work with when doing data analysis. These different file types are usually distinguished by the three letter extension following a period at the end of the file name. Here are some examples of different types of files and the functions you would use to read them in or write them out. Extension File Type Reading Writing .csv Comma-separated values readr::read_csv() readr::write_csv() .xls, .xlsx Excel workbook readxl::read_excel() N/A .rds R binary file readRDS() saveRDS() .RData R binary file load() save() Note: following the conventions introduced above in the section about add-on packages, readr::read_csv() refers to the read_csv() function in the readr package, and readxl::read_excel() refers to the function read_excel() in the package readxl. Probably the most common file type you will encounter is .csv (comma-separated values). As the name suggests, a CSV file distinguishes which values go with which variable by separating them with commas, and text values are sometimes enclosed in double quotes. The first line of a file usually provides the names of the variables. For example, here are the first few lines of a CSV containing Scottish baby names (see the page at National Records Scotland): yr,sex,FirstForename,number,rank,position 1974,B,David,1794,1,1 1974,B,John,1528,2,2 1974,B,Paul,1260,3,3 1974,B,Mark,1234,4,4 1974,B,James,1202,5,5 1974,B,Andrew,1067,6,6 1974,B,Scott,1060,7,7 1974,B,Steven,1020,8,8 1974,B,Robert,885,9,9 1974,B,Stephen,866,10,10 There are six variables in this dataset, and their names are given in the first line of the file: yr, sex, FirstForename, number, rank, and position. You can see that the values for each of these variables are given in order, separated by commas, on each subsequent line of the file. When you read in CSV files, it is best practice to use the readr::read_csv() function. The readr package is automatically loaaded as part of the tidyverse package, which we will be using in almost every script. Note that you would normally want to store the result of the read_csv() function to a variable, as so: library(tidyverse) dat &lt;- read_csv(&quot;my_data_file.csv&quot;) Once loaded, you can view your data using the data viewer. In the upper right hand window of RStudio, under the Environment tab, you will see the object dat listed. If you click on the View icon (), it will bring up a table view of the data you loaded in the top left pane of RStudio. This allows you to check that the data have been loaded in properly. You can close the tab when you’re done looking at it—it won’t remove the object. 2.5.1 Writing Data If you have data that you want to save your data to a CSV file, use readr::write_csv(), as follows. write_csv(dat, &quot;my_data_file2.csv&quot;) This will save the data in CSV format to your working directory. 2.6 Exercises Download the exercises. See the answers only after you’ve attempted all the questions. "],
["ggplot.html", "Chapter 3 Data Visualisation 3.1 Learning Objectives 3.2 Resources 3.3 Setup 3.4 Common Variable Combinations 3.5 Data 3.6 Basic Plots 3.7 Save as File 3.8 Combination Plots 3.9 Overlapping Data 3.10 Heat map 3.11 Interactive Plots 3.12 Quiz 3.13 Exercises", " Chapter 3 Data Visualisation Take the quiz to see if you need to review this chapter. 3.1 Learning Objectives 3.1.1 Basic Understand what types of graphs are best for different types of data 1 discrete 1 continuous 2 discrete 2 continuous 1 discrete, 1 continuous 3 continuous Create common types of graphs with ggplot2 geom_bar() geom_density() geom_freqpoly() geom_histogram() geom_violin() geom_boxplot() geom_col() geom_point() geom_smooth() Set custom labels Represent factorial designs with different colours or facets Save plots as an image file 3.1.2 Intermediate Superimpose different types of graphs Add lines to graphs Deal with overlapping data Create less common types of graphs geom_tile() geom_density2d() geom_bin2d() geom_hex() geom_count() Use the viridis package to set colours 3.1.3 Advanced Arrange plots in a grid using cowplot Adjust axes (e.g., flip coordinates, set axis limits) Change the theme Create interactive graphs with plotly 3.2 Resources Look at Data from Data Vizualization for Social Science Chapter 3: Data Visualisation of R for Data Science Chapter 28: Graphics for communication of R for Data Science ggplot2 cheat sheet ggplot2 documentation The R Graph Gallery (this is really useful) Top 50 ggplot2 Visualizations R Graphics Cookbook by Winston Chang The viridis color palettes ggplot extensions plotly for creating interactive graphs 3.3 Setup # libraries needed for these graphs library(tidyverse) library(viridis) library(plotly) # cowplot will change the default theme of graphs, so we&#39;re loading it later # library(cowplot) 3.4 Common Variable Combinations 1 discrete 1 continuous 2 discrete 2 continuous 1 discrete, 1 continuous 3 continuous Before you read ahead, come up with an example of each type of variable combination and sketch the types of graphs that would best display these data. 3.5 Data Here we’ve created some data frames with different types of data. pets has a column with pet type pet_happy has happiness and age for 500 dog owners and 500 cat owners x_vs_y has two correlated continuous variables (x and y) overlap has two correlated ordinal variables and 1000 observations so there is a lot of overlap overplot has two correlated continuous variables and 10000 observations pets &lt;- tibble( pet = sample( c(&quot;dog&quot;, &quot;cat&quot;, &quot;ferret&quot;, &quot;bird&quot;, &quot;fish&quot;), 100, TRUE, c(0.45, 0.40, 0.05, 0.05, 0.05) ) ) pet_happy &lt;- tibble( pet = rep(c(&quot;dog&quot;, &quot;cat&quot;), each = 500), happiness = c(rnorm(500, 55, 10), rnorm(500, 45, 10)), age = rpois(1000, 3) + 20 ) x_vs_y &lt;- tibble( x = rnorm(100), y = x + rnorm(100, 0, 0.5) ) overlap &lt;- tibble( x = rbinom(1000, 10, 0.5), y = x + rbinom(1000, 20, 0.5) ) overplot &lt;- tibble( x = rnorm(10000), y = x + rnorm(10000, 0, 0.5) ) First, think about what kinds of graphs are best for representing these different types of data. 3.6 Basic Plots 3.6.1 Bar plot Bar plots are good for categorical data where you want to represent the count. ggplot(pets, aes(pet)) + geom_bar() Figure 3.1: Bar plot 3.6.2 Density plot Density plots are good for one continuous variable, but only if you have a fairly large number of observations. ggplot(pet_happy, aes(happiness)) + geom_density() Figure 3.2: Density plot You can represent subsets of a variable by assigning the category variable to the argument group, fill, or color. ggplot(pet_happy, aes(happiness, fill = pet)) + geom_density(alpha = 0.5) Figure 3.3: Grouped density plot Try changing the alpha argument to figure out what it does. 3.6.3 Frequency Polygons If you don’t want smoothed distributions, try geom_freqpoly(). ggplot(pet_happy, aes(happiness, color = pet)) + geom_freqpoly(binwidth = 1) Figure 3.4: Frequency ploygon plot Try changing the binwidth argument to 5 and 0.1. How do you figure out the right value? 3.6.4 Histogram Histograms are also good for one continuous variable, and work well if you don’t have many observations. Set the binwidth to control how wide each bar is. ggplot(pet_happy, aes(happiness)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;) Figure 3.5: Histogram Histograms in ggplot look pretty bad unless you set the fill and color. If you show grouped histograms, you also probably want to change the default position argument. ggplot(pet_happy, aes(happiness, fill=pet)) + geom_histogram(binwidth = 1, alpha = 0.5, position = &quot;dodge&quot;) Figure 3.6: Grouped Histogram Try changing the position argument to “identity”, “fill”, “dodge”, or “stack”. 3.6.5 Column plot Column plots are the worst way to represent grouped continuous data, but also one of the most common. To make column plots with error bars, you first need to calculate the means, error bar uper limits (ymax) and error bar lower limits (ymin) for each category. You’ll learn more about how to use the code below in the next two lessons. # calculate mean and SD for each pet pet_happy %&gt;% group_by(pet) %&gt;% summarise( mean = mean(happiness), sd = sd(happiness) ) %&gt;% ggplot(aes(pet, mean, fill=pet)) + geom_col(alpha = 0.5) + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.25) + geom_hline(yintercept = 40) Figure 3.7: Column plot What do you think geom_hline() does? 3.6.6 Boxplot Boxplots are great for representing the distribution of grouped continuous variables. They fix most of the problems with using barplots for continuous data. ggplot(pet_happy, aes(pet, happiness, fill=pet)) + geom_boxplot(alpha = 0.5) Figure 3.8: Box plot 3.6.7 Violin plot Violin pots are like sideways, mirrored density plots. They give even more information than a boxplot about distribution and are especially useful when you have non-normal distributions. ggplot(pet_happy, aes(pet, happiness, fill=pet)) + geom_violin( trim = FALSE, draw_quantiles = c(0.25, 0.5, 0.75), alpha = 0.5 ) Figure 3.9: Violin plot Try changing the numbers in the draw_quantiles argument. 3.6.8 Scatter plot Scatter plots are a good way to represent the relationship between two continuous variables. ggplot(x_vs_y, aes(x, y)) + geom_point() Figure 3.10: Scatter plot using geom_point() 3.6.9 Line graph You often want to represent the relationship as a single line. ggplot(x_vs_y, aes(x, y)) + geom_smooth(method=&quot;lm&quot;) Figure 3.11: Line plot using geom_smooth() 3.7 Save as File You can save a ggplot using ggsave(). It saves the last ggplot you made, by default, but you can specify which plot you want to save if you assigned that plot to a variable. You can set the width and height of your plot. The default units are inches, but you can change the units argument to “in”, “cm”, or “mm”. box &lt;- ggplot(pet_happy, aes(pet, happiness, fill=pet)) + geom_boxplot(alpha = 0.5) violin &lt;- ggplot(pet_happy, aes(pet, happiness, fill=pet)) + geom_violin(alpha = 0.5) ggsave(&quot;demog_violin_plot.png&quot;, width = 5, height = 7) ggsave(&quot;demog_box_plot.jpg&quot;, plot = box, width = 5, height = 7) 3.8 Combination Plots 3.8.1 Violinbox plot To demonstrate the use of facet_grid() for factorial designs, we create a new column called agegroup to split the data into participants older than the meadian age or younger than the median age. New factors will display in alphabetical order, so we can use the factor() function to set the levels in the order we want. pet_happy %&gt;% mutate(agegroup = ifelse(age&lt;median(age), &quot;Younger&quot;, &quot;Older&quot;), agegroup = factor(agegroup, levels = c(&quot;Younger&quot;, &quot;Older&quot;))) %&gt;% ggplot(aes(pet, happiness, fill=pet)) + geom_violin(trim = FALSE, alpha=0.5, show.legend = FALSE) + geom_boxplot(width = 0.25, fill=&quot;white&quot;) + facet_grid(.~agegroup) + scale_fill_manual(values = c(&quot;orange&quot;, &quot;green&quot;)) Figure 3.12: Violin-box plot Set the show.legend argument to FALSE to hide the legend. We do this here because the x-axis already labels the pet types. 3.8.2 Violin-point-range plot You can use stat_summary() to superimpose a point-range plot showning the mean ± 1 SD. You’ll learn how to write your own functions in the lesson on Iteration and Functions. ggplot(pet_happy, aes(pet, happiness, fill=pet)) + geom_violin( trim = FALSE, alpha = 0.5 ) + stat_summary( fun.y = mean, fun.ymax = function(x) {mean(x) + sd(x)}, fun.ymin = function(x) {mean(x) - sd(x)}, geom=&quot;pointrange&quot; ) Figure 3.13: Point-range plot using stat_summary() 3.8.3 Violin-jitter plot If you don’t have a lot of data points, it’s good to represent them individually. You can use geom_point to do this, setting position to “jitter”. pet_happy %&gt;% sample_n(50) %&gt;% # choose 50 random observations from the dataset ggplot(aes(pet, happiness, fill=pet)) + geom_violin( trim = FALSE, draw_quantiles = c(0.25, 0.5, 0.75), alpha = 0.5 ) + geom_point(position = &quot;jitter&quot;, alpha = 0.7, size = 3) Figure 3.14: Violin-jitter plot 3.8.4 Scatter-line graph If your graph isn’t too complicated, it’s good to also show the individual data points behind the line. ggplot(x_vs_y, aes(x, y)) + geom_point(alpha = 0.25) + geom_smooth(method=&quot;lm&quot;) (#fig:scatter_line)Scatter-line plot 3.8.5 Grid of plots You can use the cowplot package to easily make grids of different graphs. First, you have to assign each plot a name. Then you list all the plots as the first arguments of plot_grid() and provide a list of labels. library(cowplot) my_hist &lt;- ggplot(pet_happy, aes(happiness, fill=pet)) + geom_histogram( binwidth = 1, alpha = 0.5, position = &quot;dodge&quot;, show.legend = FALSE ) my_violin &lt;- ggplot(pet_happy, aes(pet, happiness, fill=pet)) + geom_violin( trim = FALSE, draw_quantiles = c(0.5), alpha = 0.5, show.legend = FALSE ) my_box &lt;- ggplot(pet_happy, aes(pet, happiness, fill=pet)) + geom_boxplot(alpha=0.5, show.legend = FALSE) my_density &lt;- ggplot(pet_happy, aes(happiness, fill=pet)) + geom_density(alpha=0.5, show.legend = FALSE) my_bar &lt;- pet_happy %&gt;% group_by(pet) %&gt;% summarise( mean = mean(happiness), sd = sd(happiness) ) %&gt;% ggplot(aes(pet, mean, fill=pet)) + geom_bar(stat=&quot;identity&quot;, alpha = 0.5, show.legend = FALSE) + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.25) plot_grid( my_violin, my_box, my_density, my_bar, labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;) ) Figure 3.15: Grid of plots using cowplot {#theme} Once you load the cowplot package, your ggplot default theme will change. You can get back the default ggplot theme with + theme_set(theme_grey()). 3.9 Overlapping Data 3.9.1 Discrete Data You can deal with overlapping data points (very common if you’re using Likert scales) by reducing the opacity of the points. You need to use trial and error to adjust these so they look right. ggplot(overlap, aes(x, y)) + geom_point(size = 5, alpha = .05) + geom_smooth(method=&quot;lm&quot;) (#fig:overlap_alpha)Deal with overlapping data using transparency {#geom_count} Or you can set the size of the dot proportional to the number of overlapping observations using geom_count(). overlap %&gt;% ggplot(aes(x, y)) + geom_count(color = &quot;#663399&quot;) (#fig:overlap_size)Deal with overlapping data using geom_count() Alternatively, you can transform your data to create a count column and use the count to set the dot colour. overlap %&gt;% group_by(x, y) %&gt;% summarise(count = n()) %&gt;% ggplot(aes(x, y, color=count)) + geom_point(size = 5) + scale_color_viridis() Figure 3.16: Deal with overlapping data using dot colour 3.9.2 Colours The viridis package changes the colour themes to be easier to read by people with colourblindness and to print better in greyscale. Use scale_color_viridis() to set the colour palette and scale_fill_viridis() to set the fill palette in ggplot. If you need discrete (as opposed to continuous) colours, use scale_color_viridis(discrete=TRUE) or scale_fill_viridis(discrete=TRUE) instead. The newest version of ggplot2 v3.0.0 has viridis built in. It uses scale_colour_viridis_c() and scale_fill_viridis_c() for continuous variables and scale_colour_viridis_d() and scale_fill_viridis_d() for discrete variables. 3.9.3 Continuous Data Even if the variables are continuous, overplotting might obscure any relationships if you have lots of data. overplot %&gt;% ggplot(aes(x, y)) + geom_point() Figure 3.17: Overplotted data {#geom_density2d} Use geom_density2d() to create a contour map. overplot %&gt;% ggplot(aes(x, y)) + geom_density2d() Figure 3.18: Contour map with geom_density2d() You can use stat_density_2d(aes(fill = ..level..), geom = &quot;polygon&quot;) to create a heatmap-style density plot. overplot %&gt;% ggplot(aes(x, y)) + stat_density_2d(aes(fill = ..level..), geom = &quot;polygon&quot;) + scale_fill_viridis() Figure 3.19: Heatmap-density plot {#geom_bin2d} Use geom_bin2d() to create a rectangular heatmap of bin counts. Set the binwidth to the x and y dimensions to capture in each box. overplot %&gt;% ggplot(aes(x, y)) + geom_bin2d(binwidth = c(1,1)) Figure 3.20: Heatmap of bin counts {#geom_hex} Use geomhex() to create a hexagonal heatmap of bin counts. Adjust the binwidth, xlim(), ylim() and/or the figure dimensions to make the hexagons more or less stretched. overplot %&gt;% ggplot(aes(x, y)) + geom_hex(binwidth = c(0.25, 0.25)) Figure 3.21: Hexagonal heatmap of bin counts 3.10 Heat map I’ve included the code for creating a correlation matrix from a table of variables, but you don’t need to understand how this is done yet. We’ll cover mutate and gather functions in the dplyr and tidyr lessons. # generate two sets of correlated variables (a and b) heatmap &lt;- tibble( a1 = rnorm(100), b1 = rnorm(100) ) %&gt;% mutate( a2 = a1 + rnorm(100), a3 = a1 + rnorm(100), a4 = a1 + rnorm(100), b2 = b1 + rnorm(100), b3 = b1 + rnorm(100), b4 = b1 + rnorm(100) ) %&gt;% cor() %&gt;% # create the correlation matrix as.data.frame() %&gt;% # make it a data frame rownames_to_column(var = &quot;V1&quot;) %&gt;% # set rownames as V1 gather(&quot;V2&quot;, &quot;r&quot;, a1:b4) # wide to long (V2) Once you have a correlation matrix in the correct (long) format, it’s easy to make a heatmap using geom_tile(). ggplot(heatmap, aes(V1, V2, fill=r)) + geom_tile() + scale_fill_viridis() Figure 3.22: Heatmap using geom_tile() The file type is set from the filename suffix, or by specifying the argument device, which can take the following values: “eps”, “ps”, “tex”, “pdf”, “jpeg”, “tiff”, “png”, “bmp”, “svg” or “wmf”. 3.11 Interactive Plots You can use the plotly package to make interactive graphs. Just assign your ggplot to a variable and use the function ggplotly(). demog_plot &lt;- ggplot(pet_happy, aes(pet, happiness, fill=pet)) + geom_point(position = position_jitter(width= 0.2, height = 0), size = 2) ggplotly(demog_plot) Figure 3.23: Interactive graph using plotly Hover over the data points above and click on the legend items. 3.12 Quiz Generate a plot like this from the built-in dataset iris. Make sure to include the custom axis labels. ggplot(iris, aes(Species, Petal.Width, fill = Species)) + geom_boxplot(show.legend = FALSE) + xlab(&quot;Flower Species&quot;) + ylab(&quot;Petal Width (in cm)&quot;) # there are many ways to do things, the code below is also correct ggplot(iris) + geom_boxplot(aes(Species, Petal.Width, fill = Species), show.legend = FALSE) + labs(x = &quot;Flower Species&quot;, y = &quot;Petal Width (in cm)&quot;) You have just created a plot using the following code. How do you save it? ggplot(cars, aes(speed, dist)) + geom_point() + geom_smooth(method = lm) ggsave() ggsave(“figname”) ggsave(“figname.png”) ggsave(“figname.png”, plot = cars) Debug the following code. ggplot(iris) + geom_point(aes(Petal.Width, Petal.Length, colour = Species)) + geom_smooth(method = lm) + facet_grid(Species) ggplot(iris, aes(Petal.Width, Petal.Length, colour = Species)) + geom_point() + geom_smooth(method = lm) + facet_grid(~Species) Generate a plot like this from the built-in dataset ChickWeight. ggplot(ChickWeight, aes(weight, Time)) + geom_hex(binwidth = c(10, 1)) + scale_fill_viridis_c() Generate a plot like this from the built-in dataset iris. pw &lt;- ggplot(iris, aes(Petal.Width, color = Species)) + geom_density() + xlab(&quot;Petal Width (in cm)&quot;) pl &lt;- ggplot(iris, aes(Petal.Length, color = Species)) + geom_density() + xlab(&quot;Petal Length (in cm)&quot;) + coord_flip() pw_pl &lt;- ggplot(iris, aes(Petal.Width, Petal.Length, color = Species)) + geom_point() + geom_smooth(method = lm) + xlab(&quot;Petal Width (in cm)&quot;) + ylab(&quot;Petal Length (in cm)&quot;) cowplot::plot_grid( pw, pl, pw_pl, labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), nrow = 3 ) 3.13 Exercises Download the exercises. See the plots to see what your plots should look like (this doesn’t contain the answer code). See the answers only after you’ve attempted all the questions. "],
["tidyr.html", "Chapter 4 Tidy Data 4.1 Learning Objectives 4.2 Resources 4.3 Setup 4.4 Three Rules for Tidy Data 4.5 Tidying Data 4.6 Pipes 4.7 More Complex Example 4.8 Quiz 4.9 Exercises", " Chapter 4 Tidy Data Take the quiz to see if you need to review this chapter. 4.1 Learning Objectives 4.1.1 Basic Understand the concept of tidy data Be able to use the 4 basic tidyr verbs gather() separate() spread() unite() Be able to chain functions using pipes 4.1.2 Intermediate Be able to use arguments like sep, extra, and convert to handle less straightforward data cleaning 4.1.3 Advanced Be able to use regular expressions to separate complex columns 4.2 Resources Tidy Data Chapter 12: Tidy Data in R for Data Science Chapter 18: Pipes in R for Data Science Data wrangling cheat sheet 4.3 Setup # libraries needed library(tidyverse) library(readxl) 4.4 Three Rules for Tidy Data Each variable must have its own column Each observation must have its own row Each value must have its own cell This table has three observations per row and the total_meanRT column contains two values. id score_1 score_2 score_3 rt_1 rt_2 rt_3 t otal_meanRT 1 1 4 4 846 784 762 9 (797) 2 3 1 2 641 751 837 6 (743) 3 6 2 1 745 897 773 9 (805) 4 2 3 7 824 814 792 12 (810) 5 7 5 6 726 881 759 18 (789) This is the tidy version. id t rial rt score t otal m ean_rt 1 1 846 1 9 797 1 2 784 4 9 797 1 3 762 4 9 797 2 1 641 3 6 743 2 2 751 1 6 743 2 3 837 2 6 743 3 1 745 6 9 805 3 2 897 2 9 805 3 3 773 1 9 805 4 1 824 2 12 810 4 2 814 3 12 810 4 3 792 7 12 810 5 1 726 7 18 789 5 2 881 5 18 789 5 3 759 6 18 789 4.5 Tidying Data Download the data from personality.csv. These data are from a 5-factor (OCEAN) personality questionnaire. Each question is labelled with the domain (Op = openness, Co = concientiousness, Ex = extraversion, Ag = agreeableness, and Ne = neuroticism) and the question number. ocean &lt;- read_csv(&quot;https://psyteachr.github.io/msc-data-skills/data/personality.csv&quot;) ## Parsed with column specification: ## cols( ## .default = col_double(), ## date = col_date(format = &quot;&quot;) ## ) ## See spec(...) for full column specifications. 4.5.1 gather() gather(data, key = &quot;key&quot;, value = &quot;value&quot;, ..., na.rm = FALSE, convert = FALSE, factor_key = FALSE) ocean is in wide format, with a separate column for each question. Change it to long format, with a row for each user/question observation. key is what you want to call the row headers; it’s “question” in this example. value is what you want to call the values in the gathered columns; they’re “score” in this example. The ... refers to the columns you want to gather. You can refer to them by their names, like col1, col2, col3, col4 or col1:col4 or by their numbers, like 8, 9, 10 or 8:10. Convert from wide to long format. The resulting dataframe should have the columns: user_id, date, question, and score. ocean_gathered &lt;- gather(ocean, &quot;question&quot;, &quot;score&quot;, Op1:Ex9) 4.5.2 separate() separate(data, col, into, sep = &quot;[^[:alnum:]]+&quot;, remove = TRUE, convert = FALSE, extra = &quot;warn&quot;, fill = &quot;warn&quot;) Split the question column into two columns: domain and qnumber. There is no character to split on, here, but you can separate a column after a specific number of characters by setting sep to an integer. For example, to split “abcde” after the third character, use sep = 3, which results in c(&quot;abc&quot;, &quot;de&quot;). You can also use negative number to split before the nth character from the right. For example, to split a column that has words of various lengths and 2-digit suffixes (like “lisa03”“,”amanda38&quot;), you can use sep = -2. ocean_sep &lt;- separate(ocean_gathered, question, c(&quot;domain&quot;, &quot;qnumber&quot;), sep = 2) 4.5.3 unite() unite(data, col, ..., sep = &quot;_&quot;, remove = TRUE) Put the domain and qnumber columns back together into a new column named domain_n. Make it in a format like “Op_Q1”. ocean_unite &lt;- unite(ocean_sep, &quot;domain_n&quot;, domain, qnumber, sep = &quot;_Q&quot;) 4.5.4 spread() spread(data, key, value, fill = NA, convert = FALSE, drop = TRUE, sep = NULL) You can reverse the processes above, as well. For example, you can convert data from long format into wide format. key is the column that contains your new column headers value is the column that contains the values in the new spread columns ocean_spread &lt;- spread(ocean_unite, domain_n, score) 4.6 Pipes Pipes are a way to order your code in a more readable format. Let’s say you have a small data table with 10 participant IDs, two columns with variable type A, and 2 columns with variable type B. You want to calculate the mean of the A variables and the mean of the B variables and return a table with 10 rows (1 for each participant) and 3 columns (id, A_mean and B_mean). One way you could do this is by creating a new object at every step and using that object in the next step. This is pretty clear, but you’ve created 6 unnecessary data objects in your environment. This can get confusing in very long scripts. # make a data table with 10 subjects data_original &lt;- tibble( id = 1:10, A1 = rnorm(10, 0), A2 = rnorm(10, 1), B1 = rnorm(10, 2), B2 = rnorm(10, 3) ) # gather columns A1 to B2 into &quot;variable&quot; and &quot;value&quot; columns data_gathered &lt;- gather(data_original, variable, value, A1:B2) # separate the variable column at the _ into &quot;var&quot; and &quot;var_n&quot; columns data_separated &lt;- separate(data_gathered, variable, c(&quot;var&quot;, &quot;var_n&quot;), sep = 1) # group the data by id and var data_grouped &lt;- group_by(data_separated, id, var) # calculate the mean value for each id/var data_summarised &lt;- summarise(data_grouped, mean = mean(value)) # spread the mean column into A and B columns data_spread &lt;- spread(data_summarised, var, mean) # rename A and B to A_mean and B_mean data &lt;- rename(data_spread, A_mean = A, B_mean = B) data ## # A tibble: 10 x 3 ## # Groups: id [10] ## id A_mean B_mean ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.317 2.11 ## 2 2 0.160 1.89 ## 3 3 1.90 2.32 ## 4 4 1.14 2.34 ## 5 5 0.491 1.77 ## 6 6 -1.52 3.00 ## 7 7 -0.144 2.71 ## 8 8 -0.568 2.30 ## 9 9 0.533 2.58 ## 10 10 0.0620 2.57 You can name each object data and keep replacing the old data object with the new one at each step. This will keep your environment clean, but I don’t recommend it because it makes it too easy to accidentally run your code out of order when you are running line-by-line for development or debugging. One way to avoid extra objects is to nest your functions, literally replacing each data object with the code that generated it in the previous step. This can be fine for very short chains. mean_petal_width &lt;- round(mean(iris$Petal.Width), 2) But it gets extremely confusing for long chains: # do not ever do this!! data &lt;- rename( spread( summarise( group_by( separate( gather( tibble( id = 1:10, A1 = rnorm(10, 0), A2 = rnorm(10, 1), B1 = rnorm(10, 2), B2 = rnorm(10,3)), variable, value, A1:B2), variable, c(&quot;var&quot;, &quot;var_n&quot;), sep = 1), id, var), mean = mean(value)), var, mean), A_mean = A, B_mean = B) The pipe lets you “pipe” the result of each function into the next function, allowing you to put your code in a logical order without creating too many extra objects. # calculate mean of A and B variables for each participant data &lt;- tibble( id = 1:10, A1 = rnorm(10, 0), A2 = rnorm(10, 1), B1 = rnorm(10, 2), B2 = rnorm(10,3) ) %&gt;% gather(variable, value, A1:B2) %&gt;% separate(variable, c(&quot;var&quot;, &quot;var_n&quot;), sep=1) %&gt;% group_by(id, var) %&gt;% summarise(mean = mean(value)) %&gt;% spread(var, mean) %&gt;% rename(A_mean = A, B_mean = B) You can read this code from top to bottom as follows: Make a tibble called data with id of 1 to 10, A1 of 10 random numbers from a normal distribution, A2 of 10 random numbers from a normal distribution, B1 of 10 random numbers from a normal distribution, B2 of 10 random numbers from a normal distribution; and then Gather to create variable and value column from columns A_1 to B_2; and then Separate the column variable into 2 new columns called varand var_n, separate at character 1; and then Group by columns id and var; and then Summarise and new column called mean as the mean of the value column for each group; and then Spread to make new columns with the key names in var and values in mean; and then Rename to make columns called A_mean (old A) and B_mean (old B) You can make intermediate objects whenever you need to break up your code because it’s getting too complicated or you need to debug something. You can debug a pipe by highlighting from the beginning to just before the pipe you want to stop at. Try this by highlighting from data &lt;- to the end of the separate function and typing cmd-return. What does data look like now? Chain all the steps above using pipes. ocean &lt;- read_csv(&quot;https://psyteachr.github.io/msc-data-skills/data/personality.csv&quot;) %&gt;% gather(&quot;question&quot;, &quot;score&quot;, Op1:Ex9) %&gt;% separate(question, c(&quot;domain&quot;, &quot;qnumber&quot;), sep = 2) %&gt;% unite(&quot;domain_n&quot;, domain, qnumber, sep = &quot;_Q&quot;) %&gt;% spread(domain_n, score) ## Parsed with column specification: ## cols( ## .default = col_double(), ## date = col_date(format = &quot;&quot;) ## ) ## See spec(...) for full column specifications. 4.7 More Complex Example 4.7.1 Load Data Get data on infant mortality rates from the CSV file infmort.csv in the directory data. infmort &lt;- read_csv(&quot;data/infmort.csv&quot;) ## Parsed with column specification: ## cols( ## Country = col_character(), ## Year = col_double(), ## `Infant mortality rate (probability of dying between birth and age 1 per 1000 live births)` = col_character() ## ) glimpse(infmort) ## Observations: 5,044 ## Variables: 3 ## $ Country &lt;chr&gt; … ## $ Year &lt;dbl&gt; … ## $ `Infant mortality rate (probability of dying between birth and age 1 per 1000 live births)` &lt;chr&gt; … Get data on maternal mortality from from the excel file matmort.xls in the directory data matmort &lt;- read_xls(&quot;data/matmort.xls&quot;) glimpse(matmort) ## Observations: 181 ## Variables: 4 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argentin… ## $ `1990` &lt;chr&gt; &quot;1 340 [ 878 - 1 950]&quot;, &quot;71 [ 58 - 88]&quot;, &quot;216 [ 141 - … ## $ `2000` &lt;chr&gt; &quot;1 100 [ 745 - 1 570]&quot;, &quot;43 [ 33 - 56]&quot;, &quot;170 [ 118 - … ## $ `2015` &lt;chr&gt; &quot;396 [ 253 - 620]&quot;, &quot;29 [ 16 - 46]&quot;, &quot;140 [ 82 - 244]… Get data on country codes from https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv ccodes &lt;- read_csv(&quot;https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv&quot;) ## Parsed with column specification: ## cols( ## name = col_character(), ## `alpha-2` = col_character(), ## `alpha-3` = col_character(), ## `country-code` = col_character(), ## `iso_3166-2` = col_character(), ## region = col_character(), ## `sub-region` = col_character(), ## `intermediate-region` = col_character(), ## `region-code` = col_character(), ## `sub-region-code` = col_character(), ## `intermediate-region-code` = col_character() ## ) glimpse(ccodes) ## Observations: 249 ## Variables: 11 ## $ name &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Åland Islands&quot;, &quot;Alba… ## $ `alpha-2` &lt;chr&gt; &quot;AF&quot;, &quot;AX&quot;, &quot;AL&quot;, &quot;DZ&quot;, &quot;AS&quot;, &quot;AD&quot;, &quot;… ## $ `alpha-3` &lt;chr&gt; &quot;AFG&quot;, &quot;ALA&quot;, &quot;ALB&quot;, &quot;DZA&quot;, &quot;ASM&quot;, &quot;A… ## $ `country-code` &lt;chr&gt; &quot;004&quot;, &quot;248&quot;, &quot;008&quot;, &quot;012&quot;, &quot;016&quot;, &quot;0… ## $ `iso_3166-2` &lt;chr&gt; &quot;ISO 3166-2:AF&quot;, &quot;ISO 3166-2:AX&quot;, &quot;IS… ## $ region &lt;chr&gt; &quot;Asia&quot;, &quot;Europe&quot;, &quot;Europe&quot;, &quot;Africa&quot;,… ## $ `sub-region` &lt;chr&gt; &quot;Southern Asia&quot;, &quot;Northern Europe&quot;, &quot;… ## $ `intermediate-region` &lt;chr&gt; NA, NA, NA, NA, NA, NA, &quot;Middle Afric… ## $ `region-code` &lt;chr&gt; &quot;142&quot;, &quot;150&quot;, &quot;150&quot;, &quot;002&quot;, &quot;009&quot;, &quot;1… ## $ `sub-region-code` &lt;chr&gt; &quot;034&quot;, &quot;154&quot;, &quot;039&quot;, &quot;015&quot;, &quot;061&quot;, &quot;0… ## $ `intermediate-region-code` &lt;chr&gt; NA, NA, NA, NA, NA, NA, &quot;017&quot;, &quot;029&quot;,… 4.7.2 Wide to Long matmort is in wide format, with a separate column for each year. Change it to long format, with a row for each County/Year observation. This example is complicated because the column names to gather are numbers. If the column names are non-standard (e.g., have spaces, start with numbers, or have special characters), you can enclose them in backticks (`) like the example below. matmort_long &lt;- matmort %&gt;% gather(&quot;Year&quot;, &quot;stats&quot;, `1990`:`2015`) glimpse(matmort_long) ## Observations: 543 ## Variables: 3 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argentin… ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, … ## $ stats &lt;chr&gt; &quot;1 340 [ 878 - 1 950]&quot;, &quot;71 [ 58 - 88]&quot;, &quot;216 [ 141 - … 4.7.3 One Piece of Data per Column The data in the stats column is in an unusual format with some sort of confidence interval in brackets and lots of extra spaces. We don’t need any of the spaces, so first we’ll remove them with mutate. The separate function will separate your data on anything that is not a number or letter, so try it first without specifying the sep argument. The into argument is a list of the new column names. matmort_split &lt;- matmort_long %&gt;% mutate(stats = gsub(&quot; &quot;, &quot;&quot;, stats)) %&gt;% separate(stats, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;)) ## Warning: Expected 3 pieces. Additional pieces discarded in 543 rows [1, 2, ## 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]. glimpse(matmort_split) ## Observations: 543 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argentin… ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, … ## $ rate &lt;chr&gt; &quot;1340&quot;, &quot;71&quot;, &quot;216&quot;, &quot;1160&quot;, &quot;72&quot;, &quot;58&quot;, &quot;8&quot;, &quot;8&quot;, &quot;64&quot;,… ## $ ci_low &lt;chr&gt; &quot;878&quot;, &quot;58&quot;, &quot;141&quot;, &quot;627&quot;, &quot;64&quot;, &quot;51&quot;, &quot;7&quot;, &quot;7&quot;, &quot;56&quot;, &quot;… ## $ ci_hi &lt;chr&gt; &quot;1950&quot;, &quot;88&quot;, &quot;327&quot;, &quot;2020&quot;, &quot;80&quot;, &quot;65&quot;, &quot;9&quot;, &quot;10&quot;, &quot;74&quot;… The gsub(pattern, replacement, x) function is a flexible way to do search and replace. The example above replaces all occurances of the pattern &quot; &quot; (a space), with the replacement &quot;&quot; (nothing), in the string x (the stats column). Use sub() instead if you only want to replace the first occurance of a pattern. We only used a simple pattern here, but you can use more complicated regex patterns to replace, for example, all even numbers (e.g., gsub(“[:02468:]”, &quot;“,”id = 123456“)) or all occurances of the word colour in US or UK spelling (e.g., gsub(”colo(u)?r“,”**“,”replace color, colour, or colours, but not collors&quot;)). 4.7.3.1 Handle spare columns with extra The previous example should have given you an error warning about “Too many values at 543 locations”. This is because separate splits the column at the brackets and dashes, so the text 100[90-110] would split into four values c(“100”, “90”, “110”, &quot;“), but we only specified 3 new columns. The fourth value is always empty (just the part after the last bracket), so we are happy to drop it, but separate generates a warning so you don’t do that accidentally. You can turn off the warning by adding the extra argument and setting it to “drop”. Look at the help for ??tidyr::separate to see what the other options do. matmort_split &lt;- matmort_long %&gt;% mutate(stats = gsub(&quot; &quot;, &quot;&quot;, stats)) %&gt;% separate(stats, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;) glimpse(matmort_split) ## Observations: 543 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argentin… ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, … ## $ rate &lt;chr&gt; &quot;1340&quot;, &quot;71&quot;, &quot;216&quot;, &quot;1160&quot;, &quot;72&quot;, &quot;58&quot;, &quot;8&quot;, &quot;8&quot;, &quot;64&quot;,… ## $ ci_low &lt;chr&gt; &quot;878&quot;, &quot;58&quot;, &quot;141&quot;, &quot;627&quot;, &quot;64&quot;, &quot;51&quot;, &quot;7&quot;, &quot;7&quot;, &quot;56&quot;, &quot;… ## $ ci_hi &lt;chr&gt; &quot;1950&quot;, &quot;88&quot;, &quot;327&quot;, &quot;2020&quot;, &quot;80&quot;, &quot;65&quot;, &quot;9&quot;, &quot;10&quot;, &quot;74&quot;… 4.7.3.2 Set delimiters with sep Now do the same with infmort. It’s already in long format, so you don’t need to use gather, but the third column has a crazy long name, so we can just refer to it by its column number (3). infmort_split &lt;- infmort %&gt;% separate(3, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;) glimpse(infmort_split) ## Observations: 5,044 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanista… ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 20… ## $ rate &lt;chr&gt; &quot;66&quot;, &quot;68&quot;, &quot;69&quot;, &quot;71&quot;, &quot;73&quot;, &quot;75&quot;, &quot;76&quot;, &quot;78&quot;, &quot;80&quot;, &quot;8… ## $ ci_low &lt;chr&gt; &quot;3&quot;, &quot;1&quot;, &quot;9&quot;, &quot;7&quot;, &quot;4&quot;, &quot;1&quot;, &quot;8&quot;, &quot;6&quot;, &quot;4&quot;, &quot;3&quot;, &quot;4&quot;, &quot;… ## $ ci_hi &lt;chr&gt; &quot;52&quot;, &quot;55&quot;, &quot;58&quot;, &quot;61&quot;, &quot;64&quot;, &quot;66&quot;, &quot;69&quot;, &quot;71&quot;, &quot;73&quot;, &quot;7… Wait, that didn’t work at all! It split the column on spaces, brackets, and full stops. We just want to split on the spaces, brackets and dashes. So we need to manually set sep to what the delimiters are. Also, once there are more than a few arguments specified for a function, it’s easier to read them if you put one argument on each line. {#regex} You can use regular expressions to separate complex columns. Here, we want to separate on dashes and brackets. You can separate on a list of delimiters by putting them in parentheses, separated by “|”. It’s a little more complicated because brackets have a special meaning in regex, so you need to “escape” the left one with two backslashes “\\”. infmort_split &lt;- infmort %&gt;% separate( col = 3, into = c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, sep = &quot;(\\\\[|-|])&quot; ) glimpse(infmort_split) ## Observations: 5,044 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanista… ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 20… ## $ rate &lt;chr&gt; &quot;66.3 &quot;, &quot;68.1 &quot;, &quot;69.9 &quot;, &quot;71.7 &quot;, &quot;73.4 &quot;, &quot;75.1 &quot;, &quot;7… ## $ ci_low &lt;chr&gt; &quot;52.7&quot;, &quot;55.7&quot;, &quot;58.7&quot;, &quot;61.6&quot;, &quot;64.4&quot;, &quot;66.9&quot;, &quot;69.0&quot;, … ## $ ci_hi &lt;chr&gt; &quot;83.9&quot;, &quot;83.6&quot;, &quot;83.5&quot;, &quot;83.7&quot;, &quot;84.2&quot;, &quot;85.1&quot;, &quot;86.1&quot;, … 4.7.3.3 Fix data types with convert That’s better. Notice the next to Year, rate, ci_low and ci_hi. That means these columns hold characters (like words), not numbers or integers. This can cause problems when you try to do thigs like average the numbers (you can’t average words), so we can fix it by adding the argument convert and setting it to TRUE. infmort_split &lt;- infmort %&gt;% separate(3, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, sep = &quot;(\\\\[|-|])&quot;, convert = TRUE) glimpse(infmort_split) ## Observations: 5,044 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanista… ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 20… ## $ rate &lt;dbl&gt; 66.3, 68.1, 69.9, 71.7, 73.4, 75.1, 76.8, 78.6, 80.4, 82… ## $ ci_low &lt;dbl&gt; 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, 75… ## $ ci_hi &lt;dbl&gt; 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, 90… Do the same for matmort. matmort_split &lt;- matmort_long %&gt;% mutate(stats = gsub(&quot; &quot;, &quot;&quot;, stats)) %&gt;% separate(stats, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, convert = TRUE) glimpse(matmort_split) ## Observations: 543 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argentin… ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, … ## $ rate &lt;int&gt; 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58, … ## $ ci_low &lt;int&gt; 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, 28… ## $ ci_hi &lt;int&gt; 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 72,… 4.7.4 All in one step We can chain all the steps above together, since we don’t need those intermediate dataframes. infmort &lt;- read_csv(&quot;data/infmort.csv&quot;) %&gt;% separate( 3, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, sep = &quot;(\\\\[|-|])&quot;, convert = TRUE ) ## Parsed with column specification: ## cols( ## Country = col_character(), ## Year = col_double(), ## `Infant mortality rate (probability of dying between birth and age 1 per 1000 live births)` = col_character() ## ) matmort &lt;- read_xls(&quot;data/matmort.xls&quot;) %&gt;% gather(&quot;Year&quot;, &quot;stats&quot;, `1990`:`2015`) %&gt;% mutate(stats = gsub(&quot; &quot;, &quot;&quot;, stats)) %&gt;% separate( stats, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, convert = TRUE ) glimpse(matmort) glimpse(infmort) ## Observations: 543 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argentin… ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, … ## $ rate &lt;int&gt; 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58, … ## $ ci_low &lt;int&gt; 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, 28… ## $ ci_hi &lt;int&gt; 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 72,… ## Observations: 5,044 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanista… ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 20… ## $ rate &lt;dbl&gt; 66.3, 68.1, 69.9, 71.7, 73.4, 75.1, 76.8, 78.6, 80.4, 82… ## $ ci_low &lt;dbl&gt; 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, 75… ## $ ci_hi &lt;dbl&gt; 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, 90… 4.7.5 Columns by Year Spread out the infant mortality rate by year. infmort_wide &lt;- infmort %&gt;% spread(Year, rate) glimpse(infmort_wide) ## Observations: 4,934 ## Variables: 29 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanista… ## $ ci_low &lt;dbl&gt; 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, 75… ## $ ci_hi &lt;dbl&gt; 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, 90… ## $ `1990` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `1991` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `1992` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `1993` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `1994` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `1995` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `1996` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `1997` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `1998` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `1999` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `2000` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `2001` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ `2002` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 91.2… ## $ `2003` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 89, NA, … ## $ `2004` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 86.7, NA, NA… ## $ `2005` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 84.4, NA, NA, NA… ## $ `2006` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 82.3, NA, NA, NA, NA… ## $ `2007` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 80.4, NA, NA, NA, NA, NA… ## $ `2008` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 78.6, NA, NA, NA, NA, NA, NA… ## $ `2009` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 76.8, NA, NA, NA, NA, NA, NA, NA… ## $ `2010` &lt;dbl&gt; NA, NA, NA, NA, NA, 75.1, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `2011` &lt;dbl&gt; NA, NA, NA, NA, 73.4, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `2012` &lt;dbl&gt; NA, NA, NA, 71.7, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `2013` &lt;dbl&gt; NA, NA, 69.9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `2014` &lt;dbl&gt; NA, 68.1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `2015` &lt;dbl&gt; 66.3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… Nope, that didn’t work at all, but it’s a really common mistake when spreading data. This is because spread matches on all the remaining columns, so Afghanistan with ci_low of 52.7 is treated as a different observation than Afghanistan with ci_low of 55.7. We can fix this by merging the rate, ci_low and ci_hi columns back together. 4.7.6 Merge Columns Merge the rate and confidence intervals into one column. infmort_united &lt;- infmort %&gt;% unite(rate_ci, rate, ci_low, ci_hi) glimpse(infmort_united) ## Observations: 5,044 ## Variables: 3 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanista… ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 20… ## $ rate_ci &lt;chr&gt; &quot;66.3_52.7_83.9&quot;, &quot;68.1_55.7_83.6&quot;, &quot;69.9_58.7_83.5&quot;, &quot;7… 4.7.6.1 Control separation with sep unite() separates merged names with an underscore by default. Set the sep argument if you want to change that. infmort_united &lt;- infmort %&gt;% unite(rate_ci, rate, ci_low, ci_hi, sep = &quot;, &quot;) glimpse(infmort_united) ## Observations: 5,044 ## Variables: 3 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanista… ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 20… ## $ rate_ci &lt;chr&gt; &quot;66.3, 52.7, 83.9&quot;, &quot;68.1, 55.7, 83.6&quot;, &quot;69.9, 58.7, 83.… What if you want to put it back into the format “rate [ci_low - ci_hi]”? Then, mutate and paste are a better choice than unite, but you have to get rid of the rate, ci_low and ci_hi columns with select. You’ll learn more about these function in the Data Manipulation lesson. infmort_united &lt;- infmort %&gt;% mutate(rate_ci = paste0(rate, &quot; [&quot;, ci_low, &quot; - &quot;, ci_hi, &quot;]&quot;)) glimpse(infmort_united) ## Observations: 5,044 ## Variables: 6 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanista… ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 20… ## $ rate &lt;dbl&gt; 66.3, 68.1, 69.9, 71.7, 73.4, 75.1, 76.8, 78.6, 80.4, 82… ## $ ci_low &lt;dbl&gt; 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, 75… ## $ ci_hi &lt;dbl&gt; 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, 90… ## $ rate_ci &lt;chr&gt; &quot;66.3 [52.7 - 83.9]&quot;, &quot;68.1 [55.7 - 83.6]&quot;, &quot;69.9 [58.7 … Now let’s try spreading on year again. Notice here we’re uniting columns rate:ci_hi, instead of rate, ci_low, ci_hi. The colon just says to select all the columns between the first and last named ones. Check the help documentation for ??tidyr::unite and ??tidyr::select to see other ways to select columns. infmort_wide &lt;- infmort %&gt;% unite(rate_ci, rate:ci_hi, sep = &quot;, &quot;) %&gt;% spread(Year, rate_ci) glimpse(infmort_wide) ## Observations: 194 ## Variables: 27 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Andorra&quot;, &quot;Angola&quot;… ## $ `1990` &lt;chr&gt; &quot;122.5, 111.6, 135.5&quot;, &quot;35.1, 31.3, 39.2&quot;, &quot;39.7, 37.1, … ## $ `1991` &lt;chr&gt; &quot;118.3, 108, 129.9&quot;, &quot;33.7, 30.2, 37.6&quot;, &quot;38.8, 36.1, 41… ## $ `1992` &lt;chr&gt; &quot;114.4, 104.6, 125.2&quot;, &quot;32.5, 29.2, 36.2&quot;, &quot;38.1, 35.4, … ## $ `1993` &lt;chr&gt; &quot;110.9, 101.4, 120.9&quot;, &quot;31.4, 28.2, 34.9&quot;, &quot;37.5, 34.9, … ## $ `1994` &lt;chr&gt; &quot;107.7, 98.6, 117.2&quot;, &quot;30.3, 27.1, 33.8&quot;, &quot;36.9, 34.6, 3… ## $ `1995` &lt;chr&gt; &quot;105, 96.2, 114.1&quot;, &quot;29.1, 26, 32.7&quot;, &quot;36.3, 34.2, 38.4&quot;… ## $ `1996` &lt;chr&gt; &quot;102.7, 94.5, 111.3&quot;, &quot;27.9, 24.8, 31.5&quot;, &quot;35.7, 34, 37.… ## $ `1997` &lt;chr&gt; &quot;100.7, 92.9, 109.1&quot;, &quot;26.8, 23.6, 30.4&quot;, &quot;35.1, 33.8, 3… ## $ `1998` &lt;chr&gt; &quot;98.9, 91.4, 107.2&quot;, &quot;25.5, 22.4, 29.2&quot;, &quot;34.7, 33.7, 35… ## $ `1999` &lt;chr&gt; &quot;97.2, 89.9, 105.4&quot;, &quot;24.4, 21.2, 28.1&quot;, &quot;34.4, 33.5, 35… ## $ `2000` &lt;chr&gt; &quot;95.4, 88.2, 103.6&quot;, &quot;23.2, 20, 27&quot;, &quot;33.9, 33.2, 34.7&quot;,… ## $ `2001` &lt;chr&gt; &quot;93.4, 86.3, 101.6&quot;, &quot;22.1, 18.8, 26&quot;, &quot;33.3, 32.7, 34&quot;,… ## $ `2002` &lt;chr&gt; &quot;91.2, 84.3, 99.3&quot;, &quot;21, 17.6, 25.1&quot;, &quot;32.4, 31.8, 33&quot;, … ## $ `2003` &lt;chr&gt; &quot;89, 82.1, 97&quot;, &quot;20, 16.5, 24.3&quot;, &quot;31.3, 30.7, 31.9&quot;, &quot;3… ## $ `2004` &lt;chr&gt; &quot;86.7, 79.9, 94.8&quot;, &quot;19.1, 15.4, 23.8&quot;, &quot;30.1, 29.5, 30.… ## $ `2005` &lt;chr&gt; &quot;84.4, 77.7, 92.6&quot;, &quot;18.3, 14.2, 23.4&quot;, &quot;28.8, 28.3, 29.… ## $ `2006` &lt;chr&gt; &quot;82.3, 75.5, 90.7&quot;, &quot;17.4, 13.2, 23.1&quot;, &quot;27.6, 27, 28.1&quot;… ## $ `2007` &lt;chr&gt; &quot;80.4, 73.4, 88.9&quot;, &quot;16.7, 12.1, 22.9&quot;, &quot;26.4, 25.9, 26.… ## $ `2008` &lt;chr&gt; &quot;78.6, 71.2, 87.3&quot;, &quot;16, 11.2, 22.7&quot;, &quot;25.3, 24.8, 25.7&quot;… ## $ `2009` &lt;chr&gt; &quot;76.8, 69, 86.1&quot;, &quot;15.4, 10.5, 22.6&quot;, &quot;24.3, 23.8, 24.7&quot;… ## $ `2010` &lt;chr&gt; &quot;75.1, 66.9, 85.1&quot;, &quot;14.8, 9.8, 22.4&quot;, &quot;23.5, 23, 23.9&quot;,… ## $ `2011` &lt;chr&gt; &quot;73.4, 64.4, 84.2&quot;, &quot;14.3, 9.1, 22.3&quot;, &quot;22.8, 22.4, 23.3… ## $ `2012` &lt;chr&gt; &quot;71.7, 61.6, 83.7&quot;, &quot;13.8, 8.5, 22.2&quot;, &quot;22.4, 22, 22.9&quot;,… ## $ `2013` &lt;chr&gt; &quot;69.9, 58.7, 83.5&quot;, &quot;13.3, 7.9, 22.1&quot;, &quot;22.1, 21.7, 22.7… ## $ `2014` &lt;chr&gt; &quot;68.1, 55.7, 83.6&quot;, &quot;12.9, 7.5, 22.1&quot;, &quot;22, 21.3, 22.7&quot;,… ## $ `2015` &lt;chr&gt; &quot;66.3, 52.7, 83.9&quot;, &quot;12.5, 7, 22.2&quot;, &quot;21.9, 20.8, 23&quot;, &quot;… 4.8 Quiz The following data table is called quiz_data. id c ondition version p et score 1 A 1 cat 0.023 1 A 2 cat 0.637 1 B 1 cat 1.115 1 B 2 cat 1.180 2 A 1 dog -0.480 2 A 2 dog 0.393 2 B 1 dog 0.426 2 B 2 dog -0.847 How do you get quiz_data into the following format? id version pet A B 1 1 cat 0.0231929 1.1154481 1 2 cat 0.6373390 1.1804001 2 1 dog -0.4801690 0.4256315 2 2 dog 0.3930236 -0.8467813 separate(quiz_data, condition, score) gather(quiz_data, condition:score) spread(quiz_data, condition, score) unite(quiz_data, condition:score) How do you get quiz_data into the following format? id cversion pet score 1 A_1 cat 0.0231929 1 A_2 cat 0.6373390 1 B_1 cat 1.1154481 1 B_2 cat 1.1804001 2 A_1 dog -0.4801690 2 A_2 dog 0.3930236 2 B_1 dog 0.4256315 2 B_2 dog -0.8467813 separate(quiz_data, cversion, condition, version) spread(quiz_data, condition:version) gather(quiz_data, cversion, condition:version) unite(quiz_data, cversion, condition, version) Put the built-in dataset iris into the following format. Species feature dimension value setosa Sepal Length 5.1 setosa Sepal Length 4.9 setosa Sepal Length 4.7 setosa Sepal Length 4.6 setosa Sepal Length 5.0 setosa Sepal Length 5.4 iris %&gt;% gather(var, value, Sepal.Length:Petal.Width) %&gt;% separate(var, into = c(&quot;feature&quot;, &quot;dimension&quot;)) Re-write the following code using pipes. Assign the resulting data table to a variable called data. # make a data table with 5 subjects providing 2 scores (A and B) in each of 2 conditions data_original &lt;- tibble( id = c(1:5, 1:5), condition = rep(1:2, each = 5), A = rnorm(10), B = rnorm(10) ) # gather columns A and B into &quot;score_type&quot; and &quot;score&quot; columns data_gathered &lt;- gather(data_original, score_type, score, A:B) # unite the score_type and condition columns into a column called &quot;cell&quot; data_united &lt;- unite(data_gathered, cell, score_type, condition, sep = &quot;&quot;) # spread the score column into cells data_spread &lt;- spread(data_united, cell, score) data &lt;- tibble( id = c(1:5, 1:5), condition = rep(1:2, each = 5), A = rnorm(10), B = rnorm(10) ) %&gt;% gather(score_type, score, A:B) %&gt;% unite(cell, score_type, condition, sep = &quot;&quot;) %&gt;% spread(cell, score) 4.9 Exercises Download the exercises. See the answers only after you’ve attempted all the questions. "],
["dplyr.html", "Chapter 5 Data Wrangling 5.1 Learning Objectives 5.2 Resources 5.3 Setup 5.4 The disgust dataset 5.5 Six main dplyr verbs 5.6 Additional dplyr one-table verbs 5.7 Window functions 5.8 Exercises", " Chapter 5 Data Wrangling 5.1 Learning Objectives 5.1.1 Basic Be able to use the 6 main dplyr one-table verbs: select() filter() arrange() mutate() summarise() group_by() 5.1.2 Intermediate Also know these additional one-table verbs: rename() distinct() count() slice() pull() 5.1.3 Advanced Fine control of select() operations Use window functions 5.2 Resources Chapter 5: Data Transformation in R for Data Science Data transformation cheat sheet Lecture slides on dplyr one-table verbs Chapter 16: Date and times in R for Data Science 5.3 Setup You’ll need the following packages. # libraries needed for these examples library(tidyverse) library(lubridate) 5.4 The disgust dataset These examples will use data from disgust.csv, which contains data from the Three Domain Disgust Scale. Each participant is identified by a unique user_id and each questionnaire completion has a unique id. disgust &lt;- read_csv(&quot;https://psyteachr.github.io/msc-data-skills/data/disgust.csv&quot;) Questionnaire Instructions: The following items describe a variety of concepts. Please rate how disgusting you find the concepts described in the items, where 0 means that you do not find the concept disgusting at all, and 6 means that you find the concept extremely disgusting. colname question moral1 Shoplifting a candy bar from a convenience store moral2 Stealing from a neighbor moral3 A student cheating to get good grades moral4 Deceiving a friend moral5 Forging someone’s signature on a legal document moral6 Cutting to the front of a line to purchase the last few tickets to a show moral7 Intentionally lying during a business transaction sexual1 Hearing two strangers having sex sexual2 Performing oral sex sexual3 Watching a pornographic video sexual4 Finding out that someone you don’t like has sexual fantasies about you sexual5 Bringing someone you just met back to your room to have sex sexual6 A stranger of the opposite sex intentionally rubbing your thigh in an elevator sexual7 Having anal sex with someone of the opposite sex pathogen1 Stepping on dog poop pathogen2 Sitting next to someone who has red sores on their arm pathogen3 Shaking hands with a stranger who has sweaty palms pathogen4 Seeing some mold on old leftovers in your refrigerator pathogen5 Standing close to a person who has body odor pathogen6 Seeing a cockroach run across the floor pathogen7 Accidentally touching a person’s bloody cut 5.5 Six main dplyr verbs Most of the data wrangling you’ll want to do with psychological data will involve the tidyr verbs you learned in Chapter 3 and the six main dplyr verbs: select, filter, arrange, mutate, summarise, and group_by. 5.5.1 select() Select columns by name or number. You can select each column individually, separated by commas (e.g., col1, col2). You can also select all columns between two columns by separating them with a colon (e.g., start_col:end_col). moral &lt;- disgust %&gt;% select(user_id, moral1:moral7) names(moral) ## [1] &quot;user_id&quot; &quot;moral1&quot; &quot;moral2&quot; &quot;moral3&quot; &quot;moral4&quot; &quot;moral5&quot; &quot;moral6&quot; ## [8] &quot;moral7&quot; You can select columns by number, which is useful when the column names are long or complicated. sexual &lt;- disgust %&gt;% select(2, 11:17) names(sexual) ## [1] &quot;user_id&quot; &quot;sexual1&quot; &quot;sexual2&quot; &quot;sexual3&quot; &quot;sexual4&quot; &quot;sexual5&quot; &quot;sexual6&quot; ## [8] &quot;sexual7&quot; You can use a minus symbol to unselect columns, leaving all of the other columns. If you want to exclude a span of columns, put parentheses around the span first (e.g., -(moral1:moral7), not -moral1:moral7). pathogen &lt;- disgust %&gt;% select(-id, -date, -(moral1:sexual7)) names(pathogen) ## [1] &quot;user_id&quot; &quot;pathogen1&quot; &quot;pathogen2&quot; &quot;pathogen3&quot; &quot;pathogen4&quot; &quot;pathogen5&quot; ## [7] &quot;pathogen6&quot; &quot;pathogen7&quot; You can select columns based on criteria about the column names.{#select_helpers} 5.5.1.1 starts_with() Select columns that start with a character string. u &lt;- disgust %&gt;% select(starts_with(&quot;u&quot;)) names(u) ## [1] &quot;user_id&quot; 5.5.1.2 ends_with() Select columns that end with a character string. firstq &lt;- disgust %&gt;% select(ends_with(&quot;1&quot;)) names(firstq) ## [1] &quot;moral1&quot; &quot;sexual1&quot; &quot;pathogen1&quot; 5.5.1.3 contains() Select columns that contain a character string. pathogen &lt;- disgust %&gt;% select(contains(&quot;pathogen&quot;)) names(pathogen) ## [1] &quot;pathogen1&quot; &quot;pathogen2&quot; &quot;pathogen3&quot; &quot;pathogen4&quot; &quot;pathogen5&quot; &quot;pathogen6&quot; ## [7] &quot;pathogen7&quot; 5.5.1.4 num_range() Select columns with a name that matches the pattern prefix. moral2_4 &lt;- disgust %&gt;% select(num_range(&quot;moral&quot;, 2:4)) names(moral2_4) ## [1] &quot;moral2&quot; &quot;moral3&quot; &quot;moral4&quot; Use width to set the number of digits with leading zeros. For example, num_range(‘var_’, 8:10, width=2) selects columns var_08, var_09, and var_10. 5.5.2 filter() Select rows by matching column criteria. Select all rows where the user_id is 1 (that’s Lisa). disgust %&gt;% filter(user_id == 1) ## # A tibble: 1 x 24 ## id user_id date moral1 moral2 moral3 moral4 moral5 moral6 moral7 ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2008-07-10 2 2 1 2 1 1 1 ## # … with 14 more variables: sexual1 &lt;dbl&gt;, sexual2 &lt;dbl&gt;, sexual3 &lt;dbl&gt;, ## # sexual4 &lt;dbl&gt;, sexual5 &lt;dbl&gt;, sexual6 &lt;dbl&gt;, sexual7 &lt;dbl&gt;, ## # pathogen1 &lt;dbl&gt;, pathogen2 &lt;dbl&gt;, pathogen3 &lt;dbl&gt;, pathogen4 &lt;dbl&gt;, ## # pathogen5 &lt;dbl&gt;, pathogen6 &lt;dbl&gt;, pathogen7 &lt;dbl&gt; Remember to use == and not = to check if two things are equivalent. A single = assigns the righthand value to the lefthand variable and (usually) evaluates to TRUE. You can select on multiple criteria by separating them with commas. amoral &lt;- disgust %&gt;% filter( moral1 == 0, moral2 == 0, moral3 == 0, moral4 == 0, moral5 == 0, moral6 == 0, moral7 == 0 ) You can use the symbols &amp;, |, and ! to mean “and”, “or”, and “not”. You can also use other operators to make equations. # everyone who chose either 0 or 7 for question moral1 moral_extremes &lt;- disgust %&gt;% filter(moral1 == 0 | moral1 == 7) # everyone who chose the same answer for all moral questions moral_consistent &lt;- disgust %&gt;% filter( moral2 == moral1 &amp; moral3 == moral1 &amp; moral4 == moral1 &amp; moral5 == moral1 &amp; moral6 == moral1 &amp; moral7 == moral1 ) # everyone who did not answer 7 for all 7 moral questions moral_no_ceiling &lt;- disgust %&gt;% filter(moral1+moral2+moral3+moral4+moral5+moral6+moral7 != 7*7) Sometimes you need to exclude some participant IDs for reasons that can’t be described in code. the %in% operator is useful here for testing if a column value is in a list. Surround the equation with parentheses and put ! in front to test that a value is not in the list. no_researchers &lt;- disgust %&gt;% filter(!(user_id %in% c(1,2))) 5.5.2.1 Dates You can use the lubridate package to work with dates. For example, you can use the year() function to return just the year from the date column and then select only data collected in 2010. disgust2010 &lt;- disgust %&gt;% filter(year(date) == 2010) Or select data from at least 5 years ago. You can use the range function to check the minimum and maxiumum dates in the resulting dataset. disgust_5ago &lt;- disgust %&gt;% filter(date &lt; today() - dyears(5)) range(disgust_5ago$date) ## [1] &quot;2008-07-10&quot; &quot;2014-06-23&quot; 5.5.3 arrange() Sort your dataset using arrange(). disgust_order &lt;- disgust %&gt;% arrange(id) head(disgust_order) ## # A tibble: 6 x 24 ## id user_id date moral1 moral2 moral3 moral4 moral5 moral6 moral7 ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2008-07-10 2 2 1 2 1 1 1 ## 2 3 155324 2008-07-11 2 4 3 5 2 1 4 ## 3 4 155366 2008-07-12 6 6 6 3 6 6 6 ## 4 5 155370 2008-07-12 6 6 4 6 6 6 6 ## 5 6 155386 2008-07-12 2 4 0 4 0 0 0 ## 6 7 155409 2008-07-12 4 5 5 4 5 1 5 ## # … with 14 more variables: sexual1 &lt;dbl&gt;, sexual2 &lt;dbl&gt;, sexual3 &lt;dbl&gt;, ## # sexual4 &lt;dbl&gt;, sexual5 &lt;dbl&gt;, sexual6 &lt;dbl&gt;, sexual7 &lt;dbl&gt;, ## # pathogen1 &lt;dbl&gt;, pathogen2 &lt;dbl&gt;, pathogen3 &lt;dbl&gt;, pathogen4 &lt;dbl&gt;, ## # pathogen5 &lt;dbl&gt;, pathogen6 &lt;dbl&gt;, pathogen7 &lt;dbl&gt; Reverse the order using desc() disgust_order &lt;- disgust %&gt;% arrange(desc(id)) head(disgust_order) ## # A tibble: 6 x 24 ## id user_id date moral1 moral2 moral3 moral4 moral5 moral6 moral7 ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 39456 356866 2017-08-21 1 1 1 1 1 1 1 ## 2 39447 128727 2017-08-13 2 4 1 2 2 5 3 ## 3 39371 152955 2017-06-13 6 6 3 6 6 6 6 ## 4 39342 48303 2017-05-22 4 5 4 4 6 4 5 ## 5 39159 151633 2017-04-04 4 5 6 5 3 6 2 ## 6 38942 370464 2017-02-01 1 5 0 6 5 5 5 ## # … with 14 more variables: sexual1 &lt;dbl&gt;, sexual2 &lt;dbl&gt;, sexual3 &lt;dbl&gt;, ## # sexual4 &lt;dbl&gt;, sexual5 &lt;dbl&gt;, sexual6 &lt;dbl&gt;, sexual7 &lt;dbl&gt;, ## # pathogen1 &lt;dbl&gt;, pathogen2 &lt;dbl&gt;, pathogen3 &lt;dbl&gt;, pathogen4 &lt;dbl&gt;, ## # pathogen5 &lt;dbl&gt;, pathogen6 &lt;dbl&gt;, pathogen7 &lt;dbl&gt; 5.5.4 mutate() Add new columns. This is one of the most useful functions in the tidyverse. Refer to other columns by their names (unquoted). You can add more than one column, just separate the columns with a comma. Once you make a new column, you can use it in further column definitions e.g., total below). disgust_total &lt;- disgust %&gt;% mutate( pathogen = pathogen1 + pathogen2 + pathogen3 + pathogen4 + pathogen5 + pathogen6 + pathogen7, moral = moral1 + moral2 + moral3 + moral4 + moral5 + moral6 + moral7, sexual = sexual1 + sexual2 + sexual3 + sexual4 + sexual5 + sexual6 + sexual7, total = pathogen + moral + sexual, user_id = paste0(&quot;U&quot;, user_id) ) You can overwrite a column by giving a new column the same name as the old column. Make sure that you mean to do this and that you aren’t trying to use the old column value after you redefine it. 5.5.5 summarise() Create summary statistics for the dataset. Check the Data Wrangling Cheat Sheet or the Data Transformation Cheat Sheet for various summary functions. Some common ones are: mean(), sd(), n(), sum(), and quantile(). disgust_total %&gt;% summarise( n = n(), q25 = quantile(total, .25, na.rm = TRUE), q50 = quantile(total, .50, na.rm = TRUE), q75 = quantile(total, .75, na.rm = TRUE), avg_total = mean(total, na.rm = TRUE), sd_total = sd(total, na.rm = TRUE), min_total = min(total, na.rm = TRUE), max_total = max(total, na.rm = TRUE) ) ## # A tibble: 1 x 8 ## n q25 q50 q75 avg_total sd_total min_total max_total ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20000 59 71 83 70.7 18.2 0 126 5.5.6 group_by() Create subsets of the data. You can use this to create summaries, like the mean value for all of your experimental groups. Here, we’ll use mutate to create a new column called year, group by year, and calculate the average scores. disgust_total %&gt;% mutate(year = year(date)) %&gt;% group_by(year) %&gt;% summarise( n = n(), avg_total = mean(total, na.rm = TRUE), sd_total = sd(total, na.rm = TRUE), min_total = min(total, na.rm = TRUE), max_total = max(total, na.rm = TRUE) ) ## # A tibble: 10 x 6 ## year n avg_total sd_total min_total max_total ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2008 2578 70.3 18.5 0 126 ## 2 2009 2580 69.7 18.6 3 126 ## 3 2010 1514 70.6 18.9 6 126 ## 4 2011 6046 71.3 17.8 0 126 ## 5 2012 5938 70.4 18.4 0 126 ## 6 2013 1251 71.6 17.6 0 126 ## 7 2014 58 70.5 17.2 19 113 ## 8 2015 21 74.3 16.9 43 107 ## 9 2016 8 67.9 32.6 0 110 ## 10 2017 6 57.2 27.9 21 90 You can use filter after group_by. The following example returns the lowest total score from each year. disgust_total %&gt;% mutate(year = year(date)) %&gt;% select(user_id, year, total) %&gt;% group_by(year) %&gt;% filter(rank(total) == 1) %&gt;% arrange(year) ## # A tibble: 7 x 3 ## # Groups: year [7] ## user_id year total ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 U236585 2009 3 ## 2 U292359 2010 6 ## 3 U245384 2013 0 ## 4 U206293 2014 19 ## 5 U407089 2015 43 ## 6 U453237 2016 0 ## 7 U356866 2017 21 You can also use mutate after group_by. The following example calculates subject-mean-centered scores by grouping the scores by user_id and then subtracting the group-specific mean from each score. Note the use of gather to tidy the data into a long format first. disgust_smc &lt;- disgust %&gt;% gather(&quot;question&quot;, &quot;score&quot;, moral1:pathogen7) %&gt;% group_by(user_id) %&gt;% mutate(score_smc = score - mean(score, na.rm = TRUE)) 5.5.7 All Together A lot of what we did above would be easier if the data were tidy, so let’s do that first. Then we can use group_by to calculate the domain scores. It is good practice to use ungroup() after using group_by and summarise. Forgetting to ungroup the dataset won’t affect some further processing, but can really mess up other things. Then we can spread out the 3 domains, calculate the total score, remove any rows with a missing (NA) total, and calculate mean values by year. disgust_tidy &lt;- read_csv(&quot;data/disgust.csv&quot;) %&gt;% gather(&quot;question&quot;, &quot;score&quot;, moral1:pathogen7) %&gt;% separate(question, c(&quot;domain&quot;,&quot;q_num&quot;), sep = -1) %&gt;% group_by(id, user_id, date, domain) %&gt;% summarise(score = mean(score)) %&gt;% ungroup() ## Parsed with column specification: ## cols( ## .default = col_double(), ## date = col_date(format = &quot;&quot;) ## ) ## See spec(...) for full column specifications. disgust_tidy2 &lt;- disgust_tidy %&gt;% spread(domain, score) %&gt;% mutate( total = moral + sexual + pathogen, year = year(date) ) %&gt;% filter(!is.na(total)) %&gt;% arrange(user_id) disgust_tidy3 &lt;- disgust_tidy2 %&gt;% group_by(year) %&gt;% summarise( n = n(), avg_pathogen = mean(pathogen), avg_moral = mean(moral), avg_sexual = mean(sexual), first_user = first(user_id), last_user = last(user_id) ) 5.6 Additional dplyr one-table verbs Use the code examples below and the help pages to figure out what the following one-table verbs do. Most have pretty self-explanatory names. 5.6.1 rename() iris_underscore &lt;- iris %&gt;% rename(sepal_length = Sepal.Length, sepal_width = Sepal.Width, petal_length = Petal.Length, petal_width = Petal.Width) names(iris_underscore) ## [1] &quot;sepal_length&quot; &quot;sepal_width&quot; &quot;petal_length&quot; &quot;petal_width&quot; ## [5] &quot;Species&quot; Almost everyone gets confused at some point with rename() and tries to put the original names on the left and the new names on the right. Try it and see what the error message looks like. 5.6.2 distinct() # create a data table with duplicated values dupes &lt;- tibble( id = rep(1:5, 2), dv = rep(LETTERS[1:5], 2) ) distinct(dupes) ## # A tibble: 5 x 2 ## id dv ## &lt;int&gt; &lt;chr&gt; ## 1 1 A ## 2 2 B ## 3 3 C ## 4 4 D ## 5 5 E 5.6.3 count() # how many observations from each species are in iris? count(iris, Species) ## # A tibble: 3 x 2 ## Species n ## &lt;fct&gt; &lt;int&gt; ## 1 setosa 50 ## 2 versicolor 50 ## 3 virginica 50 5.6.4 slice() tibble( id = 1:10, condition = rep(c(&quot;A&quot;,&quot;B&quot;), 5) ) %&gt;% slice(3:6, 9) ## # A tibble: 5 x 2 ## id condition ## &lt;int&gt; &lt;chr&gt; ## 1 3 A ## 2 4 B ## 3 5 A ## 4 6 B ## 5 9 A 5.6.5 pull() iris %&gt;% group_by(Species) %&gt;% summarise_all(mean) %&gt;% pull(Sepal.Length) ## [1] 5.006 5.936 6.588 5.7 Window functions Window functions use the order of rows to calculate values. You can use them to do things that require ranking or ordering, like choose the top scores in each class, or acessing the previous and next rows, like calculating cumulative sums or means. The dplyr window functions vignette has very good detailed explanations of these functions, but we’ve described a few of the most useful ones below. 5.7.1 Ranking functions tibble( id = 1:5, &quot;Data Skills&quot; = c(16, 17, 17, 19, 20), &quot;Statistics&quot; = c(14, 16, 18, 18, 19) ) %&gt;% gather(class, grade, 2:3) %&gt;% group_by(class) %&gt;% mutate(row_number = row_number(), rank = rank(grade), min_rank = min_rank(grade), dense_rank = dense_rank(grade), quartile = ntile(grade, 4), percentile = ntile(grade, 100)) ## # A tibble: 10 x 9 ## # Groups: class [2] ## id class grade row_number rank min_rank dense_rank quartile ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 Data… 16 1 1 1 1 1 ## 2 2 Data… 17 2 2.5 2 2 1 ## 3 3 Data… 17 3 2.5 2 2 2 ## 4 4 Data… 19 4 4 4 3 3 ## 5 5 Data… 20 5 5 5 4 4 ## 6 1 Stat… 14 1 1 1 1 1 ## 7 2 Stat… 16 2 2 2 2 1 ## 8 3 Stat… 18 3 3.5 3 3 2 ## 9 4 Stat… 18 4 3.5 3 3 3 ## 10 5 Stat… 19 5 5 5 4 4 ## # … with 1 more variable: percentile &lt;int&gt; What are the differences among row_number(), rank(), min_rank(), dense_rank(), and ntile()? Why doesn’t row_number() need an argument? What would happen if you gave it the argument grade or class? What do you think would happen if you removed the group_by(class) line above? What if you added id to the grouping? What happens if you change the order of the rows? What does the second argument in ntile() do? You can use window functions to group your data into quantiles. iris %&gt;% group_by(tertile = ntile(Sepal.Length, 3)) %&gt;% summarise(mean.Sepal.Length = mean(Sepal.Length)) ## # A tibble: 3 x 2 ## tertile mean.Sepal.Length ## &lt;int&gt; &lt;dbl&gt; ## 1 1 4.94 ## 2 2 5.81 ## 3 3 6.78 5.7.2 Offset functions tibble( trial = 1:10, cond = rep(c(&quot;exp&quot;, &quot;ctrl&quot;), c(6, 4)), score = rpois(10, 4) ) %&gt;% mutate( score_change = score - lag(score, order_by = trial), last_cond_trial = cond != lead(cond, default = TRUE) ) ## # A tibble: 10 x 5 ## trial cond score score_change last_cond_trial ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt; ## 1 1 exp 4 NA FALSE ## 2 2 exp 5 1 FALSE ## 3 3 exp 4 -1 FALSE ## 4 4 exp 6 2 FALSE ## 5 5 exp 5 -1 FALSE ## 6 6 exp 6 1 TRUE ## 7 7 ctrl 7 1 FALSE ## 8 8 ctrl 4 -3 FALSE ## 9 9 ctrl 1 -3 FALSE ## 10 10 ctrl 3 2 TRUE Look at the help pages for lag() and lead(). What happens if you remove the order_by argument or change it to cond? What does the default argument do? Can you think of circumstances in your own data where you might need to use lag() or lead()? 5.7.3 Cumulative aggregates cumsum(), cummin(), and cummax() are base R functions for calcumaling cumulative means, minimums, and maximums. The dplyr package introduces cumany() and cumall(), which return TRUE if any or all of the previous values meet their criteria. tibble( time = 1:10, obs = c(1, 0, 1, 2, 4, 3, 1, 0, 3, 5) ) %&gt;% mutate( cumsum = cumsum(obs), cummin = cummin(obs), cummax = cummax(obs), cumany = cumany(obs == 3), cumall = cumall(obs &lt; 4) ) ## # A tibble: 10 x 7 ## time obs cumsum cummin cummax cumany cumall ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 1 1 1 1 1 FALSE TRUE ## 2 2 0 1 0 1 FALSE TRUE ## 3 3 1 2 0 1 FALSE TRUE ## 4 4 2 4 0 2 FALSE TRUE ## 5 5 4 8 0 4 FALSE FALSE ## 6 6 3 11 0 4 TRUE FALSE ## 7 7 1 12 0 4 TRUE FALSE ## 8 8 0 12 0 4 TRUE FALSE ## 9 9 3 15 0 4 TRUE FALSE ## 10 10 5 20 0 5 TRUE FALSE What would happen if you change cumany(obs == 3) to cumany(obs &gt; 2)? What would happen if you change cumall(obs &lt; 4) to cumall(obs &lt; 2)? Can you think of circumstances in your own data where you might need to use cumany() or cumall()? 5.8 Exercises Download the exercises. See the answers only after you’ve attempted all the questions. "],
["joins.html", "Chapter 6 Data Relations 6.1 Learning Objectives 6.2 Resources 6.3 Data 6.4 Mutating Joins 6.5 Filtering Joins 6.6 Binding Joins 6.7 Set Operations 6.8 Exercises", " Chapter 6 Data Relations 6.1 Learning Objectives 6.1.1 Beginner Be able to use the 4 mutating join verbs: left_join() right_join() inner_join() full_join() Use the by argument to set the join columns 6.1.2 Intermediate Use the suffix argument to distinguish columns with the same name Be able to use the 2 filtering join verbs: semi_join() anti_join() Be able to use the 2 binding join verbs: bind_rows() bind_cols() Be able to use the 3 set operations: intersect() union() setdiff() 6.2 Resources Chapter 13: Relational Data in R for Data Science Cheatsheet for dplyr join functions Lecture slides on dplyr two-table verbs 6.3 Data First, we’ll create two small data tables. subject has id, sex and age for subjects 1-5. Age and sex are missing for subject 3. subject &lt;- tibble( id = seq(1,5), sex = c(&quot;m&quot;, &quot;m&quot;, NA, &quot;f&quot;, &quot;f&quot;), age = c(19, 22, NA, 19, 18) ) id s ex age 1 m 19 2 m 22 3 NA NA 4 f 19 5 f 18 exp has subject id and the score from an experiment. Some subjects are missing, some completed twice, and some are not in the subject table. exp &lt;- tibble( id = c(2, 3, 4, 4, 5, 5, 6, 6, 7), score = c(10, 18, 21, 23, 9, 11, 11, 12, 3) ) id score 2 10 3 18 4 21 4 23 5 9 5 11 6 11 6 12 7 3 6.4 Mutating Joins All the mutating joins have this basic syntax: ****_join(x, y, by = NULL, suffix = c(&quot;.x&quot;, &quot;.y&quot;) x = the first (left) table y = the second (right) table {#join-by} by = what columns to match on. If you leave this blank, it will match on all columns with the same names in the two tables. {#join-suffix} suffix = if columns have the same name in the two tables, but you aren’t joining by them, they get a suffix to make them unambiguous. This defaults to “.x” and “.y”, but you can change it to something more meaningful. You can leave out the by argument if you’re matching on all of the columns with the same name, but it’s good practice to always specify it so your code is robust to changes in the loaded data. 6.4.1 left_join() Figure 6.1: Left Join A left_join keeps all the data from the first (left) table and joins anything that matches from the second (right) table. If the right table has more than one match for a row in the right table, there will be more than one row in the joined table (see ids 4 and 5). left_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 7 x 4 ## id sex age score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 m 19 NA ## 2 2 m 22 10 ## 3 3 &lt;NA&gt; NA 18 ## 4 4 f 19 21 ## 5 4 f 19 23 ## 6 5 f 18 9 ## 7 5 f 18 11 Figure 6.2: Left Join (reversed) The order of tables is swapped here, so the result is all rows from the exp table joined to any matching rows from the subject table. left_join(exp, subject, by = &quot;id&quot;) ## # A tibble: 9 x 4 ## id score sex age ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2 10 m 22 ## 2 3 18 &lt;NA&gt; NA ## 3 4 21 f 19 ## 4 4 23 f 19 ## 5 5 9 f 18 ## 6 5 11 f 18 ## 7 6 11 &lt;NA&gt; NA ## 8 6 12 &lt;NA&gt; NA ## 9 7 3 &lt;NA&gt; NA 6.4.2 right_join() Figure 6.3: Right Join A right_join keeps all the data from the second (right) table and joins anything that matches from the first (left) table. right_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 9 x 4 ## id sex age score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 m 22 10 ## 2 3 &lt;NA&gt; NA 18 ## 3 4 f 19 21 ## 4 4 f 19 23 ## 5 5 f 18 9 ## 6 5 f 18 11 ## 7 6 &lt;NA&gt; NA 11 ## 8 6 &lt;NA&gt; NA 12 ## 9 7 &lt;NA&gt; NA 3 This table has the same information as left_join(exp, subject, by = “id”), but the columns are in a different order (left table, then right table). 6.4.3 inner_join() Figure 6.4: Inner Join An inner_join returns all the rows that have a match in the other table. inner_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 6 x 4 ## id sex age score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 m 22 10 ## 2 3 &lt;NA&gt; NA 18 ## 3 4 f 19 21 ## 4 4 f 19 23 ## 5 5 f 18 9 ## 6 5 f 18 11 6.4.4 full_join() Figure 6.5: Full Join A full_join lets you join up rows in two tables while keeping all of the information from both tables. If a row doesn’t have a match in the other table, the other table’s column values are set to NA. full_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 10 x 4 ## id sex age score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 m 19 NA ## 2 2 m 22 10 ## 3 3 &lt;NA&gt; NA 18 ## 4 4 f 19 21 ## 5 4 f 19 23 ## 6 5 f 18 9 ## 7 5 f 18 11 ## 8 6 &lt;NA&gt; NA 11 ## 9 6 &lt;NA&gt; NA 12 ## 10 7 &lt;NA&gt; NA 3 6.5 Filtering Joins 6.5.1 semi_join() Figure 6.6: Semi Join A semi_join returns all rows from the left table where there are matching values in the right table, keeping just columns from the left table. semi_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 4 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2 m 22 ## 2 3 &lt;NA&gt; NA ## 3 4 f 19 ## 4 5 f 18 Unlike an inner join, a semi join will never duplicate the rows in the left table if there is more than one maching row in the right table. Figure 6.7: Semi Join (Reversed) Order matters in a semi join. semi_join(exp, subject, by = &quot;id&quot;) ## # A tibble: 6 x 2 ## id score ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 10 ## 2 3 18 ## 3 4 21 ## 4 4 23 ## 5 5 9 ## 6 5 11 6.5.2 anti_join() Figure 6.8: Anti Join A anti_join return all rows from the left table where there are not matching values in the right table, keeping just columns from the left table. anti_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 1 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 m 19 Figure 6.9: Anti Join (Reversed) Order matters in an anti join. anti_join(exp, subject, by = &quot;id&quot;) ## # A tibble: 3 x 2 ## id score ## &lt;dbl&gt; &lt;dbl&gt; ## 1 6 11 ## 2 6 12 ## 3 7 3 6.6 Binding Joins 6.6.1 bind_rows() You can combine the rows of two tables with bind_rows. Here we’ll add subject data for subjects 6-9 and bind that to the original subject table. new_subjects &lt;- tibble( id = seq(6, 9), sex = c(&quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;), age = c(19, 16, 20, 19) ) bind_rows(subject, new_subjects) ## # A tibble: 9 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 m 19 ## 2 2 m 22 ## 3 3 &lt;NA&gt; NA ## 4 4 f 19 ## 5 5 f 18 ## 6 6 m 19 ## 7 7 m 16 ## 8 8 f 20 ## 9 9 f 19 The columns just have to have the same names, they don’t have to be in the same order. Any columns that differ between the two tables will just have NA values for entries from the other table. If a row is duplicated between the two tables (like id 5 below), the row will also be duplicated in the resulting table. If your tables have the exact same columns, you can use union() (see below) to avoid duplicates. new_subjects &lt;- tibble( id = seq(5, 9), age = c(18, 19, 16, 20, 19), sex = c(&quot;f&quot;, &quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;), new = c(1,2,3,4,5) ) bind_rows(subject, new_subjects) ## # A tibble: 10 x 4 ## id sex age new ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 m 19 NA ## 2 2 m 22 NA ## 3 3 &lt;NA&gt; NA NA ## 4 4 f 19 NA ## 5 5 f 18 NA ## 6 5 f 18 1 ## 7 6 m 19 2 ## 8 7 m 16 3 ## 9 8 f 20 4 ## 10 9 f 19 5 6.6.2 bind_cols() You can merge two tables with the same number of rows using bind_cols. This is only useful if the two tables have their rows in the exact same order. The only advantage over a left join is when the tables don’t have any IDs to join by and you have to rely solely on their order. new_info &lt;- tibble( colour = c(&quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;) ) bind_cols(subject, new_info) ## # A tibble: 5 x 4 ## id sex age colour ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 m 19 red ## 2 2 m 22 orange ## 3 3 &lt;NA&gt; NA yellow ## 4 4 f 19 green ## 5 5 f 18 blue 6.7 Set Operations 6.7.1 intersect() intersect() returns all rows in two tables that match exactly. The columns don’t have to be in the same order. new_subjects &lt;- tibble( id = seq(4, 9), age = c(19, 18, 19, 16, 20, 19), sex = c(&quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;) ) dplyr::intersect(subject, new_subjects) ## # A tibble: 2 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 f 19 ## 2 5 f 18 6.7.2 union() union() returns all the rows from both tables, removing duplicate rows. dplyr::union(subject, new_subjects) ## # A tibble: 9 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 m 19 ## 2 2 m 22 ## 3 3 &lt;NA&gt; NA ## 4 4 f 19 ## 5 5 f 18 ## 6 6 m 19 ## 7 7 m 16 ## 8 8 f 20 ## 9 9 f 19 6.7.3 setdiff() setdiff returns rows that are in the first table, but not in the second table. setdiff(subject, new_subjects) ## # A tibble: 3 x 3 ## id age sex ## &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 19 m ## 2 2 22 m ## 3 3 NA &lt;NA&gt; Order matters for setdiff. setdiff(new_subjects, subject) ## # A tibble: 4 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 6 m 19 ## 2 7 m 16 ## 3 8 f 20 ## 4 9 f 19 6.8 Exercises Download the exercises. See the answers only after you’ve attempted all the questions. "],
["func.html", "Chapter 7 Iteration &amp; Functions 7.1 Learning Objectives 7.2 Resources 7.3 Iteration functions 7.4 Custom functions 7.5 Iterating your own functions 7.6 Exercises", " Chapter 7 Iteration &amp; Functions 7.1 Learning Objectives You will learn about functions and iteration by using simulation to calculate a power analysis for ANOVA on a simple two-group design. 7.1.1 Basic Work with iteration functions rep, seq, and replicate Use arguments by order or name Write your own custom functions with function() Set default values for the arguments in your functions 7.1.2 Intermediate Understand scope Use error handling and warnings in a function 7.1.3 Advanced The topics below are not (yet) covered in these materials, but they are directions for independent learning. Repeat commands and handle result using purrr::rerun(), purrr::map_*(), purrr::walk() Repeat commands having multiple arguments using purrr::map2_*() and purrr::pmap_*() Create nested data frames using dplyr::group_by() and tidyr::nest() Work with nested data frames in dplyr Capture and deal with errors using ‘adverb’ functions purrr::safely() and purrr::possibly() 7.2 Resources Chapters 19 and 21 of R for Data Science RStudio Apply Functions Cheatsheet In the next two lectures, we are going to learn more about iteration (doing the same commands over and over) and custom functions through a data simulation exercise, which will also lead us into more traditional statistical topics. Along the way you will also learn more about how to create vectors and tables in R. # libraries needed for these examples library(tidyverse) ## contains purrr, tidyr, dplyr 7.3 Iteration functions 7.3.1 rep() The function rep() lets you repeat the first argument a number of times. Use rep() to create a vector of alternating &quot;A&quot; and &quot;B&quot; values of length 24. rep(c(&quot;A&quot;, &quot;B&quot;), 12) ## [1] &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; ## [18] &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; Use rep() to create a vector of 12 &quot;A&quot; values followed by 12 &quot;B&quot; values rep(c(&quot;A&quot;, &quot;B&quot;), each = 12) ## [1] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; ## [18] &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; Use rep() to create a vector of 11 &quot;A&quot; values followed by 3 &quot;B&quot; values rep(c(&quot;A&quot;, &quot;B&quot;), c(11, 3)) ## [1] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; 7.3.2 seq() The function seq() is useful for generating a sequence of numbers with some pattern. Use seq() to create a vector of the numbers 0 to 100 by 10s. seq(0, 100, by = 10) ## [1] 0 10 20 30 40 50 60 70 80 90 100 The argument length.out is useful if you know how many steps you want to divide something into Use seq() to create a vector that starts with 0, ends with 100, and has 12 equally spaced steps (hint: how many numbers would be in a vector with 2 steps?). seq(0, 100, length.out = 13) ## [1] 0.000000 8.333333 16.666667 25.000000 33.333333 41.666667 ## [7] 50.000000 58.333333 66.666667 75.000000 83.333333 91.666667 ## [13] 100.000000 7.4 Custom functions In addition to the built-in functions and functions you can access from packages, you can also write your own functions (and eventually even packages!). 7.4.1 Structuring a function The general structure of a function is as follows: function_name &lt;- function(my_args) { # process the arguments # return some value } Here is a very simple function. Can you guess what it does? add1 &lt;- function(my_number) { my_number + 1 } add1(10) ## [1] 11 Let’s make a function that reports p-values in APA format (with “p = rounded value” when p &gt;= .001 and “p &lt; .001” when p &lt; .001). First, we have to name the function. You can name it anything, but try not to duplicate existing functions or you will overwrite them. For example, if you call your function rep, then you will need to use base::rep() to access the normal rep function. Let’s call our p-value function report_p and set up the framework of the function. report_p &lt;- function() { } 7.4.2 Arguments We need to add one argument, the p-value you want to report. The names you choose for the arguments are private to that argument, so it is not a problem if they conflict with other variables in your script. You put the arguments in the parentheses after function in the order you want them to default (just like the built-in functions you’ve used before). report_p &lt;- function(p) { } 7.4.3 Argument defaults You can add a default value to any argument. If that argument is skipped, then the function uses the default argument. It probably doesn’t make sense to run this function without specifying the p-value, but we can add a second argument called digits that defaults to 3, so we can round p-values to 3 digits. report_p &lt;- function(p, digits = 3) { } Now we need to write some code inside the function to process the input arguments and turn them into a returned output. Put the output as the last item in function. report_p &lt;- function(p, digits = 3) { if (p &lt; .001) { reported = &quot;p &lt; .001&quot; } else { roundp &lt;- round(p, digits) reported = paste(&quot;p =&quot;, roundp) } reported } You might also see the returned output inside of the return() function. This does the same thing. report_p &lt;- function(p, digits = 3) { if (p &lt; .001) { reported = &quot;p &lt; .001&quot; } else { roundp &lt;- round(p, digits) reported = paste(&quot;p =&quot;, roundp) } return(reported) } When you run the code defining your function, it doesn’t output anything, but makes a new object in the Environment tab under Functions. Now you can run the function. report_p(0.04869) report_p(0.0000023) ## [1] &quot;p = 0.049&quot; ## [1] &quot;p &lt; .001&quot; 7.4.4 Scope What happens in a function stays in a function. You can change the value of a variable passed to a function, but that won’t change the value of the variable outside of the function, even if that variable has the same name as the one in the function. half &lt;- function(x) { x &lt;- x/2 return(x) } x &lt;- 10 list( &quot;half(x)&quot; = half(x), &quot;x&quot; = x ) ## $`half(x)` ## [1] 5 ## ## $x ## [1] 10 7.4.5 Warnings and errors What happens when you omit the argument for p? Or if you set p to 1.5 or “a”? You might want to add a more specific warning and stop running the function code if someone enters a value that isn’t a number. You can do this with the stop() function. If someone enters a number that isn’t possible for a p-value (0-1), you might want to warn them that this is probably not what they intended, but still continue with the function. You can do this with warning(). report_p &lt;- function(p, digits = 3) { if (!is.numeric(p)) stop(&quot;p must be a number&quot;) if (p &lt;= 0) warning(&quot;p-values are normally greater than 0&quot;) if (p &gt;= 1) warning(&quot;p-values are normally less than 1&quot;) if (p &lt; .001) { reported = &quot;p &lt; .001&quot; } else { roundp &lt;- round(p, digits) reported = paste(&quot;p =&quot;, roundp) } reported } report_p() ## Error in report_p(): argument &quot;p&quot; is missing, with no default report_p(&quot;a&quot;) ## Error in report_p(&quot;a&quot;): p must be a number report_p(-2) ## Warning in report_p(-2): p-values are normally greater than 0 report_p(2) ## Warning in report_p(2): p-values are normally less than 1 ## [1] &quot;p &lt; .001&quot; ## [1] &quot;p = 2&quot; 7.5 Iterating your own functions First, let’s build up the code that we want to iterate. 7.5.1 rnorm() Create a vector of 20 random numbers drawn from a normal distribution with a mean of 5 and standard deviation of 1 using the rnorm() function and store them in the variable A. A &lt;- rnorm(20, mean = 5, sd = 1) 7.5.2 tibble::tibble() A tibble is a type of table or data.frame. The function tibble::tibble() creates a tibble with a column for each argument. Each argument takes the form column_name = data_vector. Create a table called dat including two vectors: A that is a vector of 20 random normally distributed numbers with a mean of 5 and SD of 1, and B that is a vector of 20 random normally distributed numbers with a mean of 5.5 and SD of 1. dat &lt;- tibble( A = rnorm(20, 5, 1), B = rnorm(20, 5.5, 1) ) 7.5.3 t.test You can run a Welch two-sample t-test by including the two samples you made as the first two arguments to the function t.test. You can reference one column of a table by its names using the format table_name$column_name t.test(dat$A, dat$B) ## ## Welch Two Sample t-test ## ## data: dat$A and dat$B ## t = -2.2611, df = 35.667, p-value = 0.02995 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.33872796 -0.07250043 ## sample estimates: ## mean of x mean of y ## 5.065206 5.770821 You can also convert the table to long format using the gather function and specify the t-test using the format number_column~grouping_column. longdat &lt;- gather(dat, group, score, A:B) t.test(score~group, data = longdat) ## ## Welch Two Sample t-test ## ## data: score by group ## t = -2.2611, df = 35.667, p-value = 0.02995 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.33872796 -0.07250043 ## sample estimates: ## mean in group A mean in group B ## 5.065206 5.770821 7.5.4 broom::tidy() You can use the function broom::tidy() to extract the data from a statistical test in a table format. The example below pipes everything together. tibble( A = rnorm(20, 5, 1), B = rnorm(20, 5.5, 1) ) %&gt;% gather(group, score, A:B) %&gt;% t.test(score~group, data = .) %&gt;% broom::tidy() ## # A tibble: 1 x 10 ## estimate estimate1 estimate2 statistic p.value parameter conf.low ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.683 5.03 5.71 -2.15 0.0379 38.0 -1.33 ## # … with 3 more variables: conf.high &lt;dbl&gt;, method &lt;chr&gt;, ## # alternative &lt;chr&gt; Finally, we can extract a single value from this results table using pull(). tibble( A = rnorm(20, 5, 1), B = rnorm(20, 5.5, 1) ) %&gt;% gather(group, score, A:B) %&gt;% t.test(score~group, data = .) %&gt;% broom::tidy() %&gt;% pull(p.value) ## [1] 0.07957549 7.5.5 Turn into a function First, name your function t_sim and wrap the code above in a function with no arguments. t_sim &lt;- function() { tibble( A = rnorm(20, 5, 1), B = rnorm(20, 5.5, 1) ) %&gt;% gather(group, score, A:B) %&gt;% t.test(score~group, data = .) %&gt;% broom::tidy() %&gt;% pull(p.value) } Run it a few times to see what happens. t_sim() ## [1] 0.001119074 7.5.6 replicate() You can use the replicate function to run your function any number of times. Let’s run the t_sim function 1000 times, assign the resulting p-values to a vector called reps, and check what proportion of p-values are lower than alpha (e.g., .05). This number is the power for this analysis. reps &lt;- replicate(1000, t_sim()) alpha &lt;- .05 power &lt;- mean(reps &lt; alpha) power ## [1] 0.329 7.5.7 Add arguments You can just edit your function each time you want to cacluate power for a different sample n, but it is more efficent to build this into your fuction as an arguments. Redefine t_sim, setting arguments for the mean and SD of group A, the mean and SD of group B, and the number of subjects per group. Give them all default values. t_sim &lt;- function(n = 10, m1=0, sd1=1, m2=0, sd2=1) { tibble( A = rnorm(n, m1, sd1), B = rnorm(n, m2, sd2) ) %&gt;% gather(group, score, A:B) %&gt;% t.test(score~group, data = .) %&gt;% broom::tidy() %&gt;% pull(p.value) } Test your function with some different values to see if the results make sense. t_sim(100) t_sim(100, 0, 1, 0.5, 1) ## [1] 0.07474176 ## [1] 0.02301215 Use replicate to calculate power for 100 subjects/group with an effect size of 0.2 (e.g., A: m = 0, SD = 1; B: m = 0.2, SD = 1). Use 1000 replications. reps &lt;- replicate(1000, t_sim(100, 0, 1, 0.2, 1)) power &lt;- mean(reps &lt; .05) power ## [1] 0.286 Compare this to power calculated from the power.t.test function. power.t.test(n = 100, delta = 0.2, sd = 1, type=&quot;two.sample&quot;) ## ## Two-sample t test power calculation ## ## n = 100 ## delta = 0.2 ## sd = 1 ## sig.level = 0.05 ## power = 0.2902664 ## alternative = two.sided ## ## NOTE: n is number in *each* group Calculate power via simulation and power.t.test for the following tests: 20 subjects/group, A: m = 0, SD = 1; B: m = 0.2, SD = 1 40 subjects/group, A: m = 0, SD = 1; B: m = 0.2, SD = 1 20 subjects/group, A: m = 10, SD = 1; B: m = 12, SD = 1.5 7.6 Exercises Download the exercises. See the answers only after you’ve attempted all the questions. "],
["sim.html", "Chapter 8 Probability &amp; Simulation 8.1 Learning Objectives 8.2 Resources 8.3 Distributions 8.4 Example 8.5 Exercises", " Chapter 8 Probability &amp; Simulation 8.1 Learning Objectives 8.1.1 Basic Understand what types of data are best modeled by different distributions uniform binomial normal poisson Generate and plot data randomly sampled from the above distributions Test sampled distributions against a null hypothesis exact binomial test t-test (1-sample, independent samples, paired samples) correlation (pearson, kendall and spearman) Define the following statistical terms: p-value alpha power false positive (type I error) false negative (type II error) confidence interval 8.1.2 Intermediate Create a function to generate a sample with specific properties and run an inferential test Calculate power using replicate and a sampling function Calculate the minimum sample size for a specific power level and design 8.1.3 Advanced Generate 3+ variables from a multivariate normal distribution and plot them 8.2 Resources Chapter 21: Iteration of R for Data Science Improving your statistical inferences on Coursera (week 1) Simulation tutorials Faux package for data simulation Simulation-Based Power-Analysis for Factorial ANOVA Designs (Lakens and Caldwell 2019) Understanding mixed effects models through data simulation (DeBruine and Barr 2019) 8.3 Distributions Simulating data is a very powerful way to test your understanding of statistical concepts. We are going to use simulations to learn the basics of probability. # libraries needed for these examples library(tidyverse) library(MASS) set.seed(8675309) # makes sure random numbers are reproducible 8.3.1 Uniform Distribution The uniform distribution is the simplest distribution. All numbers in the range have an equal probability of being sampled. Take a minute to think of things in your own research that are uniformly distributed. 8.3.1.1 Sample continuous distribution runif(n, min=0, max=1) Use runif() to sample from a continuous uniform distribution. runif(10, min = 0, max = 1) ## [1] 0.1594836 0.4781883 0.7647987 0.7696877 0.2685485 0.6730459 0.9787908 ## [8] 0.8463270 0.8566562 0.4451601 8.3.1.2 Sample discrete distribution sample(x, size, replace = FALSE, prob = NULL) Use sample() to sample from a discrete distribution. Simulate a single roll of a 6-sided die. sample(6, 1) ## [1] 5 Simulate 10 rolls of a 6-sided die. Set replace to TRUE so each roll is independent. See what happens if you set replace to FALSE. sample(6, 10, replace = TRUE) ## [1] 6 3 1 4 5 2 3 6 4 6 You can also use sample to sample from a list of named outcomes. pet_types &lt;- c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;, &quot;bird&quot;, &quot;fish&quot;) sample(pet_types, 10, replace = TRUE) ## [1] &quot;ferret&quot; &quot;fish&quot; &quot;bird&quot; &quot;cat&quot; &quot;ferret&quot; &quot;bird&quot; &quot;cat&quot; ## [8] &quot;ferret&quot; &quot;cat&quot; &quot;cat&quot; Ferrets are a much less common pet than cats and dogs, so our sample isn’t very realistic. You can set the probabilities of each item in the list with the prob argument. pet_types &lt;- c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;, &quot;bird&quot;, &quot;fish&quot;) pet_prob &lt;- c(0.3, 0.4, 0.1, 0.1, 0.1) sample(pet_types, 10, replace = TRUE, prob = pet_prob) ## [1] &quot;dog&quot; &quot;dog&quot; &quot;dog&quot; &quot;ferret&quot; &quot;ferret&quot; &quot;cat&quot; &quot;ferret&quot; ## [8] &quot;cat&quot; &quot;ferret&quot; &quot;dog&quot; 8.3.2 Binomial Distribution The binomial distribution is useful for modeling binary data, where each observation can have one of two outcomes, like success/failure, yes/no or head/tails. 8.3.2.1 Sample distribution rbinom(n, size, prob) The rbinom function will generate a random binomial distribution. n = number of observations size = number of trials prob = probability of success on each trial Coin flips are a typical example of a binomial distribution, where we can assign heads to 1 and tails to 0. # 20 individual coin flips of a fair coin rbinom(20, 1, 0.5) ## [1] 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 1 # 20 individual coin flips of a baised (0.75) coin rbinom(20, 1, 0.75) ## [1] 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 You can generate the total number of heads in 1 set of 20 coin flips by setting size to 20 and n to 1. rbinom(1, 20, 0.75) ## [1] 15 You can generate more sets of 20 coin flips by increasing the n. rbinom(10, 20, 0.5) ## [1] 8 10 11 10 6 10 9 8 7 5 You should always check your randomly generated data to check that it makes sense. For large samples, it’s easiest to do that graphically. A histogram is usually the best choice for plotting binomial data. flips &lt;- rbinom(1000, 20, 0.5) ggplot() + geom_histogram( aes(flips), binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot; ) (#fig:sim_flips)CAPTION THIS FIGURE!! Run the simulation above several times, noting how the histogram changes. Try changing the values of n, size, and prob. 8.3.2.2 Exact binomial test binom.test(x, n, p) You can test a binomial distribution against a specific probability using the exact binomial test. x = the number of successes n = the number of trials p = hypothesised probability of success Here we can test a series of 10 coin flips from a fair coin and a biased coin against the hypothesised probability of 0.5 (even odds). n &lt;- 10 fair_coin &lt;- rbinom(1, n, 0.5) biased_coin &lt;- rbinom(1, n, 0.6) binom.test(fair_coin, n, p = 0.5) binom.test(biased_coin, n, p = 0.5) ## ## Exact binomial test ## ## data: fair_coin and n ## number of successes = 3, number of trials = 10, p-value = 0.3438 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.06673951 0.65245285 ## sample estimates: ## probability of success ## 0.3 ## ## ## Exact binomial test ## ## data: biased_coin and n ## number of successes = 7, number of trials = 10, p-value = 0.3438 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.3475471 0.9332605 ## sample estimates: ## probability of success ## 0.7 Run the code above several times, noting the p-values for the fair and biased coins. Alternatively, you can simulate coin flips online and build up a graph of results and p-values. How does the p-value vary for the fair and biased coins? What happens to the confidence intervals if you increase n from 10 to 100? What criterion would you use to tell if the observed data indicate the coin is fair or biased? How often do you conclude the fair coin is biased (false positives)? How often do you conclude the biased coin is fair (false negatives)? 8.3.2.3 False positives &amp; negatives The probability that a test concludes the fair coin is biased is called the false positive rate (or Type I Error Rate). The alpha is the false positive rate we accept for a test. This is traditionally set at 0.05, but there are good arguments for setting a different criterion in some circumstances. The probability that a test concludes the biased coin is fair is called the false negative rate (of Type II Error Rate). The power of a test is 1 minus its false negative rate (i.e., the true positive rate). Power depends on how biased the coin is, how many samples we take, and what we set alpha to. 8.3.2.4 Sampling function To estimate these rates, we need to repeat the sampling above many times. A function is ideal for repeating the exact same procedure over and over. Set the arguments of the function to variables that you might want to change. Here, we will want to estimate power for: different sample sizes (n) different coin biases (bias) different hypothesised probabilities (p, defaults to 0.5) sim_binom_test &lt;- function(n, bias, p = 0.5) { coin &lt;- rbinom(1, n, bias) btest &lt;- binom.test(coin, n, p) btest$p.value } Once you’ve created your function, test it a few times, changing the values. sim_binom_test(100, 0.6) ## [1] 0.02097874 8.3.2.5 Calculate power Then you can use the replicate() function to run it many times and save all the output values. You can calculate the power of your analysis by checking the proportion of your simulated analyses that have a p-value less than your alpha (the probability of rejecting the null hypothesis when the null hypothesis is true). my_reps &lt;- replicate(1e4, sim_binom_test(100, 0.6)) alpha &lt;- 0.05 # this does not always have to be 0.05 mean(my_reps &lt; alpha) ## [1] 0.4588 1e4 is just scientific notation for a 1 followed by 4 zeros (10000). When you’re running simulations, you usually want to run a lot of them. It’s a pain to keep track of whether you’ve typed 5 or 6 zeros (100000 vs 1000000) and this will change your running time by an order of magnitude. 8.3.3 Normal Distribution 8.3.3.1 Sample distribution rnorm(n, mean, sd) We can simulate a normal distribution of size n if we know the mean and standard deviation (sd). A density plot is usually the best way to visualise this type of data if your n is large. dv &lt;- rnorm(1e5, 10, 2) # proportions of normally-distributed data # within 1, 2, or 3 SD of the mean sd1 &lt;- .6827 sd2 &lt;- .9545 sd3 &lt;- .9973 ggplot() + geom_density(aes(dv), fill = &quot;white&quot;) + geom_vline(xintercept = mean(dv), color = &quot;red&quot;) + geom_vline(xintercept = quantile(dv, .5 - sd1/2), color = &quot;darkgreen&quot;) + geom_vline(xintercept = quantile(dv, .5 + sd1/2), color = &quot;darkgreen&quot;) + geom_vline(xintercept = quantile(dv, .5 - sd2/2), color = &quot;blue&quot;) + geom_vline(xintercept = quantile(dv, .5 + sd2/2), color = &quot;blue&quot;) + geom_vline(xintercept = quantile(dv, .5 - sd3/2), color = &quot;purple&quot;) + geom_vline(xintercept = quantile(dv, .5 + sd3/2), color = &quot;purple&quot;) + scale_x_continuous( limits = c(0,20), breaks = seq(0,20) ) Figure 8.1: CAPTION THIS FIGURE!! Run the simulation above several times, noting how the density plot changes. What do the vertical lines represent? Try changing the values of n, mean, and sd. 8.3.3.2 T-test t.test(x, y, alternative, mu, paired) Use a t-test to compare the mean of one distribution to a null hypothesis (one-sample t-test), compare the means of two samples (independent-samples t-test), or compare pairs of values (paired-samples t-test). You can run a one-sample t-test comparing the mean of your data to mu. Here is a simulated distribution with a mean of 0.5 and an SD of 1, creating an effect size of 0.5 SD when tested against a mu of 0. Run the simulation a few times to see how often the t-test returns a significant p-value (or run it in the shiny app). sim_norm &lt;- rnorm(100, 0.5, 1) t.test(sim_norm, mu = 0) ## ## One Sample t-test ## ## data: sim_norm ## t = 4.2158, df = 99, p-value = 5.507e-05 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 0.2058657 0.5719533 ## sample estimates: ## mean of x ## 0.3889095 Run an independent-samples t-test by comparing two lists of values. a &lt;- rnorm(100, 0.5, 1) b &lt;- rnorm(100, 0.7, 1) t_ind &lt;- t.test(a, b, paired = FALSE) t_ind ## ## Welch Two Sample t-test ## ## data: a and b ## t = -1.9196, df = 195.54, p-value = 0.05636 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.520235824 0.007028115 ## sample estimates: ## mean of x mean of y ## 0.3852249 0.6418287 The paired argument defaults to FALSE, but it’s good practice to always explicitly set it so you are never confused about what type of test you are performing. 8.3.3.3 Sampling function We can use the names() function to find out the names of all the t.test parameters and use this to just get one type of data, like the test statistic (e.g., t-value). names(t_ind) t_ind$statistic ## [1] &quot;statistic&quot; &quot;parameter&quot; &quot;p.value&quot; &quot;conf.int&quot; &quot;estimate&quot; ## [6] &quot;null.value&quot; &quot;stderr&quot; &quot;alternative&quot; &quot;method&quot; &quot;data.name&quot; ## t ## -1.919595 Alternatively, use broom::tidy() to convert the output into a tidy table. broom::tidy(t_ind) ## # A tibble: 1 x 10 ## estimate estimate1 estimate2 statistic p.value parameter conf.low ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.257 0.385 0.642 -1.92 0.0564 196. -0.520 ## # … with 3 more variables: conf.high &lt;dbl&gt;, method &lt;chr&gt;, ## # alternative &lt;chr&gt; If you want to run the simulation many times and record information each time, first you need to turn your simulation into a function. sim_t_ind &lt;- function(n, m1, sd1, m2, sd2) { v1 &lt;- rnorm(n, m1, sd1) v2 &lt;- rnorm(n, m2, sd2) t_ind &lt;- t.test(v1, v2, paired = FALSE) return(t_ind$p.value) } Run it a few times to check that it gives you sensible values. sim_t_ind(100, 0.7, 1, 0.5, 1) ## [1] 0.4973957 Now replicate the simulation 1000 times. my_reps &lt;- replicate(1e4, sim_t_ind(100, 0.7, 1, 0.5, 1)) alpha &lt;- 0.05 power &lt;- mean(my_reps &lt; alpha) power ## [1] 0.2938 Run the code above several times. How much does the power value fluctuate? How many replications do you need to run to get a reliable estimate of power? Compare your power estimate from simluation to a power calculation using power.t.test(). Here, delta is the difference between m1 and m2 above. power.t.test(n = 100, delta = 0.2, sd = 1, sig.level = alpha, type = &quot;two.sample&quot;) ## ## Two-sample t test power calculation ## ## n = 100 ## delta = 0.2 ## sd = 1 ## sig.level = 0.05 ## power = 0.2902664 ## alternative = two.sided ## ## NOTE: n is number in *each* group You can plot the distribution of p-values. ggplot() + geom_histogram( aes(my_reps), binwidth = 0.05, boundary = 0, fill = &quot;white&quot;, color = &quot;black&quot; ) Figure 8.2: CAPTION THIS FIGURE!! What do you think the distribution of p-values is when there is no effect (i.e., the means are identical)? Check this yourself. Make sure the boundary argument is set to 0 for p-value histograms. See what happens with a null effect if boundary is not set. 8.3.3.4 Bivariate Normal 8.3.3.4.1 Correlation You can test if two continuous variables are related to each other using the cor() function. Below is a quick and dirty way to generate two correlated variables. x is drawn from a normal distribution, while y is the sum of x and another value drawn from a random normal distribution. We’ll learn later how to generate specific correlations in simulated data. n &lt;- 100 # number of random samples x &lt;- rnorm(n, 0, 1) y &lt;- x + rnorm(n, 0, 1) cor(x, y) ## [1] 0.7039656 cor() defaults to Pearson’s correlations. Set the method argument to use Kendall or Spearman correlations. cor(x, y, method = &quot;spearman&quot;) ## [1] 0.6786799 8.3.3.4.2 Sample distribution What if we want to sample from a population with specific relationships between variables? We can sample from a bivariate normal distribution using the MASS package, n &lt;- 1000 # number of random samples rho &lt;- 0.5 # population correlation between the two variables mu &lt;- c(10, 20) # the means of the samples stdevs &lt;- c(5, 6) # the SDs of the samples # correlation matrix cor_mat &lt;- matrix(c( 1, rho, rho, 1), 2) # create the covariance matrix sigma &lt;- (stdevs %*% t(stdevs)) * cor_mat # sample from bivariate normal distribution bvn &lt;- mvrnorm(n, mu, sigma) cor(bvn) # check correlation matrix ## [,1] [,2] ## [1,] 1.0000000 0.4709289 ## [2,] 0.4709289 1.0000000 Plot your sampled variables to check everything worked like you expect. You need to convert the output of mvnorm into a tibble in order to use it in ggplot. bvn %&gt;% as_tibble() %&gt;% ggplot(aes(V1, V2)) + geom_point(alpha = 0.5) + geom_smooth(method = &quot;lm&quot;) + geom_density2d() ## Warning: `as_tibble.matrix()` requires a matrix with column names or a `.name_repair` argument. Using compatibility `.name_repair`. ## This warning is displayed once per session. Figure 8.3: CAPTION THIS FIGURE!! 8.3.4 Multivariate Normal 8.3.4.0.1 Sample distribution n &lt;- 200 # number of random samples rho1_2 &lt;- 0.5 # correlation betwen v1 and v2 rho1_3 &lt;- 0 # correlation betwen v1 and v3 rho2_3 &lt;- 0.7 # correlation betwen v2 and v3 mu &lt;- c(10, 20, 30) # the means of the samples stdevs &lt;- c(8, 9, 10) # the SDs of the samples # correlation matrix cor_mat &lt;- matrix(c( 1, rho1_2, rho1_3, rho1_2, 1, rho2_3, rho1_3, rho2_3, 1), 3) sigma &lt;- (stdevs %*% t(stdevs)) * cor_mat bvn3 &lt;- mvrnorm(n, mu, sigma) cor(bvn3) # check correlation matrix ## [,1] [,2] [,3] ## [1,] 1.0000000 0.4145752 -0.1546829 ## [2,] 0.4145752 1.0000000 0.6825149 ## [3,] -0.1546829 0.6825149 1.0000000 8.3.4.0.2 3D Plots You can use the plotly library to make a 3D graph. library(plotly) ## ## Attaching package: &#39;plotly&#39; ## The following object is masked from &#39;package:MASS&#39;: ## ## select ## The following object is masked from &#39;package:ggplot2&#39;: ## ## last_plot ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## The following object is masked from &#39;package:graphics&#39;: ## ## layout marker_style = list( color = &quot;#ff0000&quot;, line = list( color = &quot;#444&quot;, width = 1 ), opacity = 0.5, size = 5 ) bvn3 %&gt;% as_tibble() %&gt;% plot_ly(x = ~V1, y = ~V2, z = ~V3, marker = marker_style) %&gt;% add_markers() Figure 8.4: CAPTION THIS FIGURE!! 8.4 Example This example uses the Growth Chart Data Tables from the US CDC. 8.4.1 Load &amp; wrangle We have to do a little data wrangling first. Have a look at the data after you import it and relabel Sex to male and female instead of 1 and 2. Also convert Agemos (age in months) to years. Relabel the column 0 as mean and calculate a new column named sd as the difference between columns 1 and 0. height_age &lt;- read_csv(&quot;https://www.cdc.gov/growthcharts/data/zscore/zstatage.csv&quot;) %&gt;% filter(Sex %in% c(1,2)) %&gt;% mutate( sex = recode(Sex, &quot;1&quot; = &quot;male&quot;, &quot;2&quot; = &quot;female&quot;), age = as.numeric(Agemos)/12, sd = `1` - `0` ) %&gt;% dplyr::select(sex, age, mean = `0`, sd) ## Parsed with column specification: ## cols( ## Sex = col_character(), ## Agemos = col_character(), ## `-2` = col_double(), ## `-1.5` = col_double(), ## `-1` = col_double(), ## `-0.5` = col_double(), ## `0` = col_double(), ## `0.5` = col_double(), ## `1` = col_double(), ## `1.5` = col_double(), ## `2` = col_double() ## ) If you run the code above without putting dplyr:: before the select() function, you will get an error message. This is because the MASS package also has a function called select() and, since we loaded MASS after tidyverse, the MASS function is the default. When you loaded MASS, you should have seen a warning like “The following object is masked from ‘package:dplyr’: select”. You can use functions with the same name from different packages by specifying the package before the function name, separated by two colons. 8.4.2 Plot Plot your new data frame to see how mean height changes with age for boys and girls. ggplot(height_age, aes(age, mean, color = sex)) + geom_smooth(aes(ymin = mean - sd, ymax = mean + sd), stat=&quot;identity&quot;) Figure 8.5: CAPTION THIS FIGURE!! 8.4.3 Get means and SDs Create new variables for the means and SDs for 20-year-old men and women. height_sub &lt;- height_age %&gt;% filter(age == 20) m_mean &lt;- height_sub %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(mean) m_sd &lt;- height_sub %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(sd) f_mean &lt;- height_sub %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(mean) f_sd &lt;- height_sub %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(sd) height_sub ## # A tibble: 2 x 4 ## sex age mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 male 20 177. 7.12 ## 2 female 20 163. 6.46 8.4.4 Simulate a population Simulate 50 random male heights and 50 radom female heights using the rnorm() function and the means and SDs above. Plot the data. sim_height &lt;- tibble( male = rnorm(50, m_mean, m_sd), female = rnorm(50, f_mean, f_sd) ) %&gt;% gather(&quot;sex&quot;, &quot;height&quot;, male:female) ggplot(sim_height) + geom_density(aes(height, fill = sex), alpha = 0.5) + xlim(125, 225) Figure 8.6: CAPTION THIS FIGURE!! Run the simulation above several times, noting how the density plot changes. Try changing the age you’re simulating. 8.4.5 Analyse simulated data Use the sim_t_ind(n, m1, sd1, m2, sd2) function we created above to generate one simulation with a sample size of 50 in each group using the means and SDs of male and female 14-year-olds. height_sub &lt;- height_age %&gt;% filter(age == 14) m_mean &lt;- height_sub %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(mean) m_sd &lt;- height_sub %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(sd) f_mean &lt;- height_sub %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(mean) f_sd &lt;- height_sub %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(sd) sim_t_ind(50, m_mean, m_sd, f_mean, f_sd) ## [1] 0.003009548 8.4.6 Replicate simulation Now replicate this 1e4 times using the replicate() function. This function will save the returned p-values in a list (my_reps). We can then check what proportion of those p-values are less than our alpha value. This is the power of our test. my_reps &lt;- replicate(1e4, sim_t_ind(50, m_mean, m_sd, f_mean, f_sd)) alpha &lt;- 0.05 power &lt;- mean(my_reps &lt; alpha) power ## [1] 0.6435 8.4.7 One-tailed prediction This design has about 65% power to detect the sex difference in height (with a 2-tailed test). Modify the sim_t_ind function for a 1-tailed prediction. You could just set alternative equal to “greater” in the function, but it might be better to add the alternative argument to your function (giving it the same default value as t.test) and change the value of alternative in the function to alternative. sim_t_ind &lt;- function(n, m1, sd1, m2, sd2, alternative = &quot;two.sided&quot;) { v1 &lt;- rnorm(n, m1, sd1) v2 &lt;- rnorm(n, m2, sd2) t_ind &lt;- t.test(v1, v2, paired = FALSE, alternative = alternative) return(t_ind$p.value) } my_reps &lt;- replicate(1e4, sim_t_ind(50, m_mean, m_sd, f_mean, f_sd, &quot;greater&quot;)) mean(my_reps &lt; alpha) ## [1] 0.7605 8.4.8 Range of sample sizes What if we want to find out what sample size will give us 80% power? We can try trial and error. We know the number should be slightly larger than 50. But you can search more systematically by repeating your power calculation for a range of sample sizes. This might seem like overkill for a t-test, where you can easily look up sample size calculators online, but it is a valuable skill to learn for when your analyses become more complicated. Start with a relatively low number of replications and/or more spread-out samples to estimate where you should be looking more specifically. Then you can repeat with a narrower/denser range of sample sizes and more iterations. alpha &lt;- 0.05 power_table &lt;- tibble( n = seq(20, 100, by = 5) ) %&gt;% mutate(power = map_dbl(n, function(n) { ps &lt;- replicate(1e3, sim_t_ind(n, m_mean, m_sd, f_mean, f_sd, &quot;greater&quot;)) mean(ps &lt; alpha) })) ggplot(power_table, aes(n, power)) + geom_smooth() + geom_point() + geom_hline(yintercept = 0.8) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Figure 8.7: CAPTION THIS FIGURE!! Now we can narrow down our search to values around 55 (plus or minus 5) and increase the number of replications from 1e3 to 1e4. power_table &lt;- tibble( n = seq(50, 60) ) %&gt;% mutate(power = map_dbl(n, function(n) { ps &lt;- replicate(1e3, sim_t_ind(n, m_mean, m_sd, f_mean, f_sd, &quot;greater&quot;)) mean(ps &lt; alpha) })) ##ggplot(power_table, aes(n, power)) + ## geom_smooth() + ## geom_point() + ## geom_hline(yintercept = 0.8) + ## scale_x_continuous(breaks = sample_size) 8.5 Exercises Download the exercises. See the answers only after you’ve attempted all the questions. D References "],
["glm.html", "Chapter 9 Introduction to GLM 9.1 Learning Objectives 9.2 Resources 9.3 GLM 9.4 Relationship between t-test, ANOVA, and linear regression 9.5 Understanding decomposition matrices 9.6 Exercises", " Chapter 9 Introduction to GLM 9.1 Learning Objectives 9.1.1 Basic Prove to yourself the correspondence among two-sample t-test, one-way ANOVA, and linear regression with dummy coding Given data and a GLM, generate a decomposition matrix and calculate sums of squares, mean squares, and F ratios 9.2 Resources Jeff Miller and Patricia Haden, Statistical Analysis with the Linear Model (free online textbook) lecture slides introducing the General Linear Model GLM shiny app F distribution 9.3 GLM In the code block below, you are given the two_sample() function which you will use to generate random datasets. # libraries needed for these examples library(tidyverse) two_sample &lt;- function(diff = 0.5, n_per_group = 20) { tibble(Y = c(rnorm(n_per_group, -.5 * diff, sd = 1), rnorm(n_per_group, .5 * diff, sd = 1)), grp = factor(rep(c(&quot;a&quot;, &quot;b&quot;), each = n_per_group)), grp_d = rep(c(0, 1), each = n_per_group)) } 9.4 Relationship between t-test, ANOVA, and linear regression Generate a single random dataset using two_sample(). Then compare and contrast the results from: A t-test (with var.equal = TRUE) An ANOVA (using aov()) Linear regression (using lm()) on the data 9.5 Understanding decomposition matrices Now use two_sample() to create a dataset dat with N=5 per group. Then use the estimation equations for a one-factor ANOVA to calculate the model components mu_hat (\\(\\hat{\\mu}\\)), and a_hat (\\(\\hat{A_i}\\)). ’mu_hat&quot; should be a single value and a_hat should be a table with two rows and columns grp and a (the estimated effect for that group). Hint ```r mu_hat &lt;- dat %&gt;% summarise(????) %&gt;% pull(????) a_hat &lt;- dat %&gt;% group_by(???) %&gt;% summarise(????) ``` &lt;/div&gt; Calculate residuals (err or \\(\\widehat{S(A)_{ij}}\\)) and generate a decomposition matrix of Y in dat, such as seen slides 10-12 from the lecture. (Despite being called a matrix, your decomposition matrix should be a tibble not a matrix, and you don’t need to include the last line with SS yet.) &lt;div class=&quot;solution&quot;&gt;&lt;button&gt;Hint&lt;/button&gt; It might be easier to calculate the residuals *after* you get everything else in the table. &lt;/div&gt; &lt;div class=&quot;solution&quot;&gt;&lt;button&gt;Another Hint&lt;/button&gt; Use `select()` on dat to get `Y` and `grp`, and `inner_join()` to add in the $A_i$s. &lt;/div&gt; &lt;div class=&quot;solution&quot;&gt;&lt;button&gt;Yet Another Hint&lt;/button&gt; ```r decomp &lt;- dat %&gt;% select(Y, grp) %&gt;% mutate(mu = mu_hat) %&gt;% inner_join(a_hat, &quot;grp&quot;) # %&gt;% ...etc ``` &lt;/div&gt; Calculate sums of squares for Y, a, and err. The resulting table should be called all_ss with columns SS_Y, SS_a, and SS_err respectively. &lt;div class=&quot;solution&quot;&gt;&lt;button&gt;Hint&lt;/button&gt; Use the `summarise()` function. You can declare more than one summary values as separate arguments to the function. &lt;/div&gt; Divide each sum of squares by its corresponding df to calculate mean squares. The calculate an F-ratio, and get the p-value using the pf() function. &lt;div class=&quot;solution&quot;&gt;&lt;button&gt;Hint&lt;/button&gt; Use `lower.tail = FALSE` with `pf()`. See `?pf` &lt;/div&gt; Now run a one-way ANOVA on your results and compare it to what you obtained in your calculations. 9.6 Exercises Download the exercises. See the answers only after you’ve attempted all the questions. "],
["repro.html", "Chapter 10 Reproducible Workflows 10.1 Learning Objectives 10.2 Resources 10.3 R Markdown 10.4 References", " Chapter 10 Reproducible Workflows 10.1 Learning Objectives 10.1.1 Basic Create a reproducible script in R Markdown Edit the YAML header to add table of contents and other options Include a table Include a figure Use source() to include code from an external file Report the output of an analysis using inline R 10.1.2 Intermediate Output doc and PDF formats Add a bibliography and in-line citations Format tables using kableExtra 10.1.3 Advanced Create a computationally reproducible project in Code Ocean 10.2 Resources Chapter 27: R Markdown in R for Data Science R Markdown Cheat Sheet R Markdown reference Guide R Markdown Tutorial R Markdown: The Definitive Guide by Yihui Xie, J. J. Allaire, &amp; Garrett Grolemund Papaja Reproducible APA Manuscripts Code Ocean for Computational Reproducibility 10.3 R Markdown library(tidyverse) By now you should be pretty comfortable working with R Markdown files from the weekly formative exercises and set exercises. Here, we’ll explore some of the more advanced options and create an R Markdown document that produces a reproducible manuscript. First, make a new R Markdown document. 10.3.1 knitr options When you create a new R Markdown file in RStudio, a setup chunk is automatically created. ```{r setup, include=FALSE} knitr::opts_chunk$set(echo = TRUE) ``` You can set more default options for code chunks here. See the knitr options documentation for explanations of the possible options. ```{r setup, include=FALSE} knitr::opts_chunk$set( fig.width = 8, fig.height = 5, fig.path = &#39;images/&#39;, echo = FALSE, warning = TRUE, message = FALSE, cache = FALSE ) ``` The code above sets the following options: fig.width = 8 : figure width is 8 inches fig.height = 5 : figure height is 5 inches fig.path = 'images/' : figures are saved in the directory “images” echo = FALSE : do not show code chunks in the rendered document warning = FALSE : do not show any function warnings message = FALSE : do not show any function messages cache = FALSE : run all the code to create all of the images and objects each time you knit (set to TRUE if you have time-consuming code) 10.3.2 YAML Header The YAML header is where you can set several options. --- title: &quot;My Demo Document&quot; author: &quot;Me&quot; output: html_document: theme: spacelab highlight: tango toc: true toc_float: collapsed: false smooth_scroll: false toc_depth: 3 number_sections: false --- The built-in themes are: “cerulean”, “cosmo”, “flatly”, “journal”, “lumen”, “paper”, “readable”, “sandstone”, “simplex”, “spacelab”, “united”, and “yeti”. You can view and download more themes. Try changing the values from false to true to see what the options do. 10.3.3 TOC and Document Headers If you include a table of contents (toc), it is created from your document headers. Headers in markdown are created by prefacing the header title with one or more hashes (#). Add a typical paper structure to your document like the one below. ## Abstract My abstract here... ## Introduction What&#39;s the question; why is it interesting? ## Methods ### Participants How many participants and why? Do your power calculation here. ### Procedure What will they do? ### Analysis Describe the analysis plan... ## Results Demo results for simulated data... ## Discussion What does it all mean? ## References 10.3.4 Code Chunks You can include code chunks that create and display images, tables, or computations to include in your text. Let’s start by simulating some data. First, create a code chunk in your document. You can put this before the abstract, since we won’t be showing the code in this document. We’ll use a modified version of the two_sample function from the GLM lecture to create two groups with a difference of 0.75 and 100 observations per group. This function was modified to add sex and effect-code both sex and group. Using the recode function to set effect or difference coding makes it clearer which value corresponds to which level. There is no effect of sex or interaction with group in these simulated data. two_sample &lt;- function(diff = 0.5, n_per_group = 20) { tibble(Y = c(rnorm(n_per_group, -.5 * diff, sd = 1), rnorm(n_per_group, .5 * diff, sd = 1)), grp = factor(rep(c(&quot;a&quot;, &quot;b&quot;), each = n_per_group)), sex = factor(rep(c(&quot;female&quot;, &quot;male&quot;), times = n_per_group)) ) %&gt;% mutate( grp_e = recode(grp, &quot;a&quot; = -0.5, &quot;b&quot; = 0.5), sex_e = recode(sex, &quot;female&quot; = -0.5, &quot;male&quot; = 0.5) ) } This function requires the tibble and dplyr packages, so remember to load the whole tidyverse package at the top of this script (e.g., in the setup chunk). Now we can make a separate code chunk to create our simulated dataset dat. dat &lt;- two_sample(diff = 0.75, n_per_group = 100) You can use the set.seed function to make sure that you get the same random data back each time. Make sure you don’t ever do this inside of a simulation function, or you will just simulate the exact same data over and over again. 10.3.4.1 Tables Next, create a code chunk where you want to display a table of the descriptives (e.g., Participants section of the Methods). We’ll use tidyverse functions you learned in the data wrangling lectures to create summary statistics for each group. &#96;&#96;&#96;{r, results='asis'} dat %>% group_by(grp, sex) %>% summarise(n = n(), Mean = mean(Y), SD = sd(Y)) %>% rename(group = grp) %>% mutate_if(is.numeric, round, 3) %>% knitr::kable() &#96;&#96;&#96; ## `mutate_if()` ignored the following grouping variables: ## Column `group` group sex n Mean SD a female 50 -0.361 0.796 a male 50 -0.284 1.052 b female 50 0.335 1.080 b male 50 0.313 0.904 Notice that the r chunk specifies the option results='asis'. This lets you format the table using the kable() function from knitr. You can also use more specialised functions from papaja or kableExtra to format your tables. 10.3.4.2 Images Next, create a code chunk where you want to display the image in your document. Let’s put it in the Results section. Use what you learned in the data visualisation lecture to show violin-boxplots for the two groups. &#96;&#96;&#96;{r, fig1, fig.cap=\"Figure 1. Scores by group and sex.\"} ggplot(dat, aes(grp, Y, fill = sex)) + geom_violin(alpha = 0.5) + geom_boxplot(width = 0.25, position = position_dodge(width = 0.9), show.legend = FALSE) + scale_fill_manual(values = c(\"orange\", \"purple\")) + xlab(\"Group\") + ylab(\"Score\") + theme(text = element_text(size = 30, family = \"Times\")) &#96;&#96;&#96; The last line changes the default text size and font, which can be useful for generating figures that meet a journal’s requirements. Figure 10.1: Figure 1. Scores by group and sex. You can also include images that you did not create in R using the typical markdown syntax for images: ![All the Things by [Hyperbole and a Half](http://hyperboleandahalf.blogspot.com/)](images/x-all-the-things.png) All the Things by Hyperbole and a Half 10.3.4.3 In-line R Now let’s use what you learned in the GLM lecture to analyse our simulated data. The document is getting a little cluttered, so let’s move this code to external scripts. Create a new R script called “functions.R” Move the library(tidyverse) line and the two_sample() function definition to this file. Create a new R script called “analysis.R” Move the code for creating dat to this file. Add the following code to the end of the setup chunk: source(&quot;functions.R&quot;) source(&quot;analysis.R&quot;) The source function lets you include code from an external file. This is really useful for making your documents readable. Just make sure you call your source files in the right order (e.g., include function definitions before you use the functions). In the “analysis.R” file, we’re going to run the analysis code and save any numbers we might want to use in our manuscript to variables. grp_lm &lt;- lm(Y ~ grp_e * sex_e, data = dat) stats &lt;- grp_lm %&gt;% broom::tidy() %&gt;% mutate_if(is.numeric, round, 3) The code above runs our analysis predicting Y from the effect-coded group variable grp_e, the effect-coded sex variable sex_e and their intereaction. The tidy function from the broom package turns the output into a tidy table. The mutate_if function uses the function is.numeric to check if each column should be mutated, adn if it is numeric, applies the round function with the digits argument set to 3. If you want to report the results of the analysis in a paragraph istead of a table, you need to know how to refer to each number in the table. Like with everything in R, there are many wways to do this. One is by specifying the column and row number like this: stats$p.value[2] ## [1] 0 Another way is to create variables for each row like this: grp_stats &lt;- filter(stats, term == &quot;grp_e&quot;) sex_stats &lt;- filter(stats, term == &quot;sex_e&quot;) ixn_stats &lt;- filter(stats, term == &quot;grp_e:sex_e&quot;) Add the above code to the end of your analysis.R file. Then you can refer to columns by name like this: grp_stats$p.value sex_stats$statistic ixn_stats$estimate ## [1] 0 ## [1] 0.197 ## [1] -0.099 You can insert these numbers into a paragraph with inline R code that looks like this: Scores were higher in group B than group A (B = &#96;r grp_stats$estimate&#96;, t = &#96;r grp_stats$statistic&#96;, p = &#96;r grp_stats$p.value&#96;). There was no significant difference between men and women (B = &#96;r sex_statsestimate&#96;, t = &#96;r sex_stats$statistic&#96;, p = &#96;r sex_stats$p.value&#96;) and the effect of group was not qualified by an interaction with sex (B = &#96;r ixn_stats$estimate&#96;, t = &#96;r ixn_stats$statistic&#96;, p = &#96;r ixn_stats$p.value&#96;). Rendered text: Scores were higher in group B than group A (B = 0.647, t = 4.74, p = 0). There was no significant difference between men and women (B = 0.027, t = 0.197, p = 0.844) and the effect of group was not qualified by an interaction with sex (B = -0.099, t = -0.363, p = 0.717). Remember, line breaks are ignored when you render the file (unless you add two spaces at the end of lines), so you can use line breaks to make it easier to read your text with inline R code. The p-values aren’t formatted in APA style. We wrote a function to deal with this in the function lecture. Add this function to the “functions.R” file and change the inline text to use the report_p function. report_p &lt;- function(p, digits = 3) { if (!is.numeric(p)) stop(&quot;p must be a number&quot;) if (p &lt;= 0) warning(&quot;p-values are normally greater than 0&quot;) if (p &gt;= 1) warning(&quot;p-values are normally less than 1&quot;) if (p &lt; .001) { reported = &quot;p &lt; .001&quot; } else { roundp &lt;- round(p, digits) fmt &lt;- paste0(&quot;p = %.&quot;, digits, &quot;f&quot;) reported = sprintf(fmt, roundp) } reported } Scores were higher in group B than group A (B = &#96;r grp_stats$estimate&#96;, t = &#96;r grp_stats$statistic&#96;, &#96;r report_p(grp_stats$p.value, 3)&#96;). There was no significant difference between men and women (B = &#96;r sex_stats$estimate&#96;, t = &#96;r sex_stats$statistic&#96;, &#96;r report_p(sex_stats$p.value, 3)&#96;) and the effect of group was not qualified by an interaction with sex (B = &#96;r ixn_stats$estimate&#96;, t = &#96;r ixn_stats$statistic&#96;, &#96;r report_p(ixn_stats$p.value, 3)&#96;). Rendered text: Scores were higher in group B than group A (B = 0.647, t = 4.74, p &lt; .001). There was no significant difference between men and women (B = 0.027, t = 0.197, p = 0.844) and the effect of group was not qualified by an interaction with sex (B = -0.099, t = -0.363, p = 0.717). You might also want to report the statistics for the regression. There are a lot of numbers to format and insert, so it is easier to do this in the analysis script using sprintf for formatting. s &lt;- summary(grp_lm) # calculate p value from fstatistic fstat.p &lt;- pf(s$fstatistic[1], s$fstatistic[2], s$fstatistic[3], lower=FALSE) adj_r &lt;- sprintf( &quot;The regression equation had an adjusted $R^{2}$ of %.3f ($F_{(%i, %i)}$ = %.3f, %s).&quot;, round(s$adj.r.squared, 3), s$fstatistic[2], s$fstatistic[3], round(s$fstatistic[1], 3), report_p(fstat.p, 3) ) Then you can just insert the text in your manuscript like this: ` adj_r`: The regression equation had an adjusted \\(R^{2}\\) of 0.090 (\\(F_{(3, 196)}\\) = 7.546, p &lt; .001). 10.3.5 Bibliography There are several ways to do in-text citations and automatically generate a bibliography in RMarkdown. 10.3.5.1 Create a BibTeX File Manually You can just make a BibTeX file and add citations manually. Make a new Text File in RStudio called “bibliography.bib”. Next, add the line bibliography: bibliography.bib to your YAML header. You can add citations in the following format: @article{shortname, author = {Author One and Author Two and Author Three}, title = {Paper Title}, journal = {Journal Title}, volume = {vol}, number = {issue}, pages = {startpage--endpage}, year = {year}, doi = {doi} } 10.3.5.2 Citing R packages You can get the citation for an R package using the function citation. You can paste the bibtex entry into your bibliography.bib file. Make sure to add a short name (e.g., “rmarkdown”) before the first comma to refer to the reference. citation(package=&quot;rmarkdown&quot;) ## ## To cite the &#39;rmarkdown&#39; package in publications, please use: ## ## JJ Allaire and Yihui Xie and Jonathan McPherson and Javier ## Luraschi and Kevin Ushey and Aron Atkins and Hadley Wickham and ## Joe Cheng and Winston Chang and Richard Iannone (2019). ## rmarkdown: Dynamic Documents for R. R package version 1.13. URL ## https://rmarkdown.rstudio.com. ## ## Yihui Xie and J.J. Allaire and Garrett Grolemund (2018). R ## Markdown: The Definitive Guide. Chapman and Hall/CRC. ISBN ## 9781138359338. URL https://bookdown.org/yihui/rmarkdown. ## ## To see these entries in BibTeX format, use &#39;print(&lt;citation&gt;, ## bibtex=TRUE)&#39;, &#39;toBibtex(.)&#39;, or set ## &#39;options(citation.bibtex.max=999)&#39;. 10.3.5.3 Download Citation Info You can get the BibTeX formatted citation from most publisher websites. For example, go to the publisher’s page for Equivalence Testing for Psychological Research: A Tutorial, click on the Cite button (in the sidebar or under the bottom Explore More menu), choose BibTeX format, and download the citation. You can open up the file in a text editor and copy the text. It should look like this: @article{doi:10.1177/2515245918770963, author = {Daniël Lakens and Anne M. Scheel and Peder M. Isager}, title ={Equivalence Testing for Psychological Research: A Tutorial}, journal = {Advances in Methods and Practices in Psychological Science}, volume = {1}, number = {2}, pages = {259-269}, year = {2018}, doi = {10.1177/2515245918770963}, URL = { https://doi.org/10.1177/2515245918770963 }, eprint = { https://doi.org/10.1177/2515245918770963 } , abstract = { Psychologists must be able to test both for the presence of an effect and for the absence of an effect. In addition to testing against zero, researchers can use the two one-sided tests (TOST) procedure to test for equivalence and reject the presence of a smallest effect size of interest (SESOI). The TOST procedure can be used to determine if an observed effect is surprisingly small, given that a true effect at least as extreme as the SESOI exists. We explain a range of approaches to determine the SESOI in psychological science and provide detailed examples of how equivalence tests should be performed and reported. Equivalence tests are an important extension of the statistical tools psychologists currently use and enable researchers to falsify predictions about the presence, and declare the absence, of meaningful effects. } } Paste the reference into your bibliography.bib file. Change doi:10.1177/2515245918770963 in the first line of the reference to a short string you will use to cite the reference in your manuscript. We’ll use TOSTtutorial. 10.3.5.4 Converting from reference software Most reference software like EndNote, Zotero or mendeley have exporting options that can export to BibTeX format. You just need to check the shortnames in the resulting file. 10.3.5.5 In-text citations You can cite reference in text like this: This tutorial uses several R packages [@tidyverse;@rmarkdown]. This tutorial uses several R packages (Wickham 2017; Allaire et al. 2018). Put a minus in front of the @ if you just want the year: Lakens, Scheel and Isengar [-@TOSTtutorial] wrote a tutorial explaining how to test for the absence of an effect. Lakens, Scheel and Isengar (2018) wrote a tutorial explaining how to test for the absence of an effect. 10.3.5.6 Citation Styles You can search a list of style files for various journals and download a file that will format your bibliography for a specific journal’s style. You’ll need to add the line csl: filename.csl to your YAML header. Add some citations to your bibliography.bib file, reference them in your text, and render your manuscript to see the automatically generated reference section. Try a few different citation style files. 10.3.6 Output Formats You can knit your file to PDF or Word if you have the right packages installed on your computer. 10.3.7 Computational Reproducibility Computational reproducibility refers to making all aspects of your analysis reproducible, including specifics of the software you used to run the code you wrote. R packages get updated periodically and some of these updates may break your code. Using a computational reproducibility platform guards against this by always running your code in the same environment. Code Ocean is a new platform that lets you run your code in the cloud via a web browser. 10.4 References D References "],
["acknowledgements.html", "Acknowledgements 10.5 Contributors", " Acknowledgements The whole psyTeachR team at the University of Glasgow School of Psychology deserves enormous thanks for making it possible and rewarding to teach methods with a focus on reproducibility and open science. Particularly Heather Cleland Woods, Phil McAleer, Helena Paterson, Emily Nordmann, Benedict Jones, and Niamh Stack. We greatly appreciate Iris Holzleitner’s volunteer in-class assistance with the first year of this course. We were ever so lucky to get Rebecca Lai as a teaching assistant in the second year; her kind and patient approach to teaching technical skills is an inspiration. Thanks to Daniël Lakens for many inspirational discussions and resources. 10.5 Contributors Several people contributed to testing these materials. Mossa Merhi Reimert "],
["installing-r.html", "A Installing R A.1 Installing Base R A.2 Installing RStudio A.3 Installing LaTeX", " A Installing R Installing R and RStudio is usually straightforward. The sections below explain how and there is a helpful YouTube video here. A.1 Installing Base R Install base R from https://cran.rstudio.com/. Choose the download link for your operating system (Linux, Mac OS X, or Windows). If you have a Mac, install the latest release from the newest R-x.x.x.pkg link (or a legacy version if you have an older operating system). After you install R, you should also install XQuartz to be able to use some visualisation packages. If you are installing the Windows version, choose the “base” subdirectory and click on the download link at the top of the page. After you install R, you should also install RTools; use the “recommended” version highlighted near the top of the list. If you are using Linux, choose your specific operating system and follow the installation instructions. A.2 Installing RStudio Go to rstudio.com and download the RStudio Desktop (Open Source License) version for your operating system under the list titled Installers for Supported Platforms. A.3 Installing LaTeX You can install the LaTeX typesetting system to produce PDF reports from RStudio. Without this additional installation, you will be able to produce reports in HTML but not PDF. To generate PDF reports, you will additionally need: pandoc, and LaTeX, a typesetting language, available for WINDOWS: MikTeX Mac OS: MacTex (3.2GB download) or BasicTeX (78MB download, but should work fine) Linux: TeX Live "],
["symbols.html", "B Symbols", " B Symbols Symbol psyTeachR Term Also Known As () (round) brackets parentheses [] square brackets brackets {} curly brackets squiggly brackets &lt;&gt; chevrons angled brackets / guillemets &lt; less than &gt; greater than &amp; ampersand “and” symbol # hash pound / octothorpe / slash forward slash \\ backslash - dash hyphen / minus _ underscore * asterisk star ^ caret power symbol ~ tilde twiddle / squiggle = equal sign == double equal sign . full stop period / point ! exclamation mark bang / not ? question mark ’ single quote quote / apostrophe &quot; double quote quote %&gt;% pipe magrittr pipe | vertical bar pipe , comma ; semi-colon : colon @ “at” symbol various hilarious regional terms "],
["exercise-answers.html", "C Exercise Answers", " C Exercise Answers Download all exercises and data files below as a ZIP archive. The answers are not included in the zip file. 01 intro (answers): Intro to R, functions, R markdown 02 data (answers): Vectors, tabular data, data import, pipes Essential Skills (answers): You must be able to complete these exercises to advance in the class beyond the first two lectures 03 ggplot (answers): Data visualisation 04 tidyr (answers): Tidy Data 05 dplyr (answers): Data wrangling 06 joins (answers): Data relations 07 functions (answers): Functions and iteration 08 simulation (answers): Simulation 09 glm (answers): GLM "],
["references-1.html", "D References", " D References "]
]
