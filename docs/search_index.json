[
["index.html", "Data Skills Chapter 1 Overview 1.1 Course Aims 1.2 Intended Learning Outcomes 1.3 Formative Exercises 1.4 Resources", " Data Skills Dale J Barr &amp; Lisa M. DeBruine 2019-01-19 Chapter 1 Overview This course provides an overview of skills needed for reproducible research and open science using the statistical programming language R. Students will learn about data visualisation, data tidying and wrangling, archiving, iteration and functions, probability and data simulations, general linear models, and reproducible workflows. Learning is reinforced through weekly assignments that involve working with different types of data. It is taught by Dale Barr and Lisa DeBruine. 1.1 Course Aims This course aims to teach students the basic principles of reproducible research and to provide practical training in data processing and analysis in the statistical programming language R. 1.2 Intended Learning Outcomes By the end of this course students will be able to: write scripts in R to organise and transform data sets using best accepted practices; explain basics of probability and its role in statistical inference; analyse data and report descriptive and inferential statistics in a reproducible manner. 1.3 Formative Exercises Exercises are available at the end of each lesson’s webpage. These are not marked or mandatory, but if you can work through each of these (using web resources, of course), you will easily complete the marked assessments. 01 Intro: Intro to R, functions 02 Intro: Vectors, tabular data, data import, pipes Essential Skills: You must be able to complete these exercises to advance in the class beyond the first two lectures 03 ggplot: Data visualisation 04 wrangle1: Data wrangling (mostly tidyr) 05 wrangle2: Data wrangling (mostly dplyr) 06 joins: Data relations 07 functions: Functions and Iteration 08 simulation: Simulation 1.4 Resources Miscellanous materials added throughout the semester, such tips on installation, or the results of live-coding demos, can be found in the Miscellaneous section. Glasgow Psychology RStudio Learning Statistics with R by Navarro R for Data Science by Grolemund and Wickham 1.4.1 Online tutorials swirl R for Reproducible Scientific Analysis codeschool.com datacamp Improving your statistical inferences on Coursera 1.4.2 Cheat sheets You can access several cheatsheets in RStudio under the Help menu Or get the most recent RStudio Cheat Sheets 1.4.3 Other Style guide for R programming type browseVignettes(&quot;name_of_package&quot;) to learn about add-on packages #rstats on twitter highly recommended! "],
["intro.html", "Chapter 2 Introduction 2.1 Learning Objectives 2.2 Resources 2.3 What is R? 2.4 Interacting with R 2.5 Developing reproducible scripts 2.6 Typing in commands 2.7 Some basic data types 2.8 Add-on packages 2.9 Getting help 2.10 Exercises", " Chapter 2 Introduction 2.1 Learning Objectives Understand the R console and the components of the RStudio IDE Use R as a calculator Creating vectors and storing as variables Understand vectorized operations Understand function syntax Appropriately structure an R script Create and compile an Rmarkdown document 2.2 Resources Chapter 1: Introduction in R for Data Science RStudio IDE Cheatsheet If you need tips on how to install R/RStudio, head on over to the Miscellaneous section. 2.3 What is R? A programming environment for data processing and statistical analysis free and open-source community supported continually evolving promotes reproducible research 2.4 Interacting with R 2.4.1 The Base R Console R is was developed almost two decades ago, and has a longer history as a derivative language of the scripting language S-PLUS developed in Bell Labs in the 70s and 80s. “Base R” consists of a “Read Evaluate Print Loop” (REPL) command interpreter, in which you type in text commands, which are evaluated, and the results of which are printed to the screen. This “R Console” window looks something like this. 2.4.2 The RStudio Integrated Development Environment (IDE) However, when you are developing a script, you will want to work in a text editor and send commands to the console, rather than typing directly into the console. Developing an analysis script is R is essentially an exercise in programming, and for developing code it is best to use an Integrated Development Environment or IDE. An IDE provides additional functionality that wraps around the basic console. The IDE that is highly recommended for this class is by RStudio (http://www.rstudio.com) and is depicted above. This IDE provides multiple windows in additional to the console that greatly facilitate developing code. In addition to the console (appearing as the bottom left window in the above figure), there is a script editor (top left), which provides syntax highlighting, autocompletion, and pop-up tool tips, a window showing functions and objects residing in memory for the session in the “Environment” tab (top right window in the figure), and a window that shows plots, files in the working directory, available add-on packages, and documentation (bottom right). You will install both base R and RStudio, but will interact with R through the RStudio IDE. You will have icons for both RStudio and for a very primitive IDE called “R commander” which comes packaged with R. R commander is not as sophisticated or user-friendly as RStudio, so make sure you launch the RStudio IDE and not R commander by clicking on the correct icon. Launch RStudio will also launch the R console, so that is all you need to click. ALWAYS REMEMBER: Launch R though the RStudio IDE If you are an experienced programmer, you might want to consider using Emacs + ESS + Org Mode as an IDE instead of RStudio. See this link if you want to go this advanced route. 2.5 Developing reproducible scripts Here is what an R script looks like. Don’t worry about the details for now. # load add-on packages library(tidyverse) # define custom functions cumulativeToTarget &lt;- function(x) { sessID &lt;- x$SessionID[1] # etc... do some other stuff return(res) } ## SCRIPT BEGINS HERE load(file = &quot;pog.RData&quot;) pog2 &lt;- pog %&gt;% filter(ms &gt;= -200 &amp; ms &lt;= 1000) %&gt;% filter(FrameID &lt;= 600) %&gt;% select(-ms) %&gt;% do(cumulativeToTarget(.)) %&gt;% ungroup %&gt;% mutate(ms = (FrameID-1) * 2 - 200, ID = factor(ID)) save(pog2, file = &quot;pog2.RData&quot;) All scripts will have the following structure: load in any add-on packages you need to use define any custom functions load in the data you will be working with work with the data save anything you need to save Its best if you follow the above convention when developing your own scripts. 2.5.1 Configure RStudio for Maximum Reproducibility In this class, you will be learning how to develop reproducible scripts. This means scripts that completely and transparently perform some analysis from start to finish in a way that yields the same result for different people using the same software on different computers. And transparency is a key value of science, as embodied in the “trust but verify” motto. When you do things reproducibly, others can understand and check your work. This benefits science, but there is a selfish reason, too: the most important person who will benefit from a reproducible script is your future self. When you return to an analysis after two weeks of vacation, you will thank your earlier self for doing things in a transparent, reproducible way, as you can easily pick up right where you left off. There are two tweaks that you should do to your RStudio installation to maximize reproducibility. Go to the setting menu, and uncheck the box that says “Restore .RData into workspace at startup”. If you keep things around in your workspace, things will get messy, and unexpected things will happen. You should always start with a clear workspace. This also means that you never want to save your workspace when you exit, so set this to “Never”. The only thing you want to save are your scripts. 2.5.2 Reproducible reports with RStudio and RMarkdown We will be working toward producing reproducible reports following the principles of “literate programming”. The basic idea is to have the text of the report together in a single document along with the R code needed to perform all analyses and generate the tables. The report is then ’compiled’ from the original format into some other, more portable format, such as HTML or PDF. This is different from traditional cutting and pasting approaches where, for instance, you create a graph in Microsoft Excel or a statistics program like SPSS and then paste it into Microsoft Word. We will be using RMarkdown to create reproducible reports, which enables interleaving text with R code blocks. You can read more about Donald Knuth’s idea about literate programming at this Wikipedia page, and about the RMarkdown format here. A reproducible script will contain sections of code in code blocks. A code block is delimited using three backtick symbols in a row, like so: This is just some text before the code block ` ``{r blockname} # now we are inside the R code block rnorm(10) # generate some random numbers ` `` now we&#39;re back outside the code block If you open up a new RMarkdown file from a template, you will see an example document with several code blocks in it. To create an HTML or PDF report from an rmarkdown (rmd) document, you compile it. Compiling a document is called ’knitting’ in RStudio. There is a button that looks like a ball of yarn with needles through it that you click on to compile your file into a report. Try it with the template file and see what happens! 2.6 Typing in commands We are first going to learn about how to interact with the console. In generally, you will be developing R scripts or R markdown files, rather than working directly in the console window. However, you can consider the console a kind of ’sandbox’ where you can try out lines of code and adapt them until you get them to do what you want. Then you can copy them back into the script editor. Mostly, however, you will be typing into the script editor window (either into an R script or an RMarkdown file) and then sending the commands to the console by placing the cursor on the line and holding down the Ctrl key while you press Enter. The Ctrl+Enter key sequence sends the command in the script to the console. 2.6.1 Warming up: Use R as a calculator One simple way to learn about the R console is to use it as a calculator. Enter the lines of code below and see if your results match. Be prepared to make lots of typos (at first) :/ ## REPL: Read/Evaluate/Print Loop ## R prints results back at you 1 + 1 ## [1] 2 The R console remembers a history of the commands you typed in the past. Use the up and down arrow keys on your keyboard to scroll backwards and forwards through your history. It’s a lot faster than re-typing. 1 + 1 + 3 ## [1] 5 You can break up math expressions over multiple lines; R waits for a complete expression before processing it. ## here comes a long expression ## let&#39;s break it over multiple lines 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 ## [1] 55 &quot;Good afternoon&quot; ## [1] &quot;Good afternoon&quot; You can break up text over multiple lines; R waits for a close quote before processing it. &quot;There is nothing in the world that makes people so unhappy as fear. The misfortune that befalls us is seldom, or never, as bad as that which we fear. - Friedrich Schiller&quot; ## [1] &quot;There is nothing in the world \\nthat makes people so unhappy as fear. \\nThe misfortune that befalls us is \\nseldom, or never, as bad as that \\nwhich we fear.\\n\\n- Friedrich Schiller&quot; You can add comments to an R script by with the ’#’ symbol. The R interpreter will ignore characters from the # symbol to the end of the line. ## comments: any text from &#39;#&#39; on is ignored until end of line 22 / 7 # approximation to pi ## [1] 3.142857 2.6.2 Storing results in a variable Often you want to store the result of some computation for later use. You can store it in a variable. There are some important things to consider when naming your variables. capitalization matters (myVar is different from myvar) don’t use spaces or special characters (^&amp;&quot;'*+?) etc.; use the ’_’ where you would use a space (e.g., my_var is a legal variable name) must begin with a letter (m2 is a valid name, but 2m is not) Use the assignment operator &lt;- to assign the value on the right to the variable named on the left. ## use the assignment operator &#39;&lt;-&#39; ## R stores the number in the variable x &lt;- 5 Now that we have set x to a value, we can do something with it: x * 2 ## [1] 10 ## R evaluates the expression and stores the result in the variable boring_calculation &lt;- 2 + 2 Note that it doesn’t print the result back at you when it’s stored. To view the result, just type the variable name on a blank line. boring_calculation ## [1] 4 2.6.3 Whitespace # R waits until next line for evaluation (3 + 2) * 5 ## [1] 25 # often useful to spread function arguments over multiple lines library(cowsay) say(&quot;This function call is far too wide to fit all on one line&quot;, &quot;stretchycat&quot;) ## Colors cannot be applied in this environment :( Try using a terminal or RStudio. ## ## -------------- ## This function call is far too wide to fit all on one line ## -------------- ## \\ ## \\ ## \\ ## ,/| _.--‛‛^``-...___.._.,; ## /, \\‛. _-‛ ,--,,,--‛‛‛ ## { \\ `_-‛‛ ‛ /}‛ ## Jill `;;‛ ; ; ; ## ._.--‛‛ ._,,, _..‛ .;.‛ ## (,_....----‛‛‛ (,..--‛‛ ## When you see &gt; at the beginning of a line, that means R is waiting for you to start a new command. However, if you see a + instead of &gt; at the start of the line, that means R is waiting for you to finish a command you started on a previous line. If you want to cancel whatever command you started, just press the Esc key in the console window and you’ll get back to the &gt; command prompt. 2.6.4 The workspace Anytime you assign something to a new variable, R creates a new object in your workspace. Objects in your workspace exist until you end your session; then they disappear forever (unless you save them). ls() # print the objects in the workspace ## [1] &quot;boring_calculation&quot; &quot;x&quot; rm(&quot;x&quot;) # remove the object named x from the workspace rm(list = ls()) # clear out the workspace 2.6.5 Vectors Vectors are one of the key data structures in R. A vector in R is like a vector in math: a set of ordered elements. All of the elements in a vector must be of the same data type (numeric, character, factor). You can create a vector by enclosing the elements in c(...), as shown below. ## put information into a vector using c(...) c(1, 2, 3) ## [1] 1 2 3 c(&quot;this&quot;, &quot;is&quot;, &quot;cool&quot;) ## [1] &quot;this&quot; &quot;is&quot; &quot;cool&quot; ## what happens when you mix types? c(2, &quot;good&quot;, 2, &quot;b&quot;, &quot;true&quot;) ## [1] &quot;2&quot; &quot;good&quot; &quot;2&quot; &quot;b&quot; &quot;true&quot; 2.6.5.1 Vectorized Operations R performs calculations on vectors in a special way. Let’s look at an example using \\(z\\)-scores. A \\(z\\)-score is a deviation score (a score minus a mean) divided by a standard deviation. Let’s say we have a set of four IQ scores. ## example IQ scores: mu = 100, sigma = 15 iq &lt;- c(86, 101, 127, 99) If we want to subtract the mean from these four scores, we just use the following code: iq - 100 ## [1] -14 1 27 -1 This subtracts 100 from each element of the vector. R automatically assumes that this is what you wanted to do; it is called a vectorized operation and it makes it possible to express operations more efficiently. To calculate \\(z\\)-scores we use the formula: \\(z = \\frac{X - \\mu}{\\sigma}\\) where X are the scores, \\(\\mu\\) is the mean, and \\(\\sigma\\) is the standard deviation. We can expression this formula in R as follows: ## z-scores (iq - 100) / 15 ## [1] -0.93333333 0.06666667 1.80000000 -0.06666667 You can see that it computed all four \\(z\\)-scores with a single line of code. Very efficient! 2.6.6 Function syntax A lot of what you do in R involves calling functions and storing the results. Functions have the following generic syntax: functionname(arg1, arg2, arg3, ...) Each function has named arguments which may or may not have default values. Arguments without default values are mandatory; arguments with these values are optional. If an optional argument is not specified, it will take on the default value. You can override default values by supplying your own. Arguments can be specified by: position (unnamed) name Most functions return a value, but may also produce ’side effects’ like printing to the console. To illustrate, the function rnorm() generates random numbers from the standard normal distribution. The help page for rnorm() (accessed by typing ?rnorm in the console) shows that it has the syntax rnorm(n, mean = 0, sd = 1) where n is the number of randomly generated numbers you want, mean is the mean of the distribution, and sd is the standard deviation. The default mean is 0, and the default standard deviation is 1. There is no default for n which means you’ll get an error if you don’t specify it: rnorm() Error in rnorm() : argument &quot;n&quot; is missing, with no default If you want 10 random numbers from a distribution with mean of 0 and standard deviation, you can just use the defaults. rnorm(10) ## [1] -0.1874381 -0.2029608 0.8886399 -0.7383253 0.2862487 1.7031816 ## [7] -0.1149489 -0.5135914 0.3826321 0.4672715 If you want 10 numbers from a distribution with a mean of 100: rnorm(10, 100) ## [1] 100.19360 100.11621 100.94846 98.34609 100.93906 100.16563 99.48958 ## [8] 100.20177 98.65161 98.72387 This would be an equivalent but less efficient way of calling the function: rnorm(n = 10, mean = 100) ## [1] 99.24258 101.42987 99.62313 97.29374 101.72741 98.55789 99.23251 ## [8] 100.79858 98.50480 100.44233 We don’t need to name the arguments because R will recognize that we intended to fill in the first and second arguments by their position in the function call. However, if we want to change the default for an argument coming later in the list, then we need to name it. For instance, if we wanted to keep the default mean = 0 but change the standard deviation to 100 we would do it this way: rnorm(10, sd = 100) ## [1] -0.7958489 21.4951583 125.1569907 -49.2678773 -110.3726026 ## [6] 97.5195391 -53.5448295 20.4973747 -0.5534210 53.0278038 2.7 Some basic data types Below are a list of different data types in R. type description example double floating point value .333337 integer integer -1, 0, 1 numeric any real number (int,dbl) 1, .5, -.222 boolean assertion of truth/falsity TRUE, FALSE character text string &quot;hello world&quot;, 'howdy' Wonder what type a particular variable is? Use class() to find out 2.8 Add-on packages One of the great things about R is that it is user extensible: anyone can create a new add-on software package that extends its functionality. There are currently thousands of add-on packages that R users have created to solve many different kinds of problems, or just simply to have fun. There are packages for data visualisation, machine learning, neuroimaging, eyetracking, web scraping, and playing games such as Sudoku. Add-on packages are not distributed with base R, but have to be downloaded and installed from an archive, in the same way that you would, for instance, download and install a fitness app on your smartphone. The main repository where packages reside is called CRAN, the Comprehensive R Archive Network. A package has to pass strict tests devised by the R core team to be allowed to be part of the CRAN archive. You can install from the CRAN archive through R using the install.packages() function. There is an important distinction between installing a package and loading a package. Installing a package is done using install.packages(). This is like installing an app on your smartphone: you only have to do it once and the app will remain installed until you remove it. For instance, if you want to use Facebook on your phone you install it once from the App Store or Play Store, and you don’t have to re-install it each time you want to use it. Once you launch the app, it will run in the background until you close it or restart your phone. Likewise, when you install a package, the package will be available (but not loaded) every time you open up R. Loading a package: This is done using library(packagename). This is like launching an app on your phone: the functionality is only there where the app is launched and remains there until you close the app or restart. Likewise, when you run library(packagename) within a session, the functionality of the package referred to by packagename will be made available for your R session. The next time you start R, you will need to run the library() function again if you want to access its functionality. You may only be able to permanently install packages if you are using R on your own system; you may not be able to do this on public workstations because you will lack the appropriate privileges. Try installing the library fortunes on your system: install.packages(&quot;fortunes&quot;) If you don’t get an error message, the installation was successful. You can then access the functionality of fortune for your current R session as follows: library(fortunes) Once you have typed this, you can run the function fortune(), which spouts random wisdom from one of the R help lists: fortune() ## ## Jim Gustafsson: I would like to put my SAS-code into R. Could I do that, ## if yes, how? ## Frank Harrell: Just reverse the procedure you use when you put R code into ## SAS. ;) ## -- Jim Gustafsson and Frank Harrell ## R-help (February 2004) Note that we will use the convention package::function() and package::object to indicate in which add-on package a function or object resides. For instance, if you see readr::read_csv(), that refers to the function read_csv() in the readr add-on package. If you see a function introduced without a package name, that means it is part of the base R system and not an add-on package (depending on the context). Sometimes I will make this explicit by using base in the place of the package name; for instance, I might refer to rnorm() in base as base::rnorm(). 2.9 Getting help # these methods are all equivalent ways of getting help help(&quot;say&quot;) # if package &#39;cowsay&#39; is loaded ?say help(&quot;say&quot;, package=&quot;cowsay&quot;) # if cowsay not loaded ??say # search for help files with &quot;say&quot; # start up help in a browser help.start() 2.10 Exercises Download the first set of formative exercises. We will be working with the cowsay add-on package (help(package = &quot;cowsay&quot;)) Check to see if there are any vignettes available for this package. vignette(package = &quot;cowsay&quot;) Load in and read the vignette to get an idea of how the package works. vignette(&quot;cowsay_tutorial&quot;, package = &quot;cowsay&quot;) Your first task is to develop a reproducible script that accomplishes the tasks below. Compile the RMarkdown (rmd) document into HTML. Make sure the report includes the code in addition to the output. Important! Try to perform each task making the shortest function call you can by taking advantage of the function defaults and include the results in an R script. Make a cat say, “FEED ME” Make a shark say “Hello world!” Make anything produce a famous quote Make a clippy warn the user about the impending apocalypse Make a cat produce a random quote from an R coder. You should get a different quote every time you run the code (hint: read the documentation for cowsay::say()). Define a variable creature and assign to it the value of one of the types of creatures accepted by the say() function. Then use the variable to output the current time. Change the value of the variable creature to some other thing, and make it display the time using the date() function in base R. Restart R and re-run the script to check whether it is reproducible. Advanced: Create an RMarkdown file including each answer below each question heading (question 1-7 only), and compile it to HTML. "],
["intro2.html", "Chapter 3 Introduction 2 3.1 Learning Objectives 3.2 Resources 3.3 Organizing a project 3.4 Structuring your script 3.5 Basic data types 3.6 Basic container types 3.7 Tabular data 3.8 Importing data 3.9 Pipes", " Chapter 3 Introduction 2 3.1 Learning Objectives Organizing a project: directory structure and working directory Appropriately structure an R script or RMarkdown file Understand the use the basic data types (integer, double, character, factor) Understand and use the basic container types (list, vector) Create a simple data table Import data from a CSV and Excel files Combining analysis steps using the magrittr pipe %&gt;% 3.2 Resources Chapter 11: Data Import in R for Data Science RStudio Data Import Cheatsheet Scottish Babynames Developing an analysis in R/RStudio: Scottish babynames (1/2) Developing an analysis in R/RStudio: Scottish babynames (2/2) 3.3 Organizing a project 3.3.1 Working Directory Where should I put all my files? When developing an analysis, you usually want to have all of your scripts and data files in one subtree of your computer’s directory structure. Usually there is a single working directory where your data and scripts are stored. For the purpose of this class, to minimize problems, please store your files on your network drive (usually something like the M: drive or U: drive on a Windows machine.) Your script should only reference files in three locations, using the appropriate format. Where Example on the web “https://github.com/gupsych/data_skills/blob/master/02_intro.Rmd” in the working directory “my_file2.csv” in a subdirectory “subdir/my_file2.csv” Never set or change your working directory in a script; always store your main script file in the top-level directory and manually set your working directory to that location. This means you’ll have to reset the working directory each time you open RStudio, but this is a small price to pay for reproducibility (alternatively, learn about R Projects). For instance, if on a Windows machine your data and scripts live in the directory C:\\Carla's_files\\thesis2\\my_thesis\\new_analysis, you will set your working directory to new_analysis in one of two ways: (1) by going to the Session pull down menu in RStudio and choosing Set Working Directory, or (2) by typing setwd(&quot;C:\\Carla's_files\\thesis2\\my_thesis\\new_analysis&quot;) in the console window. If you ‘knit’ an RMarkdown file, your working directory is automatically set to the same directory where the Rmd file is located during the knitting process. But if you’re planning on running the code chunks individually, you’ll need to manually set the directory. It’s tempting to make your life simple by putting the setwd() command in your script. Don’t do this! Others will not have the same directory tree as you (and when your laptop dies and you get a new one, neither will you). When manually setting the working directory, always do so by using the Session | Set Working Directory pull-down option or by typing setwd() in the console. If your script needs a file in a subdirectory of new_analysis, say, analysis2/dat.rds, load it in using a relative path: dat &lt;- readRDS(&quot;analysis2/dat.rds&quot;) # right way Do not load it in using an absolute path: dat &lt;- readRDS(&quot;C:/Carla&#39;s_files/thesis22/my_thesis/new_analysis/analysis2/dat.rds&quot;) # wrong Also note the convention of using forward slashes, unlike the Windows specific convention of using backward slashes. This is to make references to files platform independent. 3.4 Structuring your script If you structure your R script or RMarkdown file in a predictable way, it will make your life much easier. All scripts should have the following structure: Load any add-on packages you will need Define any custom functions Import data Perform the analysis Consider, for instance, the script that we created in the last session: # Load the add-on packages library(&quot;tidyverse&quot;) library(&quot;ukbabynames&quot;) # If we had created any functions (we didn&#39;t) we would put them here. We will # learn about creating functions later in the course. # Import the data nam0 &lt;- read_csv(&quot;PSYCH5077 Grades-20180921_0719-comma_separated.csv&quot;) %&gt;% select(name = `First name`) # rename the column # The rest of the script performs the analysis nam1 &lt;- tibble(name = c(&quot;Dale&quot;, &quot;Lisa&quot;, &quot;Rebecca&quot;)) nam_uk &lt;- bind_rows(nam0, nam1) %&gt;% inner_join(ukbabynames, &quot;name&quot;) ggplot(nam_uk, aes(x = year, y= n, colour = sex)) + geom_line() + facet_wrap(~name, scales = &quot;free_y&quot;) Often when you are working on a script, you will realize that you need to load another add-on package. Don’t bury the call to library(package_I_need) way down in the script. Put it in the top, so the user has an overview of what packages are needed. When structuring an RMarkdown file, it is generally a good idea to have a single code chunk for each output that is produced in the report; for instance, the above code could all be in a single chunk since the only output we care about is the graph at the end. It is also a good idea to suppress any warnings or messages in the report so that they don’t confuse the reader. You can suppress messages or warnings by using the code chunk options message=FALSE and warning=FALSE. 3.5 Basic data types There are four main basic data types in R (there are more, but these are the critical ones you need to know about). type examples character “hello”, “ABCDE1”, “12 45”, “123.45” integer 10L, 50L, 1L, -20L double aka numeric 10, 3.1415, -99.7, 0.001, -3.5e6 logical TRUE, FALSE There is also a specific data type called a factor which will probably give you a headache sooner or later, but we can get by for now without them. Character strings can include basically anything, including quotes, but if you want a quote to be included you have to ‘escape’ it using a backslash: my_string &lt;- &quot;The instructor said, \\&quot;R is cool,\\&quot; and the class agreed.&quot; my_string ## [1] &quot;The instructor said, \\&quot;R is cool,\\&quot; and the class agreed.&quot; Note that if you just type a plain number such as 10 it is stored as a double, even if it doesn’t have a decimal point. If you want it to be an exact integer, use the L suffix (10L). If you ever want to know the data type of something, use the class function. There is also the mode function which is specifically for vectors. class(10) # numeric ## [1] &quot;numeric&quot; class(10L) # integer ## [1] &quot;integer&quot; class(&quot;10&quot;) # string ## [1] &quot;character&quot; class(10L == 11L) # logical ## [1] &quot;logical&quot; mode(TRUE) ## [1] &quot;logical&quot; 3.6 Basic container types 3.6.1 Vectors OK, here’s a question. When you type a single number in the console, it spits it back out to you, like this: 3L ## [1] 3 Why is there a [1] there? i.e., what does the [1] in the [1] 3 refer to? We’ll eventually get to the answer, but let’s see if you can discover it yourself through experiment. There is an operator : that, when placed between two integers x and y like so: x:y will yield the sequence of integers from x to y inclusive. Let’s make a big long vector of numbers and print it out. vec &lt;- 200:400 vec ## [1] 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 ## [18] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 ## [35] 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 ## [52] 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 ## [69] 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 ## [86] 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 ## [103] 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 ## [120] 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 ## [137] 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 ## [154] 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 ## [171] 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 ## [188] 387 388 389 390 391 392 393 394 395 396 397 398 399 400 Note the number in square brackets on the left hand side of the output. Note that vec is a vector: an ordered container of 200 elements, in this case, the integers from 200 to 400. The bracked number on the left hand side tells you the numeric index (i.e., element number) corresponding to the first value in that row. So the first value is 200, the 19th value is 218, the 37th value is 236, etc. Recall from the last class that another way to create a vector is to use the c() operator. (This is the easiest way, but you can also use the vector() function.) If we wanted to pick specific values out of the vector by position, we can make a vector of numbers like so: c(1L, 19L, 37L, 55L) ## [1] 1 19 37 55 And then pull them out using the [] operator, which is the extraction operator, on the variable vec. vec[c(1L, 19L, 37L, 55L)] ## [1] 200 218 236 254 ## note also: index &lt;- c(1L, 19L, 37L, 55L) vec[index] ## [1] 200 218 236 254 vec[c(1L, 1L, 19L, 19L, 19L, 19L)] ## [1] 200 200 218 218 218 218 OK let’s return to our original question: why did we get [1] 3 when we just typed 3L? The answer should now be clear: when we entered a single number, R created a vector with a single element. You can also create ‘named’ vectors, where each elements has a name. For example: vec2 &lt;- c(first = 77.9, second = -13.2, third = 100.1) vec2 ## first second third ## 77.9 -13.2 100.1 We can then access elements by name using a character vector within the square brackets. We can put them in any order we want, and we can repeat elements: vec2[c(&quot;third&quot;, &quot;second&quot;, &quot;second&quot;)] ## third second second ## 100.1 -13.2 -13.2 We can get the vector of names using the names() function, and we can set or change them using something like names(vec2) &lt;- c(&quot;n1&quot;, &quot;n2&quot;, &quot;n3&quot;). Another way to access elements is by using a logical vector within the square brackets. This will pull out the elements of the vector for which the corresponding element of the logical vector is TRUE. The logical vector must have the same length as the original. You can find out how long a vector is using the length() function. length(vec2) ## [1] 3 vec2[c(TRUE, FALSE, TRUE)] ## first third ## 77.9 100.1 Here are some useful tricks to save typing when creating vectors. Recall that in the command x:y the : operator would give you the sequence of integers from x:y. What if you want to repeat a vector many times? You could either type it out (painful) or use the rep() function, which can repeat vectors in different ways. # ten zeroes rep(0, 10) ## [1] 0 0 0 0 0 0 0 0 0 0 # alternating 1 and 3, 7 times rep(c(1L, 3L), 7) ## [1] 1 3 1 3 1 3 1 3 1 3 1 3 1 3 rep(c(TRUE, FALSE), 2) ## [1] TRUE FALSE TRUE FALSE What if you want to create a sequence but with something other than integer steps? You can use the seq() function. You can learn about this in the exercises below. # Repeat a vector # See the ?rep function rep(c(TRUE, FALSE), 3) ## [1] TRUE FALSE TRUE FALSE TRUE FALSE # Get every other (odd) element of vec vec[rep(c(TRUE, FALSE), 100)] ## [1] 200 202 204 206 208 210 212 214 216 218 220 222 224 226 228 230 232 ## [18] 234 236 238 240 242 244 246 248 250 252 254 256 258 260 262 264 266 ## [35] 268 270 272 274 276 278 280 282 284 286 288 290 292 294 296 298 300 ## [52] 302 304 306 308 310 312 314 316 318 320 322 324 326 328 330 332 334 ## [69] 336 338 340 342 344 346 348 350 352 354 356 358 360 362 364 366 368 ## [86] 370 372 374 376 378 380 382 384 386 388 390 392 394 396 398 400 # We can also store the logical vector in a variable and use that evens &lt;- rep(c(FALSE, TRUE), 100) You can’t mix data types in a vector; all elements of the vector must be the same data type. If you mix them, R will coerce them so that they are all the same. 3.6.2 Exercises The built-in vector letters contains the letters of the English alphabet. Use an indexing vector of integers to extract the letters that spell ‘cat’. The function colors() returns all of the color names that R is aware of. What is the length of the vector returned by this function? (Use code to find the answer.) The function call runif(1000, 0, 1) will draw 1000 numbers from a uniform distribution from 0 to 1, which simulates the p-values that you would get from 1000 experiments where the null hypothesis is true. Store the result of this call in pvals. Create a logical vector called is_sig that is TRUE if the corresponding element of pvals is less than .05, FALSE otherwise (hint: vectorized operations from the last lession), then use this logical vector to pull out those p-values. Finally, calculate the proportion of those p-values that were significant. 3.6.3 Lists Recall that vectors can contain data of only one type. What if you want to store a collection of data of different data types? For that purpose you would use a list. Define a list using the list() function. albums &lt;- list( Michael_Jackson = c( &quot;Off the Wall&quot;, &quot;Thriller&quot;, &quot;Bad&quot;, &quot;Dangerous&quot; ), Nirvana = c( &quot;Bleach&quot;, &quot;Nevermind&quot;, &quot;In Utero&quot; ) ) names(albums) length(albums) You can refer to elements of a list by Fun fact: tabular data, stored in data.frame or tibble objects, which you will learn about in the next section, are a special type of list. That means you can access the columns of one of these object using tablename$column syntax, which is sometimes useful. 3.7 Tabular data Most of what you will be working with in this course is tabular data, data arranged in the form of a table. Tabular data structures, like lists, allow for a collection of data of different types (characters, integers, logical, etc.) but subject to the constraint that each “column” of the table (element of the list) must have the same number of elements. The base R version of a table is called a data.frame while the ‘tidyverse’ version is called a tibble. Tibbles are far easier to work with, so we’ll be using those. To learn more about differences between these two data structures, see vignette(&quot;tibble&quot;). Tabular data becomes especially important for when we talk about tidy data in lesson 4, which consists of a set of simple principles for structuring data. If we are creating a tibble from scratch, we can use the tibble() function, and type the data right in. Note that if we want a value to repeat multiple times, we only have to specify a one-element vector; R will expand out the vector to fill out the table. All columns in the tibble must have the same lengths or be of length 1. If we want to use the tibble() function, we either need to load the tibble package or the tidyverse package (which will itself load tibble in addition to other packages). Let’s do the latter. library(&quot;tidyverse&quot;) We can get information about the table dimensions using the functions ncol() (number of columns), nrow() (number of rows), or dim() (a vector with the number of rows and number of columns). months &lt;- tibble(ID = 1:12, name = c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;)) # print it months # how many rows? nrow(months) # how many columns? ncol(months) 3.7.1 Viewing your tibble Always, always, always, look at your data once you’ve created the table and load it in. Also look at it after each step that transforms your tibble. There are three ways to look at your tibble: View() [*NB: capital ‘V’], print(), and glimpse(). Note that it is also rare that you want to print your data in a script; that is something you usually are doing for a sanity check, and you should just do it in the console. The print() method can be run explicitly, but is more commonly called by just typing the variable name on the blank line. Usually we only call print() if we want fine control of how the information is displayed. Note that the default is not to print the entire table, but just the first 10 rows. Let’s look at the starwars table that is built into the tidyverse. starwars ## # A tibble: 87 x 13 ## name height mass hair_color skin_color eye_color birth_year gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Luke… 172 77 blond fair blue 19 male ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; ## 4 Dart… 202 136 none white yellow 41.9 male ## 5 Leia… 150 49 brown light brown 19 female ## 6 Owen… 178 120 brown, gr… light blue 52 male ## 7 Beru… 165 75 brown light blue 47 female ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA &lt;NA&gt; ## 9 Bigg… 183 84 black light brown 24 male ## 10 Obi-… 182 77 auburn, w… fair blue-gray 57 male ## # ... with 77 more rows, and 5 more variables: homeworld &lt;chr&gt;, ## # species &lt;chr&gt;, films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; You can see that this is a 87 rows by 13 column table, and we can only see the first 10 rows and first 8 columns. If I want to see all 87 rows for some reason, I would use an explicit call to print(), and set the argument n to the number of rows I want to see. If I want all of them, just use +Inf, the symbol for ‘infinite’ rows. print(starwars, n = +Inf) # try this in the console But we still can’t see all the columns. If this is important to us, we can use glimpse(), which gives a sideways version of the tibble. glimpse(starwars) ## Observations: 87 ## Variables: 13 ## $ name &lt;chr&gt; &quot;Luke Skywalker&quot;, &quot;C-3PO&quot;, &quot;R2-D2&quot;, &quot;Darth Vader&quot;, ... ## $ height &lt;int&gt; 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188... ## $ mass &lt;dbl&gt; 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 8... ## $ hair_color &lt;chr&gt; &quot;blond&quot;, NA, NA, &quot;none&quot;, &quot;brown&quot;, &quot;brown, grey&quot;, &quot;b... ## $ skin_color &lt;chr&gt; &quot;fair&quot;, &quot;gold&quot;, &quot;white, blue&quot;, &quot;white&quot;, &quot;light&quot;, &quot;l... ## $ eye_color &lt;chr&gt; &quot;blue&quot;, &quot;yellow&quot;, &quot;red&quot;, &quot;yellow&quot;, &quot;brown&quot;, &quot;blue&quot;,... ## $ birth_year &lt;dbl&gt; 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0... ## $ gender &lt;chr&gt; &quot;male&quot;, NA, NA, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;,... ## $ homeworld &lt;chr&gt; &quot;Tatooine&quot;, &quot;Tatooine&quot;, &quot;Naboo&quot;, &quot;Tatooine&quot;, &quot;Alder... ## $ species &lt;chr&gt; &quot;Human&quot;, &quot;Droid&quot;, &quot;Droid&quot;, &quot;Human&quot;, &quot;Human&quot;, &quot;Human... ## $ films &lt;list&gt; [&lt;&quot;Revenge of the Sith&quot;, &quot;Return of the Jedi&quot;, &quot;Th... ## $ vehicles &lt;list&gt; [&lt;&quot;Snowspeeder&quot;, &quot;Imperial Speeder Bike&quot;&gt;, &lt;&gt;, &lt;&gt;,... ## $ starships &lt;list&gt; [&lt;&quot;X-wing&quot;, &quot;Imperial shuttle&quot;&gt;, &lt;&gt;, &lt;&gt;, &quot;TIE Adva... The other way to look at the table is a more graphical spreadsheet-like version given by View() (capital ‘V’). It can be useful in the console, but don’t ever put this one in a script because it will create an annoying pop-up window when the user goes to run it. Note that data.frame objects are printed out in different ways from tibble objects. If you print a data.frame object with thousands or millions of rows, you won’t just get a preview… you will spam your console with row upon row of data. If you want to make a data.frame into a tibble so that it prints out nicely, just use the as_tibble() function. mtcars # prints out way too many rows; TMI as_tibble(mtcars) # much cleaner mtcars2 &lt;- as_tibble(mtcars) # store it 3.7.2 Accessing rows and columns There are various base R ways of accessing specific columns or rows from a table that are useful to know about, but you’ll be learning easier (and more readable) ways when we get to the lecture on data wrangling. Examples of these base R accessing functions are provided here for reference. months[1, ] # first row months[, 2] # second column (position) months[1:3, ] # first 3 months months[, c(&quot;Month&quot;)] # access column by name months$month # by column name You’ll learn about data frame operations in the tidyr and dplyr lessons. 3.7.3 Exercises Create a tibble with the name, age, and sex of 3-5 people whose names, ages, and sex you know. Convert the built-in base R iris dataset to a tibble, and store it in the variable iris2. Create a tibble that has the structure of the table below, using the minimum typing possible. (Hint: rep()). Store it in the variable my_tbl. ## # A tibble: 8 x 4 ## ID A B C ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 A1 B1 C1 ## 2 2 A1 B2 C1 ## 3 3 A1 B1 C1 ## 4 4 A1 B2 C1 ## 5 5 A2 B1 C1 ## 6 6 A2 B2 C1 ## 7 7 A2 B1 C1 ## 8 8 A2 B2 C1 3.8 Importing data There are many different types of files that you might work with when doing data analysis. These different file types are usually distinguished by the three letter extension following a period at the end of the file name. Here are some examples of different types of files and the functions you would use to read them in or write them out. Extension File Type Reading Writing .csv Comma-separated values readr::read_csv() readr::write_csv() .xls, .xlsx Excel workbook readxl::read_excel() N/A .rds R binary file readRDS() saveRDS() .RData R binary file load() save() Note: following the conventions introduced above in the section about add-on packages, readr::read_csv() refers to the read_csv() function in the readr package, and readxl::read_excel() refers to the function read_excel() in the package readxl. Probably the most common file type you will encounter is .csv (comma-separated values). As the name suggests, a CSV file distinguishes which values go with which variable by separating them with commas, and text values are sometimes enclosed in double quotes. The first line of a file usually provides the names of the variables. For example, here are the first few lines of a CSV containing Scottish baby names (see the page at National Records Scotland): yr,sex,FirstForename,number,rank,position 1974,B,David,1794,1,1 1974,B,John,1528,2,2 1974,B,Paul,1260,3,3 1974,B,Mark,1234,4,4 1974,B,James,1202,5,5 1974,B,Andrew,1067,6,6 1974,B,Scott,1060,7,7 1974,B,Steven,1020,8,8 1974,B,Robert,885,9,9 1974,B,Stephen,866,10,10 There are six variables in this dataset, and their names are given in the first line of the file: yr, sex, FirstForename, number, rank, and position. You can see that the values for each of these variables are given in order, separated by commas, on each subsequent line of the file. When you read in CSV files, it is best practice to use the readr::read_csv() function. The readr package is automatically loaaded as part of the tidyverse package, which we will be using in almost every script. Note that you would normally want to store the result of the read_csv() function to a variable, as so: library(tidyverse) dat &lt;- read_csv(&quot;my_data_file.csv&quot;) Once loaded, you can view your data using the data viewer. In the upper right hand window of RStudio, under the Environment tab, you will see the object dat listed. If you click on the View icon (), it will bring up a table view of the data you loaded in the top left pane of RStudio. This allows you to check that the data have been loaded in properly. You can close the tab when you’re done looking at it—it won’t remove the object. 3.8.1 Writing Data If you have data that you want to save your data to a CSV file, use readr::write_csv(), as follows. write_csv(dat, &quot;my_data_file2.csv&quot;) This will save the data in CSV format to your working directory. 3.8.2 Exercises Download the dataset disgust_scores.csv and read it into a table. Override the default column specifications to skip the id column. How many rows and columns are in the dataset from question 3? 3.9 Pipes Pipes (%&gt;%) are very useful for stringing together a sequence of commands in R. They might be a bit confusing at first but they are worth learning because they will make your code more readable and efficient. Because pipes are a recent innovation, they are not part of base R. That means you need to load an add-on package to use them. Although the “home” package of the pipe operator is a package called magrittr, more commonly you will gain access to them by loading the tidyverse package (library(&quot;tidyverse&quot;)). If you get either of the following errors in your script: Error: unexpected SPECIAL in &quot;%&gt;%&quot; or Error: could not find function &quot;%&gt;%&quot; you tried to use %&gt;% before doing library(&quot;tidyverse&quot;). It is easiest to understand how to use pipes through an example. Let’s say that we want to sample 5 random integers between 1 and 10 (with replacement), figure out which unique numbers were sampled, and then sort them in descending order. We will need to call three functions in a sequence: sample() to generate the integers, unique() to figure out which unique integers were sampled (because the same integer may have been sampled multiple times), and then sort() with decreasing = TRUE to put them in descending order. So we might write code like this: x &lt;- sample(1:10, 5, replace = TRUE) y &lt;- unique(x) sort(y, TRUE) # set second argument to &#39;TRUE&#39; so that sort order is descending ## [1] 10 9 8 7 While there is nothing wrong with this code, it required us to define variables x and y which we won’t ever need again, and which clutter up our environment. To avoid this you could rewrite this code using nested function calls like so: sort( unique( sample(1:10, 5, replace = TRUE) ) , TRUE) ## [1] 9 6 1 (If the above call looks confusing, it should!) The call to sample() is embedded within a call to unique() which in turn is embedded within a call to sort(). The functions are executed from most embedded (the “bottom”) to least embedded (the “top”), starting with the function sample(), whose result is then passed in as the first argument to unique(), whose result in turn is passed in as the first argument to sort(); notice the second argument of sort (TRUE) is all the way at the end of the statement, making it hard to figure out which of the three functions it belongs to. We read from left to right; however, understanding this code requires us to work our way from right to left, and therefore unnatural. Moreover it is simply an ugly line of code. This is where pipes come in. You can re-write the original code using pipes like so: sample(1:10, 5, replace = TRUE) %&gt;% unique() %&gt;% sort(TRUE) ## [1] 7 6 4 2 1 R will calculate the result of sample(1:10, 5, replace = TRUE) and then pass this result as the first argument of unique(); then, the result of unique() will in turn be passed along as the first argument of sort() with the second argument set to TRUE. The thing to note here is that for any function call on the right hand side of a pipe, you should omit the first argument and start with the second, because the pipe automatically places the result of the call on the left as the first argument of the next function call. 3.9.0.1 Exercises Re-write the following sequence of commands into a single ‘pipeline’. x &lt;- 1:20 # integers from 1:20 y &lt;- rep(x, 2) # then repeat them twice z &lt;- sum(y) # and then take the sum Deconstruct the pipeline below back into separate commands. LETTERS[c(18, 5, 7, 1, 12)] %&gt;% rev() %&gt;% paste(collapse = &quot;&quot;) ## [1] &quot;LAGER&quot; Download the formative exercises. "],
["ggplot.html", "Chapter 4 Data Visualisation 4.1 Learning Objectives 4.2 Resources 4.3 Setup 4.4 Common Variable Combinations 4.5 Data 4.6 Basic Plots 4.7 Save as File 4.8 Combination Plots 4.9 Overlapping Data 4.10 Heat map 4.11 Interactive Plots 4.12 Exercises", " Chapter 4 Data Visualisation 4.1 Learning Objectives 4.1.1 Basic Understand what types of graphs are best for different types of data 1 discrete 1 continuous 2 discrete 2 continuous 1 discrete, 1 continuous 3 continuous Create common types of graphs with ggplot2 geom_bar() geom_density() geom_freqpoly() geom_histogram() geom_violin() geom_boxplot() geom_col() geom_point() geom_smooth() Set custom labels Save plots as an image file 4.1.2 Intermediate Represent factorial designs with different colours or facets Superimpose different types of graphs Add lines to graphs Create less common types of graphs geom_tile() geom_density2d() geom_bin2d() geom_hex() geom_count() Deal with overlapping data Use the viridis package to set colours 4.1.3 Advanced Arrange plots in a grid using cowplot Adjust axes (e.g., flip coordinates, set axis limits) Change the theme Create interactive graphs with plotly 4.2 Resources Look at Data from Data Vizualization for Social Science Chapter 3: Data Visualisation of R for Data Science Chapter 28: Graphics for communication of R for Data Science ggplot2 cheat sheet ggplot2 documentation The R Graph Gallery (this is really useful) Top 50 ggplot2 Visualizations R Graphics Cookbook by Winston Chang The viridis color palettes ggplot extensions plotly for creating interactive graphs 4.3 Setup # libraries needed for these graphs library(tidyverse) library(viridis) library(plotly) # cowplot will change the default theme of graphs, so we&#39;re loading it later # library(cowplot) 4.4 Common Variable Combinations 1 discrete 1 continuous 2 discrete 2 continuous 1 discrete, 1 continuous 3 continuous Before you read ahead, come up with an example of each type of variable combination and sketch the types of graphs that would best display these data. 4.5 Data Here we’ve created some data frames with different types of data. pets has a column with pet type demog has height and age for 500 men and 500 women. x_vs_y has two correlated continuous variables (x and y) overlap has two correlated ordinal variables and 1000 observations so there is a lot of overlap overplot has two correlated continuous variables and 10000 observations pets &lt;- tibble( pet = sample( c(&quot;dog&quot;, &quot;cat&quot;, &quot;ferret&quot;, &quot;bird&quot;, &quot;fish&quot;), 100, TRUE, c(0.45, 0.40, 0.05, 0.05, 0.05) ) ) demog &lt;- tibble( sex = rep(c(&quot;male&quot;, &quot;female&quot;), each = 500), height = c(rnorm(500, 70, 4), rnorm(500, 65, 3.5)), age = rpois(1000, 3) + 20 ) x_vs_y &lt;- tibble( x = rnorm(100), y = x + rnorm(100, 0, 0.5) ) overlap &lt;- tibble( x = rbinom(1000, 10, 0.5), y = x + rbinom(1000, 20, 0.5) ) overplot &lt;- tibble( x = rnorm(10000), y = x + rnorm(10000, 0, 0.5) ) First, think about what kinds of graphs are best for representing these different types of data. 4.6 Basic Plots 4.6.1 Bar plot Bar plots are good for categorical data where you want to represent the count. ggplot(pets, aes(pet)) + geom_bar() 4.6.2 Density plot Density plots are good for one continuous variable, but only if you have a fairly large number of observations. ggplot(demog, aes(height)) + geom_density() You can represent subsets of a variable by assigning the category variable to the argument group, fill, or color. ggplot(demog, aes(height, fill = sex)) + geom_density(alpha = 0.5) Try changing the alpha argument to figure out what it does. 4.6.3 Frequency Polygons If you don’t want smoothed distributions, try geom_freqpoly(). ggplot(demog, aes(height, color = sex)) + geom_freqpoly(binwidth = 1) Try changing the binwidth argument to 5 and 0.1. How do you figure out the right value? 4.6.4 Histogram Histograms are also good for one continuous variable, and work well if you don’t have many observations. Set the binwidth to control how wide each bar is. ggplot(demog, aes(height)) + geom_histogram(binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot;) If you show grouped histograms, you also probably want to change the default position argument. ggplot(demog, aes(height, fill=sex)) + geom_histogram(binwidth = 1, alpha = 0.5, position = &quot;dodge&quot;) Try changing the position argument to “identity”, “fill”, “dodge”, or “stack”. 4.6.5 Column plot Column plots are the worst way to represent grouped continuous data, but also one of the most common. To make column plots with error bars, you first need to calculate the means, error bar uper limits (ymax) and error bar lower limits (ymin) for each category. You’ll learn more about how to use the code below in the next two lessons. # calculate mean and SD for each sex demog %&gt;% group_by(sex) %&gt;% summarise( mean = mean(height), sd = sd(height) ) %&gt;% ggplot(aes(sex, mean, fill=sex)) + geom_col(alpha = 0.5) + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.25) + geom_hline(yintercept = 40) What do you think geom_hline() does? 4.6.6 Boxplot Boxplots are great for representing the distribution of grouped continuous variables. They fix most of the problems with using barplots for continuous data. ggplot(demog, aes(sex, height, fill=sex)) + geom_boxplot(alpha = 0.5) 4.6.7 Violin plot Violin pots are like sideways, mirrored density plots. They give even more information than a boxplot about distribution and are especially useful when you have non-normal distributions. ggplot(demog, aes(sex, height, fill=sex)) + geom_violin( trim = FALSE, draw_quantiles = c(0.25, 0.5, 0.75), alpha = 0.5 ) Try changing the numbers in the draw_quantiles argument. ggplot(demog, aes(sex, height, fill=sex)) + geom_violin( trim = FALSE, alpha = 0.5 ) + stat_summary( fun.data = function(x) { m &lt;- mean(x) sd &lt;- sd(x) c(y = m, ymin = m - sd, ymax = m + sd) }, geom=&quot;pointrange&quot;) 4.6.8 Scatter plot Scatter plots are a good way to represent the relationship between two continuous variables. ggplot(x_vs_y, aes(x, y)) + geom_point() 4.6.9 Line graph You often want to represent the relationship as a single line. ggplot(x_vs_y, aes(x, y)) + geom_smooth(method=&quot;lm&quot;) 4.7 Save as File You can save a ggplot using ggsave(). It saves the last ggplot you made, by default, but you can specify which plot you want to save if you assigned that plot to a variable. You can set the width and height of your plot. The default units are inches, but you can change the units argument to “in”, “cm”, or “mm”. demog_box &lt;- ggplot(demog, aes(sex, height, fill=sex)) + geom_boxplot(alpha = 0.5) demog_violin &lt;- ggplot(demog, aes(sex, height, fill=sex)) + geom_violin(alpha = 0.5) ggsave(&quot;demog_violin_plot.png&quot;, width = 5, height = 7) ggsave(&quot;demog_box_plot.jpg&quot;, plot = demog_box, width = 5, height = 7) 4.8 Combination Plots 4.8.1 Violinbox plot To demonstrate the use of facet_grid() for factorial designs, I created a new column called agegroup to split the data into participants older than the meadian age or younger than the median age. demog %&gt;% mutate(agegroup = ifelse(age&lt;median(age), &quot;Younger&quot;, &quot;Older&quot;)) %&gt;% ggplot(aes(sex, height, fill=sex)) + geom_violin(trim = FALSE, alpha=0.5, show.legend = FALSE) + geom_boxplot(width = 0.25, fill=&quot;white&quot;) + facet_grid(.~agegroup) + scale_fill_manual(values = c(&quot;orange&quot;, &quot;green&quot;)) Set the show.legend argument to FALSE to hide the legend. We do this here because the x-axis already labels the sexes. 4.8.2 Violin-jitter plot If you don’t have a lot of data points, it’s good to represent them individually. You can use geom_point to do this, setting position to “jitter”. demog %&gt;% sample_n(50) %&gt;% # choose 50 random observations from the dataset ggplot(aes(sex, height, fill=sex)) + geom_violin( trim = FALSE, draw_quantiles = c(0.25, 0.5, 0.75), alpha=0.5 ) + geom_point(position = &quot;jitter&quot;, alpha = 0.7, size = 3) 4.8.3 Scatter-line graph If your graph isn’t too complicated, it’s good to also show the individual data points behind the line. ggplot(x_vs_y, aes(x, y)) + geom_point(alpha = 0.25) + geom_smooth(method=&quot;lm&quot;) 4.8.4 Grid of plots You can use the cowplot package to easily make grids of different graphs. First, you have to assign each plot a name. Then you list all the plots as the first arguments of plot_grid() and provide a list of labels. {#theme}You can get back the default ggplot theme with + theme_set(theme_grey()). library(cowplot) ## ## Attaching package: &#39;cowplot&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## ggsave my_hist &lt;- ggplot(demog, aes(height, fill=sex)) + geom_histogram( binwidth = 1, alpha = 0.5, position = &quot;dodge&quot;, show.legend = FALSE ) my_violin &lt;- ggplot(demog, aes(sex, height, fill=sex)) + geom_violin( trim = FALSE, draw_quantiles = c(0.5), alpha = 0.5, show.legend = FALSE ) my_box &lt;- ggplot(demog, aes(sex, height, fill=sex)) + geom_boxplot(alpha=0.5, show.legend = FALSE) my_density &lt;- ggplot(demog, aes(height, fill=sex)) + geom_density(alpha=0.5, show.legend = FALSE) my_bar &lt;- demog %&gt;% group_by(sex) %&gt;% summarise( mean = mean(height), sd = sd(height) ) %&gt;% ggplot(aes(sex, mean, fill=sex)) + geom_bar(stat=&quot;identity&quot;, alpha = 0.5, show.legend = FALSE) + geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = 0.25) plot_grid( my_violin, my_box, my_density, my_bar, labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;) ) Once you load the cowplot package, your ggplot default theme will change. 4.9 Overlapping Data 4.9.1 Discrete Data You can deal with overlapping data points (very common if you’re using Likert scales) by reducing the opacity of the points. You need to use trial and error to adjust these so they look right. ggplot(overlap, aes(x, y)) + geom_point(size = 5, alpha = .05) + geom_smooth(method=&quot;lm&quot;) {#geom_coun} Or you can set the size of the dot proportional to the number of overlapping observations using geom_count(). overlap %&gt;% ggplot(aes(x, y)) + geom_count(color = &quot;#663399&quot;) Alternatively, you can transform your data to create a count column and use the count to set the dot colour. overlap %&gt;% group_by(x, y) %&gt;% summarise(count = n()) %&gt;% ggplot(aes(x, y, color=count)) + geom_point(size = 5) + scale_color_viridis() 4.9.2 Colours The viridis package changes the colour themes to be easier to read by people with colourblindness and to print better in greyscale. Use scale_color_viridis() to set the colour palette and scale_fill_viridis() to set the fill palette in ggplot. If you need discrete (as opposed to continuous) colours, use scale_color_viridis(discrete=TRUE) or scale_fill_viridis(discrete=TRUE) instead. The newest version of ggplot2 v3.0.0 has viridis built in. It uses scale_colour_viridis_c() and scale_fill_viridis_c() for continuous variables and scale_colour_viridis_d() and scale_fill_viridis_d() for discrete variables. 4.9.3 Continuous Data Even if the variables are continuous, overplotting might obscure any relationships if you have lots of data. overplot %&gt;% ggplot(aes(x, y)) + geom_point() {#geom_density2d} Use geom_density2d() to create a contour map. overplot %&gt;% ggplot(aes(x, y)) + geom_density2d() You can use stat_density_2d(aes(fill = ..level..), geom = &quot;polygon&quot;) to create a heatmap-style density plot. overplot %&gt;% ggplot(aes(x, y)) + stat_density_2d(aes(fill = ..level..), geom = &quot;polygon&quot;) + scale_fill_viridis() {#geom_bin2d} Use geom_bin2d() to create a rectangular heatmap of bin counts. Set the binwidth to the x and y dimensions to capture in each box. overplot %&gt;% ggplot(aes(x, y)) + geom_bin2d(binwidth = c(1,1)) {#geom_hex} Use geomhex() to create a hexagonal heatmap of bin counts. Adjust the binwidth, xlim(), ylim() and/or the figure dimensions to make the hexagons more or less stretched. overplot %&gt;% ggplot(aes(x, y)) + geom_hex(binwidth = c(0.25, 0.25)) 4.10 Heat map I’ve included the code for creating a correlation matrix from a table of variables, but you don’t need to understand how this is done yet. We’ll cover mutate and gather functions in the dplyr and tidyr lessons. # generate two sets of correlated variables (a and b) heatmap &lt;- tibble( a1 = rnorm(100), b1 = rnorm(100) ) %&gt;% mutate( a2 = a1 + rnorm(100), a3 = a1 + rnorm(100), a4 = a1 + rnorm(100), b2 = b1 + rnorm(100), b3 = b1 + rnorm(100), b4 = b1 + rnorm(100) ) %&gt;% cor() %&gt;% # create the correlation matrix as.data.frame() %&gt;% # make it a data frame rownames_to_column(var = &quot;V1&quot;) %&gt;% # set rownames as V1 gather(&quot;V2&quot;, &quot;r&quot;, a1:b4) # wide to long (V2) Once you have a correlation matrix in the correct (long) format, it’s easy to make a heatmap using geom_tile(). ggplot(heatmap, aes(V1, V2, fill=r)) + geom_tile() + scale_fill_viridis() The file type is set from the filename suffix, or by specifying the argument device, which can take the following values: “eps”, “ps”, “tex”, “pdf”, “jpeg”, “tiff”, “png”, “bmp”, “svg” or “wmf”. 4.11 Interactive Plots You can use the plotly package to make interactive graphs. Just assign your ggplot to a variable and use the function ggplotly(). demog_plot &lt;- ggplot(demog, aes(age, height, fill=sex)) + geom_point(position = position_jitter(width= 0.2, height = 0), size = 2) ggplotly(demog_plot) Hover over the data points above and click on the legend items. 4.12 Exercises Download the formative exercises. See the answer demo to see what your plots should look like (this doesn’t contain the answer code). 4.12.1 Common Plots Generate a violin plot, boxplot, histogram, density plot, and column plot for the following data. # dog weights estimated from http://petobesityprevention.org/ideal-weight-ranges/ dogs &lt;- tibble( breed = rep(c(&quot;beagle&quot;, &quot;boxer&quot;, &quot;bulldog&quot;), each = 100), weight = c( rnorm(100, 24, 6), rnorm(100, 62.5, 12.5), rnorm(100, 45, 5) ) ) Basic: Create each plot. Intermediate: Change the axis labels and colours. Save each plot as a PNG file. Advanced: Create a grid of the first four plot styles (exclude the column plot). In your RMarkdown file, display just the graph, but not the r code for the graph. 4.12.2 Two continuous variables Represent the relationships among moral, sexual and pathogen disgust scores from the dataset disgust_scores.csv. Basic: Graph the linear relationship between moral and pathogen disgust. Make sure the axes run from the minimum to maximum possible scores on both axes. Give the graph an appropriate title and axis lables. Intermediate: Create a 2d density plot of the relationship between pathogen and sexual disgust. Use stat_density_2d(aes(fill = ..level..), geom = &quot;polygon&quot;, n = ?, h = c(?, ?)), set n and h to values that make the graph look good, and figure out what n and h represent. Advanced: Create a 3x3 grid of plots with columns representing the x-axis and rows representing the y-axis. Put a density plot of each variable along the diagonal. Make sure the graphs have appropriate titles and axis labels and that the range of the axes are the same in all graphs. moral sexual pathogen moral density line line sexual line density line pathogen line line density 4.12.3 Many correlated variables Basic: Create a heatmap of the relationships among all the questions in disgust_cors.csv (the correlations have already been calculated for you). Intermediate: Figure out how to rotate the text on the x-axis so it’s readable. "],
["tidyr.html", "Chapter 5 Tidy Data 5.1 Learning Objectives 5.2 Prep 5.3 Resources 5.4 Formative exercise 5.5 Class Notes 5.6 Exercises", " Chapter 5 Tidy Data 5.1 Learning Objectives 5.1.1 Basic Understand the concept of “tidy data” Be able to use the 4 basic tidyr verbs gather() separate() spread() unite() 5.1.2 Intermediate Be able to chain functions using pipes Be able to use arguments like sep, extra, and convert to handle less straightforward data cleaning 5.1.3 Advanced Be able to use regular expressions to separate complex columns 5.2 Prep Read Tidy Data Chapter 12: Tidy Data in R for Data Science Chapter 18: Pipes in R for Data Science 5.3 Resources Data wrangling cheat sheet 5.4 Formative exercise Download the formative exercises. See the answers only after you’ve attempted all the questions. 5.5 Class Notes 5.5.1 Setup # libraries needed library(tidyverse) library(readxl) 5.5.2 Load Data Get data on infant mortality rates from the CSV file infmort.csv in the directory data. infmort &lt;- read_csv(&quot;data/infmort.csv&quot;) ## Parsed with column specification: ## cols( ## Country = col_character(), ## Year = col_double(), ## `Infant mortality rate (probability of dying between birth and age 1 per 1000 live births)` = col_character() ## ) glimpse(infmort) ## Observations: 5,044 ## Variables: 3 ## $ Country &lt;chr&gt; ... ## $ Year &lt;dbl&gt; ... ## $ `Infant mortality rate (probability of dying between birth and age 1 per 1000 live births)` &lt;chr&gt; ... Get data on maternal mortality from from the excel file matmort.xls in the directory data matmort &lt;- read_xls(&quot;data/matmort.xls&quot;) ## readxl works best with a newer version of the tibble package. ## You currently have tibble v1.4.2. ## Falling back to column name repair from tibble &lt;= v1.4.2. ## Message displays once per session. glimpse(matmort) ## Observations: 181 ## Variables: 4 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argent... ## $ `1990` &lt;chr&gt; &quot;1 340 [ 878 - 1 950]&quot;, &quot;71 [ 58 - 88]&quot;, &quot;216 [ 141 -... ## $ `2000` &lt;chr&gt; &quot;1 100 [ 745 - 1 570]&quot;, &quot;43 [ 33 - 56]&quot;, &quot;170 [ 118 -... ## $ `2015` &lt;chr&gt; &quot;396 [ 253 - 620]&quot;, &quot;29 [ 16 - 46]&quot;, &quot;140 [ 82 - 24... Get data on country codes from https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv ccodes &lt;- read_csv(&quot;https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv&quot;) ## Parsed with column specification: ## cols( ## name = col_character(), ## `alpha-2` = col_character(), ## `alpha-3` = col_character(), ## `country-code` = col_character(), ## `iso_3166-2` = col_character(), ## region = col_character(), ## `sub-region` = col_character(), ## `intermediate-region` = col_character(), ## `region-code` = col_character(), ## `sub-region-code` = col_character(), ## `intermediate-region-code` = col_character() ## ) glimpse(ccodes) ## Observations: 249 ## Variables: 11 ## $ name &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Åland Islands&quot;, &quot;Al... ## $ `alpha-2` &lt;chr&gt; &quot;AF&quot;, &quot;AX&quot;, &quot;AL&quot;, &quot;DZ&quot;, &quot;AS&quot;, &quot;AD&quot;,... ## $ `alpha-3` &lt;chr&gt; &quot;AFG&quot;, &quot;ALA&quot;, &quot;ALB&quot;, &quot;DZA&quot;, &quot;ASM&quot;, ... ## $ `country-code` &lt;chr&gt; &quot;004&quot;, &quot;248&quot;, &quot;008&quot;, &quot;012&quot;, &quot;016&quot;, ... ## $ `iso_3166-2` &lt;chr&gt; &quot;ISO 3166-2:AF&quot;, &quot;ISO 3166-2:AX&quot;, &quot;... ## $ region &lt;chr&gt; &quot;Asia&quot;, &quot;Europe&quot;, &quot;Europe&quot;, &quot;Africa... ## $ `sub-region` &lt;chr&gt; &quot;Southern Asia&quot;, &quot;Northern Europe&quot;,... ## $ `intermediate-region` &lt;chr&gt; NA, NA, NA, NA, NA, NA, &quot;Middle Afr... ## $ `region-code` &lt;chr&gt; &quot;142&quot;, &quot;150&quot;, &quot;150&quot;, &quot;002&quot;, &quot;009&quot;, ... ## $ `sub-region-code` &lt;chr&gt; &quot;034&quot;, &quot;154&quot;, &quot;039&quot;, &quot;015&quot;, &quot;061&quot;, ... ## $ `intermediate-region-code` &lt;chr&gt; NA, NA, NA, NA, NA, NA, &quot;017&quot;, &quot;029... 5.5.3 Pipes Dale introduced pipes in the second lesson, but we will review them here. Pipes are a way to order your code in a more readable format. Let’s say you have a small data table with 10 participant IDs, two columns with variable type A, and 2 columns with variable type B. You want to calculate the mean of the A variables and the mean of the B variables and return a table with 10 rows (1 for each participant) and 3 columns (id, A_mean and B_mean). One way you could do this is by creating a new object at every step and using that object in the next step. This is pretty clear, but you’ve created 6 unnecessary data objects in your environment. This can get confusing in very long scripts. # make a data table with 10 subjects data_original &lt;- tibble( id = 1:10, A1 = rnorm(10, 0), A2 = rnorm(10, 1), B1 = rnorm(10, 2), B2 = rnorm(10,3) ) # gather columns A1 to B2 into &quot;variable&quot; and &quot;value&quot; columns data_gathered &lt;- gather(data_original, variable, value, A1:B2) # separate the variable column at the _ into &quot;var&quot; and &quot;var_n&quot; columns data_separated &lt;- separate(data_gathered, variable, c(&quot;var&quot;, &quot;var_n&quot;), sep = 1) # group the data by id and var data_grouped &lt;- group_by(data_separated, id, var) # calculate the mean value for each id/var data_summarised &lt;- summarise(data_grouped, mean = mean(value)) # spread the mean column into A and B columns data_spread &lt;- spread(data_summarised, var, mean) # rename A and B to A_mean and B_mean data &lt;- rename(data_spread, A_mean = A, B_mean = B) data ## # A tibble: 10 x 3 ## # Groups: id [10] ## id A_mean B_mean ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.469 3.54 ## 2 2 -0.149 2.39 ## 3 3 0.0825 3.20 ## 4 4 2.39 1.39 ## 5 5 1.19 2.74 ## 6 6 0.486 1.93 ## 7 7 0.313 3.35 ## 8 8 -0.248 3.56 ## 9 9 0.400 2.98 ## 10 10 -0.747 2.56 You can name each object data and keep replacing the old data object with the new one at each step. This will keep you environment clean, but I don’t recommend it because it makes it too easy to accidentally run your code out of order when you are running line-by-line for development or debugging. One way to avoid extra objects is to nest your functions, literally replacing each data object with the code that generated it in the previous step. This can be fine for very short chains. mean_petal_width &lt;- round(mean(iris$Petal.Width), 2) But it gets extremely confusing for long chains: # do not ever do this!! data &lt;- rename( spread( summarise( group_by( separate( gather( tibble( id = 1:10, A1 = rnorm(10, 0), A2 = rnorm(10, 1), B1 = rnorm(10, 2), B2 = rnorm(10,3)), variable, value, A1:B2), variable, c(&quot;var&quot;, &quot;var_n&quot;), sep = 1), id, var), mean = mean(value)), var, mean), A_mean = A, B_mean = B) The pipe lets you “pipe” the result of each function into the next function, allowing you to put your code in a logical order without creating too many extra objects. # calculate mean of A and B variables for each participant data &lt;- tibble( id = 1:10, A1 = rnorm(10, 0), A2 = rnorm(10, 1), B1 = rnorm(10, 2), B2 = rnorm(10,3) ) %&gt;% gather(variable, value, A1:B2) %&gt;% separate(variable, c(&quot;var&quot;, &quot;var_n&quot;), sep=1) %&gt;% group_by(id, var) %&gt;% summarise(mean = mean(value)) %&gt;% spread(var, mean) %&gt;% rename(A_mean = A, B_mean = B) You can read this code from top to bottom as follows: Make a tibble called data with id of 1 to 10, A1 of 10 random numbers from a normal distribution, A2 of 10 random numbers from a normal distribution, B1 of 10 random numbers from a normal distribution, B2 of 10 random numbers from a normal distribution; and then Gather to create variable and value column from columns A_1 to B_2; and then Separate the column variable into 2 new columns called varand var_n, separate at character 1; and then Group by columns id and var; and then Summarise and new column called mean as the mean of the value column for each group; and then Spread to make new columns with the key names in var and values in mean; and then Rename to make columns called A_mean (old A) and B_mean (old B) You can make intermediate objects whenever you need to break up your code because it’s getting too complicated or you need to debug something. You can debug a pipe by running just the first few functions by highlighting from the beginning to just before the pipe you want to stop at. Try this by highlighting from data &lt;- to the end of the separate function and typing cmd-return. What does data look like now? 5.5.4 gather() gather(data, key = &quot;key&quot;, value = &quot;value&quot;, ..., na.rm = FALSE, convert = FALSE, factor_key = FALSE) matmort is in wide format, with a separate column for each year. Change it to long format, with a row for each County/Year observation. key is what you want to call the row headers; it’s “year” in this example. value is what you want to call the values in the gathered columns; they’re “stats” in this example. The ... refers to the columns you want to gather. You can refer to them by their names, like col1, col2, col3, col4 or col1:col4 or by their numbers, like 8, 9, 10 or 8:10. This example is complicated because the column names to gather are numbers. If the column names are non-standard (e.g., have spaces, start with numbers, or have special characters), you can enclose them in backticks (`) like the example below. matmort_long &lt;- matmort %&gt;% gather(&quot;Year&quot;, &quot;stats&quot;, `1990`:`2015`) glimpse(matmort_long) ## Observations: 543 ## Variables: 3 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argent... ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;... ## $ stats &lt;chr&gt; &quot;1 340 [ 878 - 1 950]&quot;, &quot;71 [ 58 - 88]&quot;, &quot;216 [ 141 -... 5.5.5 separate() separate(data, col, into, sep = &quot;[^[:alnum:]]+&quot;, remove = TRUE, convert = FALSE, extra = &quot;warn&quot;, fill = &quot;warn&quot;) The data in the stats column is in a crazy format with some sort of confidence interval in brackets and lots of extra spaces. We don’t need any of the spaces, so first we’ll remove them with mutate. The separate function will separate your data on anything that is not a number or letter, so try it first without specifying the sep argument. The into argument is a list of the new column names. matmort_split &lt;- matmort_long %&gt;% mutate(stats = gsub(&quot; &quot;, &quot;&quot;, stats)) %&gt;% separate(stats, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;)) ## Warning: Expected 3 pieces. Additional pieces discarded in 543 rows [1, 2, ## 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...]. glimpse(matmort_split) ## Observations: 543 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argent... ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;... ## $ rate &lt;chr&gt; &quot;1340&quot;, &quot;71&quot;, &quot;216&quot;, &quot;1160&quot;, &quot;72&quot;, &quot;58&quot;, &quot;8&quot;, &quot;8&quot;, &quot;64... ## $ ci_low &lt;chr&gt; &quot;878&quot;, &quot;58&quot;, &quot;141&quot;, &quot;627&quot;, &quot;64&quot;, &quot;51&quot;, &quot;7&quot;, &quot;7&quot;, &quot;56&quot;,... ## $ ci_hi &lt;chr&gt; &quot;1950&quot;, &quot;88&quot;, &quot;327&quot;, &quot;2020&quot;, &quot;80&quot;, &quot;65&quot;, &quot;9&quot;, &quot;10&quot;, &quot;7... The gsub(pattern, replacement, x) function is a flexible way to do search and replace. The example above replaces all occurances of the pattern &quot; &quot; (a space), with the replacement “” (nothing), in the string x (the stats column). Use sub() instead if you only want to replace the first occurance of a pattern. We only used a simple pattern here, but you can use more complicated regex patterns to replace, for example, all even numbers (e.g., gsub(&quot;[:02468:]&quot;, &quot;*&quot;, &quot;id = 123456&quot;)) or all occurances of the word colour in US or UK spelling (e.g., gsub(&quot;colo(u)?r&quot;, &quot;***&quot;, &quot;replace color, colour, or colours, but not collors&quot;)). 5.5.5.1 Handle spare columns with extra The previous example should have given you an error warning about “Too many values at 543 locations”. This is because separate splits the column at the brackets and dashes, so the text “100[90-110]” would split into four values c(“100”, “90”, “110”, “”), but we only specified 3 new columns. The fourth value is always empty (just the part after the last bracket), so we are happy to drop it, but separate generates a warning so you don’t do that accidentally. You can turn off the warning by adding the extra argument and setting it to “drop”. Look at the help for ??tidyr::separate to see what the other options do. matmort_split &lt;- matmort_long %&gt;% mutate(stats = gsub(&quot; &quot;, &quot;&quot;, stats)) %&gt;% separate(stats, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;) glimpse(matmort_split) ## Observations: 543 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argent... ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;... ## $ rate &lt;chr&gt; &quot;1340&quot;, &quot;71&quot;, &quot;216&quot;, &quot;1160&quot;, &quot;72&quot;, &quot;58&quot;, &quot;8&quot;, &quot;8&quot;, &quot;64... ## $ ci_low &lt;chr&gt; &quot;878&quot;, &quot;58&quot;, &quot;141&quot;, &quot;627&quot;, &quot;64&quot;, &quot;51&quot;, &quot;7&quot;, &quot;7&quot;, &quot;56&quot;,... ## $ ci_hi &lt;chr&gt; &quot;1950&quot;, &quot;88&quot;, &quot;327&quot;, &quot;2020&quot;, &quot;80&quot;, &quot;65&quot;, &quot;9&quot;, &quot;10&quot;, &quot;7... 5.5.5.2 Set delimiters with sep Now do the same with infmort. It’s already in long format, so you don’t need to use gather, but the third column has a crazy long name, so we can just refer to it by its column number (3). infmort_split &lt;- infmort %&gt;% separate(3, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;) glimpse(infmort_split) ## Observations: 5,044 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis... ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, ... ## $ rate &lt;chr&gt; &quot;66&quot;, &quot;68&quot;, &quot;69&quot;, &quot;71&quot;, &quot;73&quot;, &quot;75&quot;, &quot;76&quot;, &quot;78&quot;, &quot;80&quot;, ... ## $ ci_low &lt;chr&gt; &quot;3&quot;, &quot;1&quot;, &quot;9&quot;, &quot;7&quot;, &quot;4&quot;, &quot;1&quot;, &quot;8&quot;, &quot;6&quot;, &quot;4&quot;, &quot;3&quot;, &quot;4&quot;,... ## $ ci_hi &lt;chr&gt; &quot;52&quot;, &quot;55&quot;, &quot;58&quot;, &quot;61&quot;, &quot;64&quot;, &quot;66&quot;, &quot;69&quot;, &quot;71&quot;, &quot;73&quot;, ... Wait, that didn’t work at all! It split the column on spaces, brackets, and full stops. We just want to split on the spaces, brackets and dashes. So we need to manually set sep to what the delimiters are. Also, once there are more than a few arguments specified for a function, it’s easier to read them if you put one argument on each line. You can use regular expressions to separate complex columns. Here, we want to separate on dashes and brackets. You can separate on a list of delimiters by putting them in parentheses, separated by “|”. It’s a little more complicated because brackets have a special meaning in regex, so you need to “escape” the left one with two backslashes “\\\\”. infmort_split &lt;- infmort %&gt;% separate( col = 3, into = c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, sep = &quot;(\\\\[|-|])&quot; ) glimpse(infmort_split) ## Observations: 5,044 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis... ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, ... ## $ rate &lt;chr&gt; &quot;66.3 &quot;, &quot;68.1 &quot;, &quot;69.9 &quot;, &quot;71.7 &quot;, &quot;73.4 &quot;, &quot;75.1 &quot;, ... ## $ ci_low &lt;chr&gt; &quot;52.7&quot;, &quot;55.7&quot;, &quot;58.7&quot;, &quot;61.6&quot;, &quot;64.4&quot;, &quot;66.9&quot;, &quot;69.0&quot;... ## $ ci_hi &lt;chr&gt; &quot;83.9&quot;, &quot;83.6&quot;, &quot;83.5&quot;, &quot;83.7&quot;, &quot;84.2&quot;, &quot;85.1&quot;, &quot;86.1&quot;... 5.5.5.3 Fix data types with convert That’s better. Notice the next to Year, rate, ci_low and ci_hi. That means these columns hold characters (like words), not numbers or integers. This can cause problems when you try to do thigs like average the numbers (you can’t average words), so we can fix it by adding the argument convert and setting it to TRUE. infmort_split &lt;- infmort %&gt;% separate(3, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, sep = &quot;(\\\\[|-|])&quot;, convert = TRUE) glimpse(infmort_split) ## Observations: 5,044 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis... ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, ... ## $ rate &lt;dbl&gt; 66.3, 68.1, 69.9, 71.7, 73.4, 75.1, 76.8, 78.6, 80.4, ... ## $ ci_low &lt;dbl&gt; 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, ... ## $ ci_hi &lt;dbl&gt; 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, ... Do the same for matmort. matmort_split &lt;- matmort_long %&gt;% mutate(stats = gsub(&quot; &quot;, &quot;&quot;, stats)) %&gt;% separate(stats, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, convert = TRUE) glimpse(matmort_split) ## Observations: 543 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argent... ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;... ## $ rate &lt;int&gt; 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58... ## $ ci_low &lt;int&gt; 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, ... ## $ ci_hi &lt;int&gt; 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 7... 5.5.5.4 All in one step We can chain all the steps above together, since we don’t need those intermediate dataframes. infmort &lt;- read_csv(&quot;data/infmort.csv&quot;) %&gt;% separate( 3, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, sep = &quot;(\\\\[|-|])&quot;, convert = TRUE ) ## Parsed with column specification: ## cols( ## Country = col_character(), ## Year = col_double(), ## `Infant mortality rate (probability of dying between birth and age 1 per 1000 live births)` = col_character() ## ) matmort &lt;- read_xls(&quot;data/matmort.xls&quot;) %&gt;% gather(&quot;Year&quot;, &quot;stats&quot;, `1990`:`2015`) %&gt;% mutate(stats = gsub(&quot; &quot;, &quot;&quot;, stats)) %&gt;% separate( stats, c(&quot;rate&quot;, &quot;ci_low&quot;, &quot;ci_hi&quot;), extra = &quot;drop&quot;, convert = TRUE ) glimpse(matmort) ## Observations: 543 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argent... ## $ Year &lt;chr&gt; &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;, &quot;1990&quot;... ## $ rate &lt;int&gt; 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58... ## $ ci_low &lt;int&gt; 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, ... ## $ ci_hi &lt;int&gt; 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 7... glimpse(infmort) ## Observations: 5,044 ## Variables: 5 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis... ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, ... ## $ rate &lt;dbl&gt; 66.3, 68.1, 69.9, 71.7, 73.4, 75.1, 76.8, 78.6, 80.4, ... ## $ ci_low &lt;dbl&gt; 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, ... ## $ ci_hi &lt;dbl&gt; 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, ... 5.5.6 spread() spread(data, key, value, fill = NA, convert = FALSE, drop = TRUE, sep = NULL) You can reverse the processes above, as well. For example, you can convert data from long format into wide format. key is the column that contains your new column headers value is the column that contains the values in the new spread columns Let’s spread out the infant mortality rate by year. infmort_wide &lt;- infmort %&gt;% spread(Year, rate) glimpse(infmort_wide) ## Observations: 4,934 ## Variables: 29 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis... ## $ ci_low &lt;dbl&gt; 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, ... ## $ ci_hi &lt;dbl&gt; 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, ... ## $ `1990` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `1991` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `1992` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `1993` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `1994` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `1995` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `1996` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `1997` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `1998` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `1999` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `2000` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `2001` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... ## $ `2002` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 91... ## $ `2003` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 89, NA... ## $ `2004` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 86.7, NA, ... ## $ `2005` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 84.4, NA, NA, ... ## $ `2006` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 82.3, NA, NA, NA, ... ## $ `2007` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 80.4, NA, NA, NA, NA, ... ## $ `2008` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 78.6, NA, NA, NA, NA, NA, ... ## $ `2009` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 76.8, NA, NA, NA, NA, NA, NA, ... ## $ `2010` &lt;dbl&gt; NA, NA, NA, NA, NA, 75.1, NA, NA, NA, NA, NA, NA, NA, ... ## $ `2011` &lt;dbl&gt; NA, NA, NA, NA, 73.4, NA, NA, NA, NA, NA, NA, NA, NA, ... ## $ `2012` &lt;dbl&gt; NA, NA, NA, 71.7, NA, NA, NA, NA, NA, NA, NA, NA, NA, ... ## $ `2013` &lt;dbl&gt; NA, NA, 69.9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ... ## $ `2014` &lt;dbl&gt; NA, 68.1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ... ## $ `2015` &lt;dbl&gt; 66.3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ... Nope, that didn’t work at all, but it’s a really common mistake when spreading data. This is because spread matches on all the remaining columns, so Afghanistan with ci_low of 52.7 is treated as a different observation than Afghanistan with ci_low of 55.7. We can fix this by merging the rate, ci_low and ci_hi columns back together. 5.5.7 unite() unite(data, col, ..., sep = &quot;_&quot;, remove = TRUE) infmort_united &lt;- infmort %&gt;% unite(rate_ci, rate, ci_low, ci_hi) glimpse(infmort_united) ## Observations: 5,044 ## Variables: 3 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis... ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, ... ## $ rate_ci &lt;chr&gt; &quot;66.3_52.7_83.9&quot;, &quot;68.1_55.7_83.6&quot;, &quot;69.9_58.7_83.5&quot;, ... 5.5.7.1 Control separation with sep unite() separates merged names with an underscore by default. Set the sep argument if you want to change that. infmort_united &lt;- infmort %&gt;% unite(rate_ci, rate, ci_low, ci_hi, sep = &quot;, &quot;) glimpse(infmort_united) ## Observations: 5,044 ## Variables: 3 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis... ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, ... ## $ rate_ci &lt;chr&gt; &quot;66.3, 52.7, 83.9&quot;, &quot;68.1, 55.7, 83.6&quot;, &quot;69.9, 58.7, 8... What if you want to put it back into the format “rate [ci_low - ci_hi]”? Then, mutate and paste are a better choice than unite, but you have to get rid of the rate, ci_low and ci_hi columns with select. You’ll learn more about these function in the Data Manipulation lesson. infmort_united &lt;- infmort %&gt;% mutate(rate_ci = paste0(rate, &quot; [&quot;, ci_low, &quot; - &quot;, ci_hi, &quot;]&quot;)) glimpse(infmort_united) ## Observations: 5,044 ## Variables: 6 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis... ## $ Year &lt;dbl&gt; 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, ... ## $ rate &lt;dbl&gt; 66.3, 68.1, 69.9, 71.7, 73.4, 75.1, 76.8, 78.6, 80.4, ... ## $ ci_low &lt;dbl&gt; 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, ... ## $ ci_hi &lt;dbl&gt; 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, ... ## $ rate_ci &lt;chr&gt; &quot;66.3 [52.7 - 83.9]&quot;, &quot;68.1 [55.7 - 83.6]&quot;, &quot;69.9 [58.... Now let’s try spreading on year again. Notice here we’re uniting columns rate:ci_hi, instead of rate, ci_low, ci_hi. The colon just says to select all the columns between the first and last named ones. Check the help documentation for ??tidyr::unite and ??tidyr::select to see other ways to select columns. infmort_wide &lt;- infmort %&gt;% unite(rate_ci, rate:ci_hi, sep = &quot;, &quot;) %&gt;% spread(Year, rate_ci) glimpse(infmort_wide) ## Observations: 194 ## Variables: 27 ## $ Country &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Andorra&quot;, &quot;Angol... ## $ `1990` &lt;chr&gt; &quot;122.5, 111.6, 135.5&quot;, &quot;35.1, 31.3, 39.2&quot;, &quot;39.7, 37.1... ## $ `1991` &lt;chr&gt; &quot;118.3, 108, 129.9&quot;, &quot;33.7, 30.2, 37.6&quot;, &quot;38.8, 36.1, ... ## $ `1992` &lt;chr&gt; &quot;114.4, 104.6, 125.2&quot;, &quot;32.5, 29.2, 36.2&quot;, &quot;38.1, 35.4... ## $ `1993` &lt;chr&gt; &quot;110.9, 101.4, 120.9&quot;, &quot;31.4, 28.2, 34.9&quot;, &quot;37.5, 34.9... ## $ `1994` &lt;chr&gt; &quot;107.7, 98.6, 117.2&quot;, &quot;30.3, 27.1, 33.8&quot;, &quot;36.9, 34.6,... ## $ `1995` &lt;chr&gt; &quot;105, 96.2, 114.1&quot;, &quot;29.1, 26, 32.7&quot;, &quot;36.3, 34.2, 38.... ## $ `1996` &lt;chr&gt; &quot;102.7, 94.5, 111.3&quot;, &quot;27.9, 24.8, 31.5&quot;, &quot;35.7, 34, 3... ## $ `1997` &lt;chr&gt; &quot;100.7, 92.9, 109.1&quot;, &quot;26.8, 23.6, 30.4&quot;, &quot;35.1, 33.8,... ## $ `1998` &lt;chr&gt; &quot;98.9, 91.4, 107.2&quot;, &quot;25.5, 22.4, 29.2&quot;, &quot;34.7, 33.7, ... ## $ `1999` &lt;chr&gt; &quot;97.2, 89.9, 105.4&quot;, &quot;24.4, 21.2, 28.1&quot;, &quot;34.4, 33.5, ... ## $ `2000` &lt;chr&gt; &quot;95.4, 88.2, 103.6&quot;, &quot;23.2, 20, 27&quot;, &quot;33.9, 33.2, 34.7... ## $ `2001` &lt;chr&gt; &quot;93.4, 86.3, 101.6&quot;, &quot;22.1, 18.8, 26&quot;, &quot;33.3, 32.7, 34... ## $ `2002` &lt;chr&gt; &quot;91.2, 84.3, 99.3&quot;, &quot;21, 17.6, 25.1&quot;, &quot;32.4, 31.8, 33&quot;... ## $ `2003` &lt;chr&gt; &quot;89, 82.1, 97&quot;, &quot;20, 16.5, 24.3&quot;, &quot;31.3, 30.7, 31.9&quot;, ... ## $ `2004` &lt;chr&gt; &quot;86.7, 79.9, 94.8&quot;, &quot;19.1, 15.4, 23.8&quot;, &quot;30.1, 29.5, 3... ## $ `2005` &lt;chr&gt; &quot;84.4, 77.7, 92.6&quot;, &quot;18.3, 14.2, 23.4&quot;, &quot;28.8, 28.3, 2... ## $ `2006` &lt;chr&gt; &quot;82.3, 75.5, 90.7&quot;, &quot;17.4, 13.2, 23.1&quot;, &quot;27.6, 27, 28.... ## $ `2007` &lt;chr&gt; &quot;80.4, 73.4, 88.9&quot;, &quot;16.7, 12.1, 22.9&quot;, &quot;26.4, 25.9, 2... ## $ `2008` &lt;chr&gt; &quot;78.6, 71.2, 87.3&quot;, &quot;16, 11.2, 22.7&quot;, &quot;25.3, 24.8, 25.... ## $ `2009` &lt;chr&gt; &quot;76.8, 69, 86.1&quot;, &quot;15.4, 10.5, 22.6&quot;, &quot;24.3, 23.8, 24.... ## $ `2010` &lt;chr&gt; &quot;75.1, 66.9, 85.1&quot;, &quot;14.8, 9.8, 22.4&quot;, &quot;23.5, 23, 23.9... ## $ `2011` &lt;chr&gt; &quot;73.4, 64.4, 84.2&quot;, &quot;14.3, 9.1, 22.3&quot;, &quot;22.8, 22.4, 23... ## $ `2012` &lt;chr&gt; &quot;71.7, 61.6, 83.7&quot;, &quot;13.8, 8.5, 22.2&quot;, &quot;22.4, 22, 22.9... ## $ `2013` &lt;chr&gt; &quot;69.9, 58.7, 83.5&quot;, &quot;13.3, 7.9, 22.1&quot;, &quot;22.1, 21.7, 22... ## $ `2014` &lt;chr&gt; &quot;68.1, 55.7, 83.6&quot;, &quot;12.9, 7.5, 22.1&quot;, &quot;22, 21.3, 22.7... ## $ `2015` &lt;chr&gt; &quot;66.3, 52.7, 83.9&quot;, &quot;12.5, 7, 22.2&quot;, &quot;21.9, 20.8, 23&quot;,... 5.6 Exercises Tidy the data from personality.csv. These data are from a 5-factor (OCEAN) personality questionnaire. Each question is labelled with the domain (Op = openness, Co = concientiousness, Ex = extraversion, Ag = agreeableness, and Ne = neuroticism) and the question number. Basic: Load the data and convert from wide to long format. The resulting dataframe should have the columns: user_id, date, question, and score. Solution ocean &lt;- read_csv(&quot;data/personality.csv&quot;) %&gt;% gather(&quot;question&quot;, &quot;score&quot;, Op1:Ex9) ## Parsed with column specification: ## cols( ## .default = col_double(), ## date = col_date(format = &quot;&quot;) ## ) ## See spec(...) for full column specifications. Basic: Split the question column into two columns: domain and qnumber. There is no character to split on, here, but you can separate a column after a specific number of characters by setting sep to an integer. For example, to split “abcde” after the third character, use sep = 3, which results in c(“abc”, “de”). You can also use negative number to split before the nth character from the right. For example, to split a column that has words of various lengths and 2-digit suffixes (like “lisa03”“,”amanda38“), you can use sep = -2. Solution ocean_sep &lt;- ocean %&gt;% separate(question, c(&quot;domain&quot;, &quot;qnumber&quot;), sep = 2) Basic: Put the domain and qnumber columns back together into a new column named domain_n. Make it in a format like “Op_Q1”. Solution ocean_unite &lt;- ocean_sep %&gt;% unite(&quot;domain_n&quot;, domain, qnumber, sep = &quot;_Q&quot;) Basic: Convert back to wide format. Solution ocean_spread &lt;- ocean_unite %&gt;% spread(domain_n, score) Intermediate: Chain all the steps above using pipes. Solution ocean &lt;- read_csv(&quot;data/personality.csv&quot;) %&gt;% gather(&quot;question&quot;, &quot;score&quot;, Op1:Ex9) %&gt;% separate(question, c(&quot;domain&quot;, &quot;qnumber&quot;), sep = 2) %&gt;% unite(&quot;domain_n&quot;, domain, qnumber, sep = &quot;_Q&quot;) %&gt;% spread(domain_n, score) ## Parsed with column specification: ## cols( ## .default = col_double(), ## date = col_date(format = &quot;&quot;) ## ) ## See spec(...) for full column specifications. Intermediate: Debug the following code: Load the data from sensation_seeking.csv. ss &lt;- read_csv(data/sensation_seeking.csv) Solution ss &lt;- read_csv(&quot;data/sensation_seeking.csv&quot;) ## Parsed with column specification: ## cols( ## id = col_double(), ## user_id = col_double(), ## date = col_date(format = &quot;&quot;), ## sss1 = col_double(), ## sss2 = col_double(), ## sss3 = col_double(), ## sss4 = col_double(), ## sss5 = col_double(), ## sss6 = col_double(), ## sss7 = col_double(), ## sss8 = col_double(), ## sss9 = col_double(), ## sss10 = col_double(), ## sss11 = col_double(), ## sss12 = col_double(), ## sss13 = col_double(), ## sss14 = col_double() ## ) Convert from wide to long format. ss_long &lt;- gather(ss, &quot;question&quot;, &quot;score&quot;) Solution ss_long &lt;- gather(ss, &quot;question&quot;, &quot;score&quot;, sss1:sss14) Split the question column into two columns: domain and qnumber. ss_sep &lt;- ss_long %&gt;% separate(question, domain, qnumber, sep = 3) Solution ss_sep &lt;- ss_long %&gt;% separate(question, c(&quot;domain&quot;, &quot;qnumber&quot;), sep = 3) Put the id and user_id columns together into a new column named super_id. Make it in a format like “id-user_id”. ss_unite &lt;- ss_sep %&gt;% unite(id, user_id, &quot;super_id&quot;, sep = &quot;-&quot;) Solution ss_unite &lt;- ss_sep %&gt;% unite(&quot;super_id&quot;, id, user_id, sep = &quot;-&quot;) Convert back to wide format. ss_wide &lt;- ss_unite %&gt;% spreadr(qnumber, score) Solution ss_wide &lt;- ss_unite %&gt;% spread(qnumber, score) Intermediate: Load the dataset family_composition.csv. The columns oldbro through twinsis give the number of siblings of that age and sex. Put this into long format and create separate columns for sibling age (old, young, twin) and sex (bro, sis). Solution family &lt;- read_csv(&quot;data/family_composition.csv&quot;) %&gt;% gather(&quot;sibtype&quot;, &quot;n&quot;, oldbro:twinsis) %&gt;% separate(sibtype, c(&quot;sibage&quot;, &quot;sibsex&quot;), sep = -3) Advanced: Tidy the data from eye_descriptions.csv. This dataset contains descriptions of the eyes of 50 people. Some raters wrote more than one description per face, separated by commas, semicolons, or slashes. Create a dataset with separate columns for face_id, description, and number of description. Solution eyes &lt;- read_csv(&quot;data/eye_descriptions.csv&quot;) %&gt;% gather(&quot;face_id&quot;, &quot;description&quot;, t1:t50) %&gt;% separate(description, c(&quot;d1&quot;, &quot;d2&quot;, &quot;d3&quot;), sep = &quot;(,|;|\\\\/)+&quot;, extra = &quot;merge&quot;) %&gt;% gather(&quot;desc_n&quot;, &quot;description&quot;, d1:d3) %&gt;% filter(!is.na(description)) # gets rid of rows with no description ## Warning: Expected 3 pieces. Missing pieces filled with `NA` in 10645 ## rows [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ## 20, ...]. I’m bored Using the family composition dataset from question 11, calculate how many siblings of each sex each person has, narrow the dataset down to people with fewer than 6 siblings, and generate at least two different ways to graph this. Solution family %&gt;% group_by(user_id, sex, sibsex) %&gt;% summarise(n = sum(n)) %&gt;% group_by(user_id) %&gt;% filter(sex %in% c(&quot;male&quot;, &quot;female&quot;), sum(n) &lt; 6) %&gt;% ggplot(aes(n, fill = sibsex)) + geom_histogram(binwidth = 1, colour = &quot;black&quot;, position = &quot;dodge&quot;) family %&gt;% group_by(user_id, sex, sibsex) %&gt;% summarise(n = sum(n)) %&gt;% filter(sex %in% c(&quot;male&quot;, &quot;female&quot;)) %&gt;% spread(sibsex, n) %&gt;% filter(bro + sis &lt; 6) %&gt;% ggplot(aes(bro, sis)) + geom_bin2d(binwidth = c(1,1)) Create a list of the 10 most common descriptions from the eye colour dataset in question 12. Remove useless descriptions and merge redundant descriptions. Display the table by piping the resulting tibble to knitr::kable(). Solution eyes %&gt;% mutate( description = trimws(description), # get rid of white space around string description = tolower(description) # make all characters lowercase ) %&gt;% group_by(description) %&gt;% summarise(n = n()) %&gt;% # count occurances of each description arrange(desc(n)) %&gt;% # sort by count (descending) filter(nchar(description) &gt; 1) %&gt;% # get rid of 1-character descriptions filter(row_number() &lt; 11) %&gt;% knitr::kable() description n ———— —- brown 364 blue 314 small 270 pretty 259 big 239 round 229 sad 224 tired 217 dark 190 average 174 "],
["dplyr.html", "Chapter 6 Data Wrangling", " Chapter 6 Data Wrangling "],
["learning-objectives-4.html", "Chapter 7 Learning Objectives 7.1 Basic 7.2 Intermediate/Advanced", " Chapter 7 Learning Objectives 7.1 Basic Be able to use the 6 main dplyr one-table verbs: select() filter() arrange() mutate() summarise() group_by() Also know these additional one-table verbs: rename() distinct() count() slice() pull() Be able to string together commands using pipes %&gt;% 7.2 Intermediate/Advanced Fine control of select() operations Perform ‘windowed’ operations. windowed mutate() windowed slice() "],
["prep-1.html", "Chapter 8 Prep", " Chapter 8 Prep Read Chapter 5: Data Transformation in R for Data Science "],
["resources-5.html", "Chapter 9 Resources", " Chapter 9 Resources Data transformation cheat sheet Lecture slides on dplyr one-table verbs "],
["formative-exercises-1.html", "Chapter 10 Formative exercises", " Chapter 10 Formative exercises Download the formative exercises. See the answers only after you’ve attempted all the questions. "],
["class-notes-1.html", "Chapter 11 Class notes 11.1 Setup 11.2 In-class tasks 11.3 Other things you can try: The disgust dataset", " Chapter 11 Class notes 11.1 Setup You’ll need the following two packages. Might as well convert to a tibble to make printing prettier. library(&quot;tidyverse&quot;) ## ── Attaching packages ──────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.8 ## ✔ tidyr 0.8.2 ✔ stringr 1.3.1 ## ✔ readr 1.3.0 ✔ forcats 0.3.0 ## ── Conflicts ─────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() library(&quot;ukbabynames&quot;) ## convert to a tibble ukb &lt;- as_tibble(ukbabynames) 11.2 In-class tasks 11.2.1 Easy How many records are in the dataset? Solution count(ukb) ## or: nrow(ukb) ## # A tibble: 1 x 1 ## nn ## &lt;int&gt; ## 1 227449 Remove the column rank from the dataset. Solution ukb %&gt;% select(-rank) ## # A tibble: 227,449 x 4 ## year sex name n ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1996 F Sophie 7087 ## 2 1996 F Chloe 6824 ## 3 1996 F Jessica 6711 ## 4 1996 F Emily 6415 ## 5 1996 F Lauren 6299 ## 6 1996 F Hannah 5916 ## 7 1996 F Charlotte 5866 ## 8 1996 F Rebecca 5828 ## 9 1996 F Amy 5206 ## 10 1996 F Megan 4948 ## # ... with 227,439 more rows What is the range of birth years contained in the dataset? Solution ukb %&gt;% summarise(minyear = min(year), maxyear = max(year)) ## # A tibble: 1 x 2 ## minyear maxyear ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1996 2015 Pull out the babies named Hermione. Solution ukb %&gt;% filter(name == &quot;Hermione&quot;) ## # A tibble: 20 x 5 ## year sex name n rank ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1996 F Hermione 21 974 ## 2 1997 F Hermione 29 789 ## 3 1998 F Hermione 40 628 ## 4 1999 F Hermione 35 678 ## 5 2000 F Hermione 40 637 ## 6 2001 F Hermione 52 540 ## 7 2002 F Hermione 84 394 ## 8 2003 F Hermione 158 265 ## 9 2004 F Hermione 162 265 ## 10 2005 F Hermione 122 331 ## 11 2006 F Hermione 118 359 ## 12 2007 F Hermione 109 385 ## 13 2008 F Hermione 129 348 ## 14 2009 F Hermione 116 370 ## 15 2010 F Hermione 111 398 ## 16 2011 F Hermione 118 392 ## 17 2012 F Hermione 97 465 ## 18 2013 F Hermione 77 542 ## 19 2014 F Hermione 85 500 ## 20 2015 F Hermione 79 549 Sort the dataset by sex and then by year (descending) and then by rank (descending). Solution ukb %&gt;% arrange(sex, desc(year), desc(rank)) ## # A tibble: 227,449 x 5 ## year sex name n rank ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015 F Aabidah 3 5730 ## 2 2015 F Aabish 3 5730 ## 3 2015 F Aaeesha 3 5730 ## 4 2015 F Aafreen 3 5730 ## 5 2015 F Aaiza 3 5730 ## 6 2015 F Aakifa 3 5730 ## 7 2015 F Aala 3 5730 ## 8 2015 F Aaliyah-Mai 3 5730 ## 9 2015 F Aaliyah-may 3 5730 ## 10 2015 F Aamena 3 5730 ## # ... with 227,439 more rows Create a new column, decade, that contains the decade of birth (1990, 2000, 2010). Hint: see ?floor Solution ukb %&gt;% mutate(decade = floor(year / 10) * 10) ## # A tibble: 227,449 x 6 ## year sex name n rank decade ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1996 F Sophie 7087 1 1990 ## 2 1996 F Chloe 6824 2 1990 ## 3 1996 F Jessica 6711 3 1990 ## 4 1996 F Emily 6415 4 1990 ## 5 1996 F Lauren 6299 5 1990 ## 6 1996 F Hannah 5916 6 1990 ## 7 1996 F Charlotte 5866 7 1990 ## 8 1996 F Rebecca 5828 8 1990 ## 9 1996 F Amy 5206 9 1990 ## 10 1996 F Megan 4948 10 1990 ## # ... with 227,439 more rows Pull out the male babies named Courtney that were born between 1998 and 2001 (inclusive). Solution ukb %&gt;% filter(name == &quot;Courtney&quot;, sex == &quot;M&quot;, year &gt;= 1998, year &lt;= 2001) ## # A tibble: 4 x 5 ## year sex name n rank ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1998 M Courtney 33 554 ## 2 1999 M Courtney 15 973 ## 3 2000 M Courtney 19 848 ## 4 2001 M Courtney 22 786 How many distinct names are represented in the dataset? Solution ## how many distinct names are represented in the dataset? ukb %&gt;% distinct(name) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 31272 Pull out all the female babies named Frankie that were born before 1999 or after 2010 Solution ukb %&gt;% filter(name == &quot;Frankie&quot;, sex == &quot;F&quot;, (year &lt; 1999) | (year &gt; 2010)) ## # A tibble: 8 x 5 ## year sex name n rank ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1996 F Frankie 34 686 ## 2 1997 F Frankie 48 545 ## 3 1998 F Frankie 41 619 ## 4 2011 F Frankie 337 156 ## 5 2012 F Frankie 298 173 ## 6 2013 F Frankie 273 195 ## 7 2014 F Frankie 344 162 ## 8 2015 F Frankie 376 147 How many total babies in the dataset were named ‘Emily’? Solution ## ukb %&gt;% filter(name == &quot;Emily&quot;) %&gt;% summarise(tot = sum(n)) %&gt;% pull(tot) ## [1] 102250 How many distinct names are there for each sex? Solution ukb %&gt;% group_by(sex) %&gt;% distinct(name) %&gt;% count() ## # A tibble: 2 x 2 ## # Groups: sex [2] ## sex n ## &lt;chr&gt; &lt;int&gt; ## 1 F 18823 ## 2 M 14378 What is the most popular name in the dataset? Solution ukb %&gt;% group_by(name) %&gt;% summarise(tot = sum(n)) %&gt;% arrange(desc(tot)) %&gt;% slice(1) %&gt;% pull(name) ## [1] &quot;Jack&quot; How many babies were born each year for each sex? Make a plot. Solution babes_per_year &lt;- ukb %&gt;% group_by(year, sex) %&gt;% summarise(tot = sum(n)) ggplot(babes_per_year, aes(year, tot, color = sex)) + geom_line() 11.2.2 Intermediate For the next questions, you might first want to read about window functions (group_by() + filter() or mutate() in the dplyr vignette: vignette(&quot;window-functions&quot;). Create a column prop that contains the proportion of babies that were given a particular name for a given sex in a given year, then ungroup() the resulting table. Solution ukb_prop &lt;- ukb %&gt;% group_by(year, sex) %&gt;% mutate(p = n / sum(n)) %&gt;% ungroup() ## TODO double check that you did it right by making sure the props ## for each year/sex combo sum to 1 Use a window function to pull out the top year for each name/sex combination in the table you just created (i.e., the year when the name was given to greatest proportion of babies of a given sex). Solution ukb_top_year &lt;- ukb_prop %&gt;% group_by(name, sex) %&gt;% filter(p == max(p)) %&gt;% ungroup() %&gt;% arrange(year) 11.2.3 Advanced Make a frequency histogram for the final letter of each name, broken down by sex. Are certain final letters more “gendered” than others? Solution last_letter &lt;- ukb %&gt;% mutate(lastchar = substr(name, nchar(name), nchar(name))) %&gt;% filter(lastchar %in% letters) %&gt;% count(sex, lastchar) %&gt;% arrange(lastchar) ggplot(last_letter, aes(lastchar, nn, fill = sex)) + geom_bar(stat = &quot;identity&quot;) Calculate the top 5 boys and girls names for each decade and print out the whole table. Solution ukb %&gt;% mutate(decade = floor(year / 10) * 10) %&gt;% group_by(decade, sex, name) %&gt;% summarise(tot_n = sum(n)) %&gt;% arrange(desc(tot_n)) %&gt;% slice(1:5) %&gt;% ungroup() %&gt;% print(n = +Inf) ## # A tibble: 30 x 4 ## decade sex name tot_n ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1990 F Chloe 33235 ## 2 1990 F Emily 26341 ## 3 1990 F Sophie 24111 ## 4 1990 F Megan 23363 ## 5 1990 F Jessica 23319 ## 6 1990 M Jack 40554 ## 7 1990 M Thomas 38004 ## 8 1990 M James 37183 ## 9 1990 M Daniel 34052 ## 10 1990 M Joshua 30532 ## 11 2000 F Emily 51663 ## 12 2000 F Chloe 50965 ## 13 2000 F Jessica 48023 ## 14 2000 F Olivia 44937 ## 15 2000 F Sophie 44885 ## 16 2000 M Jack 82540 ## 17 2000 M Thomas 70475 ## 18 2000 M Joshua 69428 ## 19 2000 M James 59247 ## 20 2000 M Oliver 56990 ## 21 2010 F Amelia 32397 ## 22 2010 F Olivia 28977 ## 23 2010 F Emily 24246 ## 24 2010 F Jessica 21690 ## 25 2010 F Lily 21379 ## 26 2010 M Oliver 42642 ## 27 2010 M Harry 38128 ## 28 2010 M Jack 37492 ## 29 2010 M Charlie 31009 ## 30 2010 M Jacob 29667 Pull out the top 5 boys and girls names for the final year of the dataset, and plot the historical trajectory of their popularity, with separate graphs for boys and girls. (Hint: This might require merging tables, which you will learn about next week.) Solution top_names &lt;- ukb %&gt;% filter(year == max(year), rank &lt;= 5) %&gt;% select(sex, name) ukb %&gt;% inner_join(top_names, c(&quot;sex&quot;, &quot;name&quot;)) %&gt;% ggplot(aes(year, n, color = name)) + geom_line() + facet_wrap(~sex) What are the 10 most androgynous names in the UK? Discard any names that were given to less than 5000 babies total. Calculate an “androgyny index” for each name as log(F + .5) - log(M + .5) where F is the number of female and M is the number of male babies. This index will be zero for perfect gender balance, positive for skewed female, and negative for skewed male. Solution andro &lt;- ukb %&gt;% group_by(sex, name) %&gt;% summarise(tot = sum(n)) %&gt;% ungroup() %&gt;% spread(sex, tot, fill = 0) %&gt;% mutate(N = F + M) andro_gbal &lt;- andro %&gt;% filter(N &gt;= 5000) %&gt;% mutate(gbal = log(F + .5) - log(M + .5), tot = F + M) %&gt;% arrange(abs(gbal)) %&gt;% slice(1:10) Which girl name has increased the most in popularity, if you directly compare the first year of the dataset to the last year? Which girl name has decreased the most? (Only comare names that were given to at least 500 babies in at least one of the years covered by the dataset.) Solution name_pop &lt;- ukb %&gt;% filter(sex == &quot;F&quot;, (year == 1996) | (year == 2015)) %&gt;% spread(year, n, fill = 0) %&gt;% filter(`2015` &gt; 500 | `1996` &gt; 500) %&gt;% mutate(chg = `2015` - `1996`) name_pop %&gt;% arrange(desc(chg)) %&gt;% slice(1) %&gt;% pull(name) ## [1] &quot;Amelia&quot; name_pop %&gt;% arrange(chg) %&gt;% slice(1) %&gt;% pull(name) ## [1] &quot;Sophie&quot; Calculate the proportion of names that are androgynous for each year in the dataset (were given to both male and female babies) and then plot the historical trend. Solution p_andro &lt;- ukb %&gt;% select(-rank) %&gt;% spread(sex, n, fill = 0) %&gt;% mutate(is_andro = (F != 0) &amp; (M != 0)) %&gt;% group_by(year) %&gt;% summarise(p = mean(is_andro)) ggplot(p_andro, aes(year, p)) + geom_line() Naming diversity trends. Calculate a naming diversity index (number of names divided by number of babies) for each year and sex in the dataset. Plot the historical trend for naming diversity. Solution ndiversity &lt;- ukb %&gt;% group_by(year, sex) %&gt;% summarise(n_names = n_distinct(name), n_babies = sum(n), d_index = n_names / n_babies) %&gt;% ungroup() ggplot(ndiversity, aes(year, d_index, color = sex)) + geom_line() 11.3 Other things you can try: The disgust dataset Some of the tasks below involve the use of the lubridate package for working with dates and times. See R4DS: Chapter 16: Date and times in R for Data Science # libraries needed for these examples library(lubridate) library(tidyverse) These examples will use data from disgust.csv, which contains data from the Three Domain Disgust Scale. Each participant is identified by a unique user_id and each questionnaire completion has a unique id. disgust &lt;- read_csv(&quot;https://gupsych.github.io/data_skills/data/disgust.csv&quot;) Questionnaire Instructions: The following items describe a variety of concepts. Please rate how disgusting you find the concepts described in the items, where 0 means that you do not find the concept disgusting at all, and 6 means that you find the concept extremely disgusting. colname question moral1 Shoplifting a candy bar from a convenience store moral2 Stealing from a neighbor moral3 A student cheating to get good grades moral4 Deceiving a friend moral5 Forging someone’s signature on a legal document moral6 Cutting to the front of a line to purchase the last few tickets to a show moral7 Intentionally lying during a business transaction sexual1 Hearing two strangers having sex sexual2 Performing oral sex sexual3 Watching a pornographic video sexual4 Finding out that someone you don’t like has sexual fantasies about you sexual5 Bringing someone you just met back to your room to have sex sexual6 A stranger of the opposite sex intentionally rubbing your thigh in an elevator sexual7 Having anal sex with someone of the opposite sex pathogen1 Stepping on dog poop pathogen2 Sitting next to someone who has red sores on their arm pathogen3 Shaking hands with a stranger who has sweaty palms pathogen4 Seeing some mold on old leftovers in your refrigerator pathogen5 Standing close to a person who has body odor pathogen6 Seeing a cockroach run across the floor pathogen7 Accidentally touching a person’s bloody cut 11.3.1 select() Select columns by name or number. You can select each column individually, separated by commas (e.g., col1, col2). You can also select all columns between two columns by separating them with a colon (e.g., start_col:end_col). moral &lt;- disgust %&gt;% select(user_id, moral1:moral7) glimpse(moral) ## Observations: 20,000 ## Variables: 8 ## $ user_id &lt;dbl&gt; 0, 1, 2, 2118, 2311, 3630, 4458, 4651, 4976, 5469, 606... ## $ moral1 &lt;dbl&gt; 5, 2, 1, 0, 4, 1, 3, 2, 6, 0, 4, 1, 1, 4, 2, 1, NA, 3,... ## $ moral2 &lt;dbl&gt; 6, 2, 1, 1, 4, 5, 4, 4, 6, 1, 5, 2, 4, 4, 5, 3, NA, 5,... ## $ moral3 &lt;dbl&gt; 4, 1, 1, 1, 4, NA, 3, 3, 6, 3, 6, 2, 3, 4, 4, 2, NA, 4... ## $ moral4 &lt;dbl&gt; 6, 2, 1, 1, 4, 5, 4, 5, 0, 4, 5, 2, 4, 4, 6, 4, NA, 5,... ## $ moral5 &lt;dbl&gt; 5, 1, NA, 1, 4, 5, 4, 5, 6, 1, 5, 1, 3, 3, 5, 5, NA, 3... ## $ moral6 &lt;dbl&gt; 5, 1, NA, 2, 4, 5, 3, 5, 0, 0, 4, 2, 4, 3, 4, 4, NA, 4... ## $ moral7 &lt;dbl&gt; 6, 1, 1, 1, 4, 1, 3, 3, 0, 1, 4, 1, 3, 2, 5, 4, NA, 3,... You can select colmns by number, which is useful when the column names are long or complicated. sexual &lt;- disgust %&gt;% select(2, 11:17) glimpse(sexual) ## Observations: 20,000 ## Variables: 8 ## $ user_id &lt;dbl&gt; 0, 1, 2, 2118, 2311, 3630, 4458, 4651, 4976, 5469, 606... ## $ sexual1 &lt;dbl&gt; 4, 3, 1, 4, 2, 0, 2, 4, 0, 3, 3, 1, 1, 4, 2, 0, NA, 1,... ## $ sexual2 &lt;dbl&gt; 0, 1, NA, 3, 1, 5, 4, 2, 0, 5, 0, 0, 0, 2, 1, 0, NA, 3... ## $ sexual3 &lt;dbl&gt; 1, 1, 1, 0, 2, 0, 3, 4, 0, 2, 1, 0, 0, 1, 0, 0, NA, 3,... ## $ sexual4 &lt;dbl&gt; 0, 2, NA, 6, 1, 2, 2, 6, 0, 4, 6, 3, 1, 3, 2, 0, NA, 5... ## $ sexual5 &lt;dbl&gt; 1, 1, 1, 0, 1, 0, 1, 6, 0, 6, 3, 0, 0, 2, 1, 0, NA, 5,... ## $ sexual6 &lt;dbl&gt; 4, 2, NA, 3, 1, 1, 5, 6, 0, 6, 5, 4, 2, 3, 4, 0, NA, 3... ## $ sexual7 &lt;dbl&gt; 5, 2, NA, 5, 5, 0, 4, 2, 0, 5, 3, 4, 1, 6, 3, 0, NA, 3... You can use a minus symbol to unselect columns, leaving all of the other columns. If you want to exclude a span of columns, put parentheses around the span first (e.g., -(moral1:moral7), not -moral1:moral7). pathogen &lt;- disgust %&gt;% select(-id, -date, -(moral1:sexual7)) glimpse(pathogen) ## Observations: 20,000 ## Variables: 8 ## $ user_id &lt;dbl&gt; 0, 1, 2, 2118, 2311, 3630, 4458, 4651, 4976, 5469, 6... ## $ pathogen1 &lt;dbl&gt; 6, 3, NA, 5, 5, 6, 6, 5, 6, 5, 6, 4, 4, 5, 3, 5, NA,... ## $ pathogen2 &lt;dbl&gt; 1, 2, NA, 6, 5, 3, 4, 6, 6, 2, 5, 3, 4, 2, 3, 4, NA,... ## $ pathogen3 &lt;dbl&gt; 6, 3, 1, 4, 4, 1, 4, 6, 6, 4, 5, 1, 3, 0, 2, 3, NA, ... ## $ pathogen4 &lt;dbl&gt; 5, 3, NA, 6, 4, 1, 3, 4, 6, 4, 5, 1, 4, 4, 4, 1, NA,... ## $ pathogen5 &lt;dbl&gt; 4, 2, NA, 5, 5, 3, 3, 6, 0, 2, 5, 4, 5, 5, 5, 4, NA,... ## $ pathogen6 &lt;dbl&gt; 5, 3, NA, 5, 4, 1, 2, 1, 0, 2, 5, 1, 4, 5, 1, 2, NA,... ## $ pathogen7 &lt;dbl&gt; 6, 3, NA, 4, 3, 0, 3, 6, 6, 6, 5, 3, 5, 4, 5, 3, NA,... 11.3.2 select() helpers You can select columns based on criteria about the column names. 11.3.2.1 starts_with() Select columns that start with a character string. u &lt;- disgust %&gt;% select(starts_with(&quot;u&quot;)) glimpse(u) ## Observations: 20,000 ## Variables: 1 ## $ user_id &lt;dbl&gt; 0, 1, 2, 2118, 2311, 3630, 4458, 4651, 4976, 5469, 606... 11.3.2.2 ends_with() Select columns that end with a character string. firstq &lt;- disgust %&gt;% select(ends_with(&quot;1&quot;)) glimpse(firstq) ## Observations: 20,000 ## Variables: 3 ## $ moral1 &lt;dbl&gt; 5, 2, 1, 0, 4, 1, 3, 2, 6, 0, 4, 1, 1, 4, 2, 1, NA, ... ## $ sexual1 &lt;dbl&gt; 4, 3, 1, 4, 2, 0, 2, 4, 0, 3, 3, 1, 1, 4, 2, 0, NA, ... ## $ pathogen1 &lt;dbl&gt; 6, 3, NA, 5, 5, 6, 6, 5, 6, 5, 6, 4, 4, 5, 3, 5, NA,... 11.3.2.3 contains() Select columns that contain a character string. pathogen &lt;- disgust %&gt;% select(contains(&quot;pathogen&quot;)) glimpse(pathogen) ## Observations: 20,000 ## Variables: 7 ## $ pathogen1 &lt;dbl&gt; 6, 3, NA, 5, 5, 6, 6, 5, 6, 5, 6, 4, 4, 5, 3, 5, NA,... ## $ pathogen2 &lt;dbl&gt; 1, 2, NA, 6, 5, 3, 4, 6, 6, 2, 5, 3, 4, 2, 3, 4, NA,... ## $ pathogen3 &lt;dbl&gt; 6, 3, 1, 4, 4, 1, 4, 6, 6, 4, 5, 1, 3, 0, 2, 3, NA, ... ## $ pathogen4 &lt;dbl&gt; 5, 3, NA, 6, 4, 1, 3, 4, 6, 4, 5, 1, 4, 4, 4, 1, NA,... ## $ pathogen5 &lt;dbl&gt; 4, 2, NA, 5, 5, 3, 3, 6, 0, 2, 5, 4, 5, 5, 5, 4, NA,... ## $ pathogen6 &lt;dbl&gt; 5, 3, NA, 5, 4, 1, 2, 1, 0, 2, 5, 1, 4, 5, 1, 2, NA,... ## $ pathogen7 &lt;dbl&gt; 6, 3, NA, 4, 3, 0, 3, 6, 6, 6, 5, 3, 5, 4, 5, 3, NA,... 11.3.2.4 num_range(prefix, range, width = NULL) Select columns with a name that matches the pattern prefix#. moral2_4 &lt;- disgust %&gt;% select(num_range(&quot;moral&quot;, 2:4)) glimpse(moral2_4) ## Observations: 20,000 ## Variables: 3 ## $ moral2 &lt;dbl&gt; 6, 2, 1, 1, 4, 5, 4, 4, 6, 1, 5, 2, 4, 4, 5, 3, NA, 5, ... ## $ moral3 &lt;dbl&gt; 4, 1, 1, 1, 4, NA, 3, 3, 6, 3, 6, 2, 3, 4, 4, 2, NA, 4,... ## $ moral4 &lt;dbl&gt; 6, 2, 1, 1, 4, 5, 4, 5, 0, 4, 5, 2, 4, 4, 6, 4, NA, 5, ... Use width to set the number of digits with leading zeros. For example, num_range(&quot;var_&quot;, 8:10, width=2) selects columns var_08, var_09, and var_10. 11.3.3 filter() Select rows by matching column criteria. Select all rows where the user_id is 1 (that’s Lisa). disgust %&gt;% filter(user_id == 1) ## # A tibble: 1 x 24 ## id user_id date moral1 moral2 moral3 moral4 moral5 moral6 moral7 ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2008-07-10 2 2 1 2 1 1 1 ## # ... with 14 more variables: sexual1 &lt;dbl&gt;, sexual2 &lt;dbl&gt;, sexual3 &lt;dbl&gt;, ## # sexual4 &lt;dbl&gt;, sexual5 &lt;dbl&gt;, sexual6 &lt;dbl&gt;, sexual7 &lt;dbl&gt;, ## # pathogen1 &lt;dbl&gt;, pathogen2 &lt;dbl&gt;, pathogen3 &lt;dbl&gt;, pathogen4 &lt;dbl&gt;, ## # pathogen5 &lt;dbl&gt;, pathogen6 &lt;dbl&gt;, pathogen7 &lt;dbl&gt; Remember to use == and not = to check if two things are equivalent. A single = assigns the righthand value to the lefthand variable and (usually) evaluates to TRUE. You can select on multiple criteria by separating them with commas. amoral &lt;- disgust %&gt;% filter( moral1 == 0, moral2 == 0, moral3 == 0, moral4 == 0, moral5 == 0, moral6 == 0, moral7 == 0 ) You can use the symbols &amp;, |, and ! to mean “and”, “or”, and “not”. You can also use other operators to make equations. # everyone who chose either 0 or 7 for question moral1 moral_extremes &lt;- disgust %&gt;% filter(moral1 == 0 | moral1 == 7) # everyone who chose the same answer for all moral questions moral_consistent &lt;- disgust %&gt;% filter( moral2 == moral1 &amp; moral3 == moral1 &amp; moral4 == moral1 &amp; moral5 == moral1 &amp; moral6 == moral1 &amp; moral7 == moral1 ) # everyone who did not answer 7 for all 7 moral questions moral_no_ceiling &lt;- disgust %&gt;% filter(moral1+moral2+moral3+moral4+moral5+moral6+moral7 != 7*7) Sometimes you need to exclude some participant IDs for reasons that can’t be described in code. the %in% operator is useful here for testing if a column value is in a list. Surround the equation with parentheses and put ! in front to test that a value is not in the list. no_researchers &lt;- disgust %&gt;% filter(!(user_id %in% c(1,2))) You can use the lubridate package to work with dates. For example, you can use the year() function to return just the year from the date column and then select only data collected in 2010. disgust2010 &lt;- disgust %&gt;% filter(year(date) == 2010) Or select data from at least 5 years ago. You can use the range function to check the minimum and maxiumum dates in the resulting dataset. disgust_5ago &lt;- disgust %&gt;% filter(date &lt; today() - dyears(5)) range(disgust_5ago$date) ## [1] &quot;2008-07-10&quot; &quot;2014-01-19&quot; 11.3.4 arrange() Sort your dataset using arrange(). disgust_order &lt;- disgust %&gt;% arrange(id) head(disgust_order) ## # A tibble: 6 x 24 ## id user_id date moral1 moral2 moral3 moral4 moral5 moral6 moral7 ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2008-07-10 2 2 1 2 1 1 1 ## 2 3 155324 2008-07-11 2 4 3 5 2 1 4 ## 3 4 155366 2008-07-12 6 6 6 3 6 6 6 ## 4 5 155370 2008-07-12 6 6 4 6 6 6 6 ## 5 6 155386 2008-07-12 2 4 0 4 0 0 0 ## 6 7 155409 2008-07-12 4 5 5 4 5 1 5 ## # ... with 14 more variables: sexual1 &lt;dbl&gt;, sexual2 &lt;dbl&gt;, sexual3 &lt;dbl&gt;, ## # sexual4 &lt;dbl&gt;, sexual5 &lt;dbl&gt;, sexual6 &lt;dbl&gt;, sexual7 &lt;dbl&gt;, ## # pathogen1 &lt;dbl&gt;, pathogen2 &lt;dbl&gt;, pathogen3 &lt;dbl&gt;, pathogen4 &lt;dbl&gt;, ## # pathogen5 &lt;dbl&gt;, pathogen6 &lt;dbl&gt;, pathogen7 &lt;dbl&gt; Reverse the order using desc() disgust_order &lt;- disgust %&gt;% arrange(desc(id)) head(disgust_order) ## # A tibble: 6 x 24 ## id user_id date moral1 moral2 moral3 moral4 moral5 moral6 moral7 ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 39456 356866 2017-08-21 1 1 1 1 1 1 1 ## 2 39447 128727 2017-08-13 2 4 1 2 2 5 3 ## 3 39371 152955 2017-06-13 6 6 3 6 6 6 6 ## 4 39342 48303 2017-05-22 4 5 4 4 6 4 5 ## 5 39159 151633 2017-04-04 4 5 6 5 3 6 2 ## 6 38942 370464 2017-02-01 1 5 0 6 5 5 5 ## # ... with 14 more variables: sexual1 &lt;dbl&gt;, sexual2 &lt;dbl&gt;, sexual3 &lt;dbl&gt;, ## # sexual4 &lt;dbl&gt;, sexual5 &lt;dbl&gt;, sexual6 &lt;dbl&gt;, sexual7 &lt;dbl&gt;, ## # pathogen1 &lt;dbl&gt;, pathogen2 &lt;dbl&gt;, pathogen3 &lt;dbl&gt;, pathogen4 &lt;dbl&gt;, ## # pathogen5 &lt;dbl&gt;, pathogen6 &lt;dbl&gt;, pathogen7 &lt;dbl&gt; 11.3.5 mutate() Add new columns. This is one of the most useful functions in the tidyverse. Refer to other columns by their names (unquoted). You can add more than one column, just separate the columns with a comma. Once you make a new column, you can use it in further column definitions e.g., total below). disgust_total &lt;- disgust %&gt;% mutate( pathogen = pathogen1 + pathogen2 + pathogen3 + pathogen4 + pathogen5 + pathogen6 + pathogen7, moral = moral1 + moral2 + moral3 + moral4 + moral5 + moral6 + moral7, sexual = sexual1 + sexual2 + sexual3 + sexual4 + sexual5 + sexual6 + sexual7, total = pathogen + moral + sexual, user_id = paste0(&quot;U&quot;, user_id) ) You can overwrite a column by giving a new column the same name as the old column. Make sure that you mean to do this and that you aren’t trying to use the old column value after you redefine it. 11.3.6 summarise() Create summary statistics for the dataset. Check the Data Wrangling Cheat Sheet or the Data Transformation Cheat Sheet for various summary functions. Some common ones are: mean(), sd(), n(), sum(), and quantile(). disgust_total %&gt;% summarise( n = n(), q25 = quantile(total, .25, na.rm = TRUE), q50 = quantile(total, .50, na.rm = TRUE), q75 = quantile(total, .75, na.rm = TRUE), avg_total = mean(total, na.rm = TRUE), sd_total = sd(total, na.rm = TRUE), min_total = min(total, na.rm = TRUE), max_total = max(total, na.rm = TRUE) ) ## # A tibble: 1 x 8 ## n q25 q50 q75 avg_total sd_total min_total max_total ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20000 59 71 83 70.7 18.2 0 126 11.3.7 group_by() Create subsets of the data. You can use this to create summaries, like the mean value for all of your experimental groups. Here, we’ll use mutate to create a new column called year, group by year, and calculate the average scores. disgust_total %&gt;% mutate(year = year(date)) %&gt;% group_by(year) %&gt;% summarise( n = n(), avg_total = mean(total, na.rm = TRUE), sd_total = sd(total, na.rm = TRUE), min_total = min(total, na.rm = TRUE), max_total = max(total, na.rm = TRUE) ) ## # A tibble: 10 x 6 ## year n avg_total sd_total min_total max_total ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2008 2578 70.3 18.5 0 126 ## 2 2009 2580 69.7 18.6 3 126 ## 3 2010 1514 70.6 18.9 6 126 ## 4 2011 6046 71.3 17.8 0 126 ## 5 2012 5938 70.4 18.4 0 126 ## 6 2013 1251 71.6 17.6 0 126 ## 7 2014 58 70.5 17.2 19 113 ## 8 2015 21 74.3 16.9 43 107 ## 9 2016 8 67.9 32.6 0 110 ## 10 2017 6 57.2 27.9 21 90 You can use filter after group_by. The following example returns the lowest total score from each year. disgust_total %&gt;% mutate(year = year(date)) %&gt;% select(user_id, year, total) %&gt;% group_by(year) %&gt;% filter(rank(total) == 1) %&gt;% arrange(year) ## # A tibble: 7 x 3 ## # Groups: year [7] ## user_id year total ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 U236585 2009 3 ## 2 U292359 2010 6 ## 3 U245384 2013 0 ## 4 U206293 2014 19 ## 5 U407089 2015 43 ## 6 U453237 2016 0 ## 7 U356866 2017 21 You can also use mutate after group_by. The following example calculates subject-mean-centered scores by grouping the scores by user_id and then subtracting the group-specific mean from each score. Note the use of gather to tidy the data into a long format first. disgust_smc &lt;- disgust %&gt;% gather(&quot;question&quot;, &quot;score&quot;, moral1:pathogen7) %&gt;% group_by(user_id) %&gt;% mutate(score_smc = score - mean(score, na.rm = TRUE)) 11.3.8 All Together A lot of what we did above would be easier if the data were tidy, so let’s do that first. Then we can use group_by to calculate the domain scores. It is good practice to use ungroup() after using group_by and summarise. Forgetting to ungroup the dataset won’t affect some further processing, but can really mess up other things. Then we can spread out the 3 domains, calculate the total score, remove any rows with a missing (NA) total, and calculate mean values by year. disgust_tidy &lt;- read_csv(&quot;data/disgust.csv&quot;) %&gt;% gather(&quot;question&quot;, &quot;score&quot;, moral1:pathogen7) %&gt;% separate(question, c(&quot;domain&quot;,&quot;q_num&quot;), sep = -1) %&gt;% group_by(id, user_id, date, domain) %&gt;% summarise(score = mean(score)) %&gt;% ungroup() ## Parsed with column specification: ## cols( ## .default = col_double(), ## date = col_date(format = &quot;&quot;) ## ) ## See spec(...) for full column specifications. disgust_tidy2 &lt;- disgust_tidy %&gt;% spread(domain, score) %&gt;% mutate( total = moral + sexual + pathogen, year = year(date) ) %&gt;% filter(!is.na(total)) %&gt;% arrange(user_id) disgust_tidy3 &lt;- disgust_tidy2 %&gt;% group_by(year) %&gt;% summarise( n = n(), avg_pathogen = mean(pathogen), avg_moral = mean(moral), avg_sexual = mean(sexual), first_user = first(user_id), last_user = last(user_id) ) disgust_tidy3 ## # A tibble: 10 x 7 ## year n avg_pathogen avg_moral avg_sexual first_user last_user ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2008 2392 3.70 3.81 2.54 0 188708 ## 2 2009 2410 3.67 3.76 2.53 6093 251959 ## 3 2010 1418 3.73 3.84 2.51 5469 319641 ## 4 2011 5586 3.76 3.81 2.63 4458 406569 ## 5 2012 5375 3.74 3.77 2.55 2118 458194 ## 6 2013 1222 3.77 3.91 2.55 7646 462428 ## 7 2014 54 3.76 4 2.31 11090 461307 ## 8 2015 19 3.78 4.45 2.38 102699 460283 ## 9 2016 8 3.70 3.62 2.38 4976 453237 ## 10 2017 6 3.07 3.69 1.40 48303 370464 "],
["joins.html", "Chapter 12 Data Relations 12.1 Learning Objectives 12.2 Prep 12.3 Resources 12.4 Formative exercises 12.5 Class Notes 12.6 Exercises", " Chapter 12 Data Relations 12.1 Learning Objectives Be able to use the 4 mutating join verbs: left_join() right_join() inner_join() full_join() Be able to use the 2 binding join verbs: bind_rows() bind_cols() Be able to use the 2 filtering join verbs: semi_join() anti_join() Be able to use the 3 set operations: intersect() union() setdiff() 12.2 Prep Read Chapter 13: Relational Data in R for Data Science 12.3 Resources Cheatsheet for dplyr join functions 12.4 Formative exercises Download the formative exercises. See the answers only after you’ve attempted all the questions. 12.5 Class Notes Lecture slides on dplyr two-table verbs 12.5.1 Setup # libraries needed for these examples library(tidyverse) All the joins have this basic syntax: ****_join(x, y, by = NULL, suffix = c(&quot;.x&quot;, &quot;.y&quot;) x = the first (left) table y = the second (right) table by = what columns to match on. If you leave this blank, it will match on all columns with the same names in the two tables. suffix = if columns have the same name in the two tables, but you aren’t joining by them, they get a suffix to make them unambiguous. This defaults to “.x” and “.y”, but you can change it to something more meaningful. 12.5.2 Data First, we’ll create two small data tables. subject has id, sex and age for subjects 1-5. Age and sex are missing for subject 3. subject &lt;- tibble( id = seq(1,5), sex = c(&quot;m&quot;, &quot;m&quot;, NA, &quot;f&quot;, &quot;f&quot;), age = c(19, 22, NA, 19, 18) ) subject ## # A tibble: 5 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 m 19 ## 2 2 m 22 ## 3 3 &lt;NA&gt; NA ## 4 4 f 19 ## 5 5 f 18 exp has subject id and the score from an experiment. Some subjects are missing, some completed twice, and some are not in the subject table. exp &lt;- tibble( id = c(2, 3, 4, 4, 5, 5, 6, 6, 7), score = c(10, 18, 21, 23, 9, 11, 11, 12, 3) ) exp ## # A tibble: 9 x 2 ## id score ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 10 ## 2 3 18 ## 3 4 21 ## 4 4 23 ## 5 5 9 ## 6 5 11 ## 7 6 11 ## 8 6 12 ## 9 7 3 12.5.3 left_join() A left_join keeps all the data from the first (left) table and joins anything that matches from the second (right) table. If the right table has more than one match for a row in the right table, there will be more than one row in the joined table (see ids 4 and 5). left_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 7 x 4 ## id sex age score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 m 19 NA ## 2 2 m 22 10 ## 3 3 &lt;NA&gt; NA 18 ## 4 4 f 19 21 ## 5 4 f 19 23 ## 6 5 f 18 9 ## 7 5 f 18 11 You can leave out the by argument if you’re matching on all of the columns with the same name, but it’s good practice to always specify it so your code is robust to changes in the loaded data. The order of tables is swapped here, so the result is all rows from the exp table joined to any matching rows from the subject table. left_join(exp, subject, by = &quot;id&quot;) ## # A tibble: 9 x 4 ## id score sex age ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2 10 m 22 ## 2 3 18 &lt;NA&gt; NA ## 3 4 21 f 19 ## 4 4 23 f 19 ## 5 5 9 f 18 ## 6 5 11 f 18 ## 7 6 11 &lt;NA&gt; NA ## 8 6 12 &lt;NA&gt; NA ## 9 7 3 &lt;NA&gt; NA 12.5.4 right_join() A right_join keeps all the data from the second (right) table and joins anything that matches from the first (left) table. right_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 9 x 4 ## id sex age score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 m 22 10 ## 2 3 &lt;NA&gt; NA 18 ## 3 4 f 19 21 ## 4 4 f 19 23 ## 5 5 f 18 9 ## 6 5 f 18 11 ## 7 6 &lt;NA&gt; NA 11 ## 8 6 &lt;NA&gt; NA 12 ## 9 7 &lt;NA&gt; NA 3 This table has the same information as left_join(exp, subject, by = &quot;id&quot;), but the columns are in a different order (left table, then right table). 12.5.5 inner_join() An inner_join returns all the rows that have a match in the other table. inner_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 6 x 4 ## id sex age score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 m 22 10 ## 2 3 &lt;NA&gt; NA 18 ## 3 4 f 19 21 ## 4 4 f 19 23 ## 5 5 f 18 9 ## 6 5 f 18 11 12.5.6 full_join() A full_join lets you join up rows in two tables while keeping all of the information from both tables. If a row doesn’t have a match in the other table, the other table’s column values are set to NA. full_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 10 x 4 ## id sex age score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 m 19 NA ## 2 2 m 22 10 ## 3 3 &lt;NA&gt; NA 18 ## 4 4 f 19 21 ## 5 4 f 19 23 ## 6 5 f 18 9 ## 7 5 f 18 11 ## 8 6 &lt;NA&gt; NA 11 ## 9 6 &lt;NA&gt; NA 12 ## 10 7 &lt;NA&gt; NA 3 12.5.7 semi_join() A semi_join returns all rows from the left table where there are matching values in the right table, keeping just columns from the left table. semi_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 4 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2 m 22 ## 2 3 &lt;NA&gt; NA ## 3 4 f 19 ## 4 5 f 18 Unlike an inner join, a semi join will never duplicate the rows in the left table if there is more than one maching row in the right table. Order matters in a semi join. semi_join(exp, subject, by = &quot;id&quot;) ## # A tibble: 6 x 2 ## id score ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 10 ## 2 3 18 ## 3 4 21 ## 4 4 23 ## 5 5 9 ## 6 5 11 12.5.8 anti_join() A anti_join return all rows from the left table where there are not matching values in the right table, keeping just columns from the left table. anti_join(subject, exp, by = &quot;id&quot;) ## # A tibble: 1 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 m 19 Order matters in an anti join. anti_join(exp, subject, by = &quot;id&quot;) ## # A tibble: 3 x 2 ## id score ## &lt;dbl&gt; &lt;dbl&gt; ## 1 6 11 ## 2 6 12 ## 3 7 3 12.5.9 bind_rows() You can combine the rows of two tables with bind_rows. Here we’ll add subject data for subjects 6-9 and bind that to the original subject table. new_subjects &lt;- tibble( id = seq(6, 9), sex = c(&quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;), age = c(19, 16, 20, 19) ) bind_rows(subject, new_subjects) ## # A tibble: 9 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 m 19 ## 2 2 m 22 ## 3 3 &lt;NA&gt; NA ## 4 4 f 19 ## 5 5 f 18 ## 6 6 m 19 ## 7 7 m 16 ## 8 8 f 20 ## 9 9 f 19 The columns just have to have the same names, they don’t have to be in the same order. Any columns that differ between the two tables will just have NA values for entries from the other table. If a row is duplicated between the two tables (like id 5 below), the row will also be duplicated in the resulting table. If your tables have the exact same columns, you can use union() (see below) to avoid duplicates. new_subjects &lt;- tibble( id = seq(5, 9), age = c(18, 19, 16, 20, 19), sex = c(&quot;f&quot;, &quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;), new = c(1,2,3,4,5) ) bind_rows(subject, new_subjects) ## # A tibble: 10 x 4 ## id sex age new ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 m 19 NA ## 2 2 m 22 NA ## 3 3 &lt;NA&gt; NA NA ## 4 4 f 19 NA ## 5 5 f 18 NA ## 6 5 f 18 1 ## 7 6 m 19 2 ## 8 7 m 16 3 ## 9 8 f 20 4 ## 10 9 f 19 5 12.5.10 bind_cols() You can merge two tables with the same number of rows using bind_cols. This is only useful if the two tables have their rows in the exact same order. The only advantage over a left join is when the tables don’t have any IDs to join by and you have to rely solely on their order. new_info &lt;- tibble( colour = c(&quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;) ) bind_cols(subject, new_info) ## # A tibble: 5 x 4 ## id sex age colour ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 m 19 red ## 2 2 m 22 orange ## 3 3 &lt;NA&gt; NA yellow ## 4 4 f 19 green ## 5 5 f 18 blue 12.5.11 intersect() intersect() returns all rows in two tables that match exactly. The columns don’t have to be in the same order. new_subjects &lt;- tibble( id = seq(4, 9), age = c(19, 18, 19, 16, 20, 19), sex = c(&quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;) ) dplyr::intersect(subject, new_subjects) ## # A tibble: 2 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 f 19 ## 2 5 f 18 12.5.12 union() union() returns all the rows from both tables, removing duplicate rows. dplyr::union(subject, new_subjects) ## # A tibble: 9 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 9 f 19 ## 2 8 f 20 ## 3 7 m 16 ## 4 6 m 19 ## 5 5 f 18 ## 6 4 f 19 ## 7 3 &lt;NA&gt; NA ## 8 2 m 22 ## 9 1 m 19 12.5.13 setdiff() setdiff returns rows that are in the first table, but not in the second table. setdiff(subject, new_subjects) ## # A tibble: 3 x 3 ## id age sex ## &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 19 m ## 2 2 22 m ## 3 3 NA &lt;NA&gt; Order matters for setdiff. setdiff(new_subjects, subject) ## # A tibble: 4 x 3 ## id sex age ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 6 m 19 ## 2 7 m 16 ## 3 8 f 20 ## 4 9 f 19 12.6 Exercises 12.6.1 Mutating joins Load data from disgust_scores.csv, personality_scores.csv and users.csv. Each participant is identified by a unique user_id. Add participant data to the disgust table. Solution disgust &lt;- read_csv(&quot;data/disgust_scores.csv&quot;) ocean &lt;- read_csv(&quot;data/personality_scores.csv&quot;) user &lt;- read_csv(&quot;data/users.csv&quot;) study1 &lt;- left_join(disgust, user, by = &quot;user_id&quot;) head(study1) ## # A tibble: 6 x 8 ## id user_id date moral pathogen sexual sex birthday ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;date&gt; ## 1 1 1 2008-07-10 1.43 2.71 1.71 female 1976-11-18 ## 2 3 155324 2008-07-11 3 2.57 1.86 female 1984-09-30 ## 3 4 155366 2008-07-12 5.57 4 0.429 male 1982-04-09 ## 4 5 155370 2008-07-12 5.71 4.86 4.71 female 1968-04-04 ## 5 6 155386 2008-07-12 1.43 3.86 3.71 male 1983-04-22 ## 6 7 155409 2008-07-12 4.14 4.14 1.57 male 1983-03-31 Intermediate: Calculate the age of each participant on the date they did the disgust questionnaire. Round to the nearest tenth of a year. Solution library(lubridate) study1_ages &lt;- study1 %&gt;% mutate( age = date - birthday, age_days = as.integer(age), age_years = round(age_days/365.25, 1) ) study1_ages %&gt;% select(date, birthday:age_years) %&gt;% head() ## # A tibble: 6 x 5 ## date birthday age age_days age_years ## &lt;date&gt; &lt;date&gt; &lt;time&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2008-07-10 1976-11-18 11557 days 11557 31.6 ## 2 2008-07-11 1984-09-30 8685 days 8685 23.8 ## 3 2008-07-12 1982-04-09 9591 days 9591 26.3 ## 4 2008-07-12 1968-04-04 14709 days 14709 40.3 ## 5 2008-07-12 1983-04-22 9213 days 9213 25.2 ## 6 2008-07-12 1983-03-31 9235 days 9235 25.3 Add the participant data to the disgust data, but have the columns from the participant table first. Solution study2 &lt;- right_join(user, disgust, by = &quot;user_id&quot;) head(study2) ## # A tibble: 6 x 8 ## user_id sex birthday id date moral pathogen sexual ## &lt;dbl&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 female 1976-11-18 1 2008-07-10 1.43 2.71 1.71 ## 2 155324 female 1984-09-30 3 2008-07-11 3 2.57 1.86 ## 3 155366 male 1982-04-09 4 2008-07-12 5.57 4 0.429 ## 4 155370 female 1968-04-04 5 2008-07-12 5.71 4.86 4.71 ## 5 155386 male 1983-04-22 6 2008-07-12 1.43 3.86 3.71 ## 6 155409 male 1983-03-31 7 2008-07-12 4.14 4.14 1.57 Intermediate: How many times was the disgust questionnaire completed by each sex? Solution study2 %&gt;% group_by(sex) %&gt;% summarise(n = n()) ## # A tibble: 4 x 2 ## sex n ## &lt;chr&gt; &lt;int&gt; ## 1 female 13886 ## 2 intersex 3 ## 3 male 6012 ## 4 &lt;NA&gt; 99 Advanced: Make a graph of how many people completed the questionnaire each year. Solution study2 %&gt;% mutate(year = substr(date, 1, 4)) %&gt;% group_by(year) %&gt;% summarise(times_completed = n()) %&gt;% ggplot() + geom_col(aes(year, times_completed, fill = year)) + labs( x = &quot;Year&quot;, y = &quot;Times Completed&quot; ) + guides(fill = FALSE) Create a table with only disgust and personality data from the same user_id collected on the same date. Solution study3 &lt;- inner_join(disgust, ocean, by = c(&quot;user_id&quot;, &quot;date&quot;)) head(study3) ## # A tibble: 6 x 11 ## id user_id date moral pathogen sexual Ag Co Ex Ne ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3 155324 2008-07-11 3 2.57 1.86 4 3.3 4.89 2.38 ## 2 6 155386 2008-07-12 1.43 3.86 3.71 3.14 2.6 4 0.25 ## 3 17 155567 2008-07-14 5.57 4.71 2.57 5.29 5.7 3.89 1.12 ## 4 18 155571 2008-07-14 2.71 6 4.43 3.71 3.8 4.56 2.25 ## 5 21 155665 2008-07-15 4.14 4.14 3.43 2.86 1.8 4.67 3.12 ## 6 22 155682 2008-07-15 2.71 3 0.714 3.43 3 3.56 1.38 ## # ... with 1 more variable: Op &lt;dbl&gt; Intermediate: Join data from the same user_id, regardless of date. Does this give you the same data table as above? Solution study3_nodate &lt;- inner_join(disgust, ocean, by = c(&quot;user_id&quot;)) head(study3_nodate) ## # A tibble: 6 x 12 ## id user_id date.x moral pathogen sexual date.y Ag Co ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2008-07-10 1.43 2.71 1.71 2006-02-08 2.57 3 ## 2 3 155324 2008-07-11 3 2.57 1.86 2008-07-11 4 3.3 ## 3 6 155386 2008-07-12 1.43 3.86 3.71 2008-07-12 3.14 2.6 ## 4 17 155567 2008-07-14 5.57 4.71 2.57 2008-07-14 5.29 5.7 ## 5 18 155571 2008-07-14 2.71 6 4.43 2008-07-14 3.71 3.8 ## 6 20 124756 2008-07-14 5.43 5.14 2.71 2008-01-23 4.86 3.8 ## # ... with 3 more variables: Ex &lt;dbl&gt;, Ne &lt;dbl&gt;, Op &lt;dbl&gt; Create a table of the disgust and personality data with each user_id:date on a single row, containing all of the data from both tables. Solution study4 &lt;- full_join(disgust, ocean, by = c(&quot;user_id&quot;, &quot;date&quot;)) head(study4) ## # A tibble: 6 x 11 ## id user_id date moral pathogen sexual Ag Co Ex Ne ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2008-07-10 1.43 2.71 1.71 NA NA NA NA ## 2 3 155324 2008-07-11 3 2.57 1.86 4 3.3 4.89 2.38 ## 3 4 155366 2008-07-12 5.57 4 0.429 NA NA NA NA ## 4 5 155370 2008-07-12 5.71 4.86 4.71 NA NA NA NA ## 5 6 155386 2008-07-12 1.43 3.86 3.71 3.14 2.6 4 0.25 ## 6 7 155409 2008-07-12 4.14 4.14 1.57 NA NA NA NA ## # ... with 1 more variable: Op &lt;dbl&gt; 12.6.2 Filtering joins Create a table of just the data from the disgust table for users who completed the personality questionnaire that same day. Solution study5 &lt;- semi_join(disgust, ocean, by = c(&quot;user_id&quot;, &quot;date&quot;)) head(study5) ## # A tibble: 6 x 6 ## id user_id date moral pathogen sexual ## &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3 155324 2008-07-11 3 2.57 1.86 ## 2 6 155386 2008-07-12 1.43 3.86 3.71 ## 3 17 155567 2008-07-14 5.57 4.71 2.57 ## 4 18 155571 2008-07-14 2.71 6 4.43 ## 5 21 155665 2008-07-15 4.14 4.14 3.43 ## 6 22 155682 2008-07-15 2.71 3 0.714 Create a table of data from users who did not complete either the personality questionnaire or the disgust questionnaire. (Hint: this will require two steps; use pipes.) Solution study6 &lt;- user %&gt;% anti_join(ocean, by = &quot;user_id&quot;) %&gt;% anti_join(disgust, by = &quot;user_id&quot;) head(study6) ## # A tibble: 6 x 3 ## user_id sex birthday ## &lt;dbl&gt; &lt;chr&gt; &lt;date&gt; ## 1 9 male 1972-01-19 ## 2 10 female 1978-06-20 ## 3 17 female 1981-11-21 ## 4 19 female 1980-08-08 ## 5 20 male 1964-08-27 ## 6 21 male 1945-06-13 12.6.3 Binding and sets Load new user data from users2.csv. Bind them into a single table. Solution user2 &lt;- read_csv(&quot;data/users2.csv&quot;) users_all &lt;- bind_rows(user, user2) head(users_all) ## # A tibble: 6 x 3 ## user_id sex birthday ## &lt;dbl&gt; &lt;chr&gt; &lt;date&gt; ## 1 0 &lt;NA&gt; NA ## 2 1 female 1976-11-18 ## 3 2 male 1985-10-09 ## 4 5 male 1980-06-26 ## 5 8 male 1968-06-21 ## 6 9 male 1972-01-19 How many users are in both the first and second user table? Solution dplyr::intersect(user, user2) %&gt;% nrow() ## [1] 11602 How many unique users are there in total across the first and second user tables? Solution dplyr::union(user, user2) %&gt;% nrow() ## [1] 100441 How many users are in the first, but not the second, user table? Solution dplyr::setdiff(user, user2) %&gt;% nrow() ## [1] 40441 How many users are in the second, but not the first, user table? Solution dplyr::setdiff(user2, user) %&gt;% nrow() ## [1] 48398 "],
["func.html", "Chapter 13 Iteration &amp; Functions 13.1 Learning Objectives 13.2 Prep 13.3 Resources 13.4 Formative exercises 13.5 Class Notes", " Chapter 13 Iteration &amp; Functions 13.1 Learning Objectives You will learn about functions and iteration by using simulation to calculate a power analysis for ANOVA on a simple two-group design. 13.1.1 Basic work with iteration functions rep, seq, and replicate use arguments by order or name write your own custom functions with function() set default values for the arguments in your functions 13.1.2 Intermediate understand scope use error handling and warnings in a function 13.1.3 Advanced The topics below are not covered in these materials, but they are directions for independent learning. repeat commands and handle result using purrr::rerun(), purrr::map_*(), purrr::walk() repeat commands having multiple arguments using purrr::map2_*() and purrr::pmap_*() create nested data frames using dplyr::group_by() and tidyr::nest() work with nested data frames in dplyr capture and deal with errors using ‘adverb’ functions purrr::safely() and purrr::possibly() 13.2 Prep Read Chapters 19 and 21 of R for Data Science 13.3 Resources RStudio Apply Functions Cheatsheet 13.4 Formative exercises Download the formative exercises. See the answers only after you’ve attempted all the questions. 13.5 Class Notes In the next two lectures, we are going to learn more about iteration (doing the same commands over and over) and custom functions through a data simulation exercise, which will also lead us into more traditional statistical topics. Along the way you will also learn more about how to create vectors and tables in R. # libraries needed for these examples library(tidyverse) ## contains purrr, tidyr, dplyr ## ── Attaching packages ──────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.8 ## ✔ tidyr 0.8.2 ✔ stringr 1.3.1 ## ✔ readr 1.3.0 ✔ forcats 0.3.0 ## ── Conflicts ─────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() 13.5.1 Iteration functions 13.5.1.1 rep() The function rep() lefts you repeat the first argument a number of times. Use rep() to create a vector of alternating &quot;A&quot; and &quot;B&quot; values of length 24. rep(c(&quot;A&quot;, &quot;B&quot;), 12) ## [1] &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; ## [18] &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; &quot;A&quot; &quot;B&quot; Use rep() to create a vector of 12 &quot;A&quot; values followed by 12 &quot;B&quot; values rep(c(&quot;A&quot;, &quot;B&quot;), each = 12) ## [1] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; ## [18] &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; Use rep() to create a vector of 11 &quot;A&quot; values followed by 3 &quot;B&quot; values rep(c(&quot;A&quot;, &quot;B&quot;), c(11, 3)) ## [1] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; 13.5.1.2 seq() The function seq() is useful for generating a sequence of numbers with some pattern. Use seq() to create a vector of the numbers 0 to 100 by 10s. seq(0, 100, by = 10) ## [1] 0 10 20 30 40 50 60 70 80 90 100 The argument length.out is useful if you know how many steps you want to divide something into Use seq() to create a vector that starts with 0, ends with 100, and has 12 equally spaced steps (hint: how many numbers would be in a vector with 2 steps?). seq(0, 100, length.out = 13) ## [1] 0.000000 8.333333 16.666667 25.000000 33.333333 41.666667 ## [7] 50.000000 58.333333 66.666667 75.000000 83.333333 91.666667 ## [13] 100.000000 13.5.2 Custom functions In addition to the built-n functions and functions you can access from packages, you can also write your own functions (and eventually even packages!). 13.5.2.1 Structuring a function The general structure of a function is as follows: function_name &lt;- function(my_args) { # process the arguments # return some value } Here is a very simple function. Can you guess what it does? add1 &lt;- function(my_number) { my_number + 1 } add1(10) ## [1] 11 Let’s make a function that reports p-values in APA format (with “p = rounded value” when p &gt;= .001 and “p &lt; .001” when p &lt; .001). First, we have to name the function. You can name it anything, but try not to duplicate existing functions or you will overwrite them. For example, if you call your function rep, then you will need to use base::rep() to access the normal rep function. Let’s call our p-value function report_p and set up the framework of the function. report_p &lt;- function() { } 13.5.2.2 Arguments We need to add one argument, the p-value you want to report. The names you choose for the arguments are private to that argument, so it is not a problem if they conflict with other variables in your script. You put the arguments in the parentheses after function in the order you want them to default (just like the built-in functions you’ve used before). report_p &lt;- function(p) { } 13.5.2.3 Argument defaults You can add a default value to any argument. If that argument is skipped, then the function uses the default argument. It probably doesn’t make sense to run this function without specifying the p-value, but we can add a second argument called digits that defaults to 3, so we can round p-values to 3 digits. report_p &lt;- function(p, digits = 3) { } Now we need to write some code inside the function to process the input arguments and turn them into a returned output. Put the output as the last item in function. report_p &lt;- function(p, digits = 3) { if (p &lt; .001) { reported = &quot;p &lt; .001&quot; } else { roundp &lt;- round(p, digits) reported = paste(&quot;p =&quot;, roundp) } reported } You might also see the returned output inside of the return() function. This does the same thing. report_p &lt;- function(p, digits = 3) { if (p &lt; .001) { reported = &quot;p &lt; .001&quot; } else { roundp &lt;- round(p, digits) reported = paste(&quot;p =&quot;, roundp) } return(reported) } When you run the code defining your function, it doesn’t output anything, but makes a new object in the Environment tab under “Functions”. Now you can run the function. report_p(0.04869) ## [1] &quot;p = 0.049&quot; report_p(0.0000023) ## [1] &quot;p &lt; .001&quot; 13.5.2.4 Scope What happens in a function stays in a function. You can change the value of a variable passed to a function, but that won’t change the value of the variable outside of the function, even if that variable has the same name as the one in the function. half &lt;- function(x) { x &lt;- x/2 return(x) } x &lt;- 10 list( &quot;half(x)&quot; = half(x), &quot;x&quot; = x ) ## $`half(x)` ## [1] 5 ## ## $x ## [1] 10 13.5.2.5 Warnings and errors What happens when you omit the argument for p? Or if you set p to 1.5 or “a”? You might want to add a more specific warning and stop running the function code if someone enters a value that isn’t a number. You can do this with the stop() function. If someone enters a number that isn’t possible for a p-value (0-1), you might want to warn them that this is probably not what they intended, but still continue with the function. You can do this with warning(). report_p &lt;- function(p, digits = 3) { if (!is.numeric(p)) stop(&quot;p must be a number&quot;) if (p &lt;= 0) warning(&quot;p-values are normally greater than 0&quot;) if (p &gt;= 1) warning(&quot;p-values are normally less than 1&quot;) if (p &lt; .001) { reported = &quot;p &lt; .001&quot; } else { roundp &lt;- round(p, digits) reported = paste(&quot;p =&quot;, roundp) } reported } report_p() ## Error in report_p(): argument &quot;p&quot; is missing, with no default report_p(&quot;a&quot;) ## Error in report_p(&quot;a&quot;): p must be a number report_p(-2) ## Warning in report_p(-2): p-values are normally greater than 0 ## [1] &quot;p &lt; .001&quot; report_p(2) ## Warning in report_p(2): p-values are normally less than 1 ## [1] &quot;p = 2&quot; 13.5.3 Iterating your own functions First, let’s build up the code that we want to iterate. 13.5.3.1 rnorm() Create a vector of 20 random numbers drawn from a normal distribution with a mean of 5 and standard deviation of 1 using the rnorm() function and store them in the variable A. A &lt;- rnorm(20, mean = 5, sd = 1) 13.5.3.2 tibble::tibble() A tibble is a type of table or data.frame. The function tibble::tibble() creates a tibble with a column for each argument. Each argument takes the form column_name = data_vector. Create a table called dat including two vectors: A that is a vector of 20 random normally distributed numbers with a mean of 5 and SD of 1, and B that is a vector of 20 random normally distributed numbers with a mean of 5.5 and SD of 1. dat &lt;- tibble( A = rnorm(20, 5, 1), B = rnorm(20, 5.5, 1) ) 13.5.3.3 t.test You can run a Welch two-sample t-test by including the two samples you made as the first two arguments to the function t.test. You can reference one column of a table by its names using the format table_name$column_name t.test(dat$A, dat$B) ## ## Welch Two Sample t-test ## ## data: dat$A and dat$B ## t = -2.0448, df = 37.784, p-value = 0.04789 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.308466638 -0.006424632 ## sample estimates: ## mean of x mean of y ## 5.261487 5.918932 You can also convert the table to long format using the gather function and specify the t-test using the format number_column~grouping_column. longdat &lt;- gather(dat, group, score, A:B) t.test(score~group, data = longdat) ## ## Welch Two Sample t-test ## ## data: score by group ## t = -2.0448, df = 37.784, p-value = 0.04789 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.308466638 -0.006424632 ## sample estimates: ## mean in group A mean in group B ## 5.261487 5.918932 13.5.3.4 broom::tidy() You can use the function broom::tidy() to extract the data from a statistical test in a table format. The example below pipes everything together. tibble( A = rnorm(20, 5, 1), B = rnorm(20, 5.5, 1) ) %&gt;% gather(group, score, A:B) %&gt;% t.test(score~group, data = .) %&gt;% broom::tidy() ## # A tibble: 1 x 10 ## estimate estimate1 estimate2 statistic p.value parameter conf.low ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.603 5.00 5.60 -1.83 0.0750 36.9 -1.27 ## # ... with 3 more variables: conf.high &lt;dbl&gt;, method &lt;chr&gt;, ## # alternative &lt;chr&gt; Finally, we can extract a single value from this results table using pull(). tibble( A = rnorm(20, 5, 1), B = rnorm(20, 5.5, 1) ) %&gt;% gather(group, score, A:B) %&gt;% t.test(score~group, data = .) %&gt;% broom::tidy() %&gt;% pull(p.value) ## [1] 0.9353767 13.5.3.5 Turn into a function First, name your function t_sim and wrap the code above in a function with no arguments. t_sim &lt;- function() { tibble( A = rnorm(20, 5, 1), B = rnorm(20, 5.5, 1) ) %&gt;% gather(group, score, A:B) %&gt;% t.test(score~group, data = .) %&gt;% broom::tidy() %&gt;% pull(p.value) } Run it a few times to see what happens. t_sim() ## [1] 0.219669 13.5.3.6 replicate() You can use the replicate function to run your function any number of times. Let’s run the t_sim function 1000 times, assign the resulting p-values to a vector called reps, and check what proportion of p-values are lower than alpha (e.g., .05). This number is the power for this analysis. reps &lt;- replicate(1000, t_sim()) alpha &lt;- .05 power &lt;- mean(reps &lt; alpha) power ## [1] 0.356 13.5.3.7 Add arguments You can just edit your function each time you want to cacluate power for a different sample n, but it is more efficent to build this into your fuction as an arguments. Redefine t_sim, setting arguments for the mean and SD of group A, the mean and SD of group B, and the number of subjects per group. Give them all default values. t_sim &lt;- function(n = 10, m1=0, sd1=1, m2=0, sd2=1) { tibble( A = rnorm(n, m1, sd1), B = rnorm(n, m2, sd2) ) %&gt;% gather(group, score, A:B) %&gt;% t.test(score~group, data = .) %&gt;% broom::tidy() %&gt;% pull(p.value) } Test your function with some different values to see if the results make sense. t_sim(100) ## [1] 0.4012639 t_sim(100, 0, 1, 0.5, 1) ## [1] 3.092877e-06 Use replicate to calculate power for 100 subjects/group with an effect size of 0.2 (e.g., A: m = 0, SD = 1; B: m = 0.2, SD = 1). Use 1000 replications. reps &lt;- replicate(1000, t_sim(100, 0, 1, 0.2, 1)) power &lt;- mean(reps &lt; .05) power ## [1] 0.302 Compare this to power calculated from the power.t.test function. power.t.test(n = 100, delta = 0.2, sd = 1, type=&quot;two.sample&quot;) ## ## Two-sample t test power calculation ## ## n = 100 ## delta = 0.2 ## sd = 1 ## sig.level = 0.05 ## power = 0.2902664 ## alternative = two.sided ## ## NOTE: n is number in *each* group Calculate power via simulation and power.t.test for the following tests: 20 subjects/group, A: m = 0, SD = 1; B: m = 0.2, SD = 1 40 subjects/group, A: m = 0, SD = 1; B: m = 0.2, SD = 1 20 subjects/group, A: m = 10, SD = 1; B: m = 12, SD = 1.5 "],
["sim.html", "Chapter 14 Probability &amp; Simulation 14.1 Learning Objectives 14.2 Prep 14.3 Resources 14.4 Formative exercises 14.5 Class Notes 14.6 Example", " Chapter 14 Probability &amp; Simulation 14.1 Learning Objectives 14.1.1 Basic Understand what types of data are best modeled by different distributions uniform binomial normal poisson Generate and plot data randomly sampled from the above distributions Test sampled distributions against a null hypothesis exact binomial test t-test (1-sample, independent samples, paired samples) correlation (pearson, kendall and spearman) Define the following statistical terms: p-value alpha power false positive (type I error) false negative (type II error) confidence interval 14.1.2 Intermediate Create a function to generate a sample with specific properties and run an inferential test Calculate power using replicate and a sampling function Calculate the minimum sample size for a specific power level and design 14.1.3 Advanced Generate 3+ variables from a multivariate normal distribution and plot them 14.2 Prep Chapter 21: Iteration of R for Data Science 14.3 Resources Improving your statistical inferences on Coursera (week 1) 14.4 Formative exercises Download the formative exercises. See the answers only after you’ve attempted all the questions. 14.5 Class Notes Simulating data is a very powerful way to test your understanding of statistical concepts. We are going to use simulations to learn the basics of probability. # libraries needed for these examples library(tidyverse) library(MASS) 14.5.1 Uniform Distribution The uniform distribution is the simplest distribution. All numbers in the range have an equal probability of being sampled. 14.5.1.1 Sample continuous distribution runif(n, min=0, max=1) Use runif() to sample from a continuous uniform distribution. runif(10, min = 0, max = 1) ## [1] 0.4385462 0.6849549 0.5008744 0.9106998 0.5040163 0.1870981 0.9105662 ## [8] 0.2693800 0.2505661 0.3942486 14.5.1.2 Sample discrete distribution sample(x, size, replace = FALSE, prob = NULL) Use sample() to sample from a discrete distribution. Simulate a single roll of a 6-sided die. sample(6, 1) ## [1] 3 Simulate 10 rolls of a 6-sided die. Set replace to TRUE so each roll is independent. See what happens if you set replace to FALSE. sample(6, 10, replace = TRUE) ## [1] 6 1 5 6 4 1 6 3 1 6 You can also use sample to sample from a list of named outcomes. pet_types &lt;- c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;, &quot;bird&quot;, &quot;fish&quot;) sample(pet_types, 10, replace = TRUE) ## [1] &quot;fish&quot; &quot;ferret&quot; &quot;fish&quot; &quot;bird&quot; &quot;bird&quot; &quot;ferret&quot; &quot;ferret&quot; ## [8] &quot;bird&quot; &quot;fish&quot; &quot;cat&quot; Ferrets are a much less common pet than cats and dogs, so our sample isn’t very realistic. You can set the probabilities of each item in the list with the prob argument. pet_types &lt;- c(&quot;cat&quot;, &quot;dog&quot;, &quot;ferret&quot;, &quot;bird&quot;, &quot;fish&quot;) pet_prob &lt;- c(0.3, 0.4, 0.1, 0.1, 0.1) sample(pet_types, 10, replace = TRUE, prob = pet_prob) ## [1] &quot;cat&quot; &quot;dog&quot; &quot;cat&quot; &quot;dog&quot; &quot;bird&quot; &quot;dog&quot; &quot;dog&quot; &quot;dog&quot; &quot;dog&quot; &quot;dog&quot; 14.5.2 Binomial Distribution The binomial distribution is useful for modeling binary data, where each observation can have one of two outcomes, like success/failure, yes/no or head/tails. 14.5.2.1 Sample distribution rbinom(n, size, prob) The rbinom function will generate a random binomial distribution. n = number of observations size = number of trials prob = probability of success on each trial Coin flips are a typical example of a binomial distribution, where we can assign head to 1 and tails to 0. 20 individual coin flips of a fair coin rbinom(20, 1, 0.5) ## [1] 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 20 individual coin flips of a baised (0.75) coin rbinom(20, 1, 0.75) ## [1] 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 You can generate the total number of heads in 1 set of 20 coin flips by setting size to 20 and n to 1. rbinom(1, 20, 0.75) ## [1] 14 You can generate more sets of 20 coin flips by increasing the n. rbinom(10, 20, 0.5) ## [1] 12 17 11 10 13 10 11 10 6 8 You should always check your randomly generated data to check that it makes sense. For large samples, it’s easiest to do that graphically. A histogram is usually the best choice for plotting binomial data. flips &lt;- rbinom(1000, 20, 0.5) ggplot() + geom_histogram( aes(flips), binwidth = 1, fill = &quot;white&quot;, color = &quot;black&quot; ) Run the simulation above several times, noting how the histogram changes. Try changing the values of n, size, and prob. 14.5.2.2 Exact binomial test binom.test(x, n, p) You can test a binomial distribution against a specific probability using the exact binomial test. x = the number of successes n = the number of trials p = hypothesised probability of success Here we can test a series of 10 coin flips from a fair coin and a biased coin against the hypothesised probability of 0.5 (even odds). n &lt;- 10 fair_coin &lt;- rbinom(1, n, 0.5) biased_coin &lt;- rbinom(1, n, 0.6) binom.test(fair_coin, n, p = 0.5) ## ## Exact binomial test ## ## data: fair_coin and n ## number of successes = 6, number of trials = 10, p-value = 0.7539 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.2623781 0.8784477 ## sample estimates: ## probability of success ## 0.6 binom.test(biased_coin, n, p = 0.5) ## ## Exact binomial test ## ## data: biased_coin and n ## number of successes = 7, number of trials = 10, p-value = 0.3438 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.3475471 0.9332605 ## sample estimates: ## probability of success ## 0.7 Run the code above several times, noting the p-values for the fair and biased coins. Alternatively, you can simulate coin flips online and build up a graph of results and p-values. How does the p-value vary for the fair and biased coins? What happens to the confidence intervals if you increase n from 10 to 100? What criterion would you use to tell if the observed data indicate the coin is fair or biased? How often do you conclude the fair coin is biased (false positives)? How often do you conclude the biased coin is fair (false negatives)? 14.5.2.3 False positives &amp; negatives The probability that a test concludes the fair coin is biased is called the false positive rate (or Type I Error Rate). The alpha is the false positive rate we accept for a test. This is traditionally set at 0.05, but there are good arguments for setting a different criterion in some circumstances. The probability that a test concludes the biased coin is fair is called the false negative rate (of Type II Error Rate). The power of a test is 1 minus its false negative rate (i.e., the true positive rate). Power depends on how biased the coin is and how many samples we take. 14.5.2.4 Sampling function To estimate these rates, we need to repeat the sampling above many times. A function is ideal for repeating the exact same procedure over and over. Set the arguments of the function to variables that you might want to change. Here, we will want to estimate power for: different sample sizes (n) different coin biases (bias) different hypothesised probabilities (p, defaults to 0.5) sim_binom_test &lt;- function(n, bias, p = 0.5) { coin &lt;- rbinom(1, n, bias) btest &lt;- binom.test(coin, n, p) btest$p.value } Once you’ve created your function, test it a few times, changing the values. sim_binom_test(100, 0.6) ## [1] 0.1933479 14.5.2.5 Calculate power Then you can use the replicate() function to run it many times and save all the output values. You can calculate the power of your analysis by checking the proportion of your simulated analyses that have a p-value less than your alpha (the probability of rejecting the null hypothesis when the null hypothesis is true). my_reps &lt;- replicate(1e4, sim_binom_test(100, 0.6)) mean(my_reps &lt; 0.05) ## [1] 0.4628 1e4 is just scientific notation for a 1 followed by 4 zeros (10000). When youre running simulations, you usually want to run a lot of them and it’s a pain to keep track of whether you’ve typed 5 or 6 zeros (100000 vs 1000000) and this will change your running time by an order of magnitude. 14.5.3 Normal Distribution 14.5.3.1 Sample distribution rnorm(n, mean, sd) We can simulate a normal distribution of size n if we know the mean and standard deviation (sd). A density plot is usually the best way to visualise this type of data if your n is large. dv &lt;- rnorm(1e5, 10, 2) ggplot() + geom_density(aes(dv), fill = &quot;white&quot;) + geom_vline(xintercept = mean(dv), color = &quot;red&quot;) + geom_vline(xintercept = quantile(dv, .5 - (.6827/2)), color = &quot;darkgreen&quot;) + geom_vline(xintercept = quantile(dv, .5 + (.6827/2)), color = &quot;darkgreen&quot;) + geom_vline(xintercept = quantile(dv, .5 - (.9545/2)), color = &quot;blue&quot;) + geom_vline(xintercept = quantile(dv, .5 + (.9545/2)), color = &quot;blue&quot;) + geom_vline(xintercept = quantile(dv, .5 - (.9973/2)), color = &quot;purple&quot;) + geom_vline(xintercept = quantile(dv, .5 + (.9973/2)), color = &quot;purple&quot;) + scale_x_continuous( limits = c(0,20), breaks = seq(0,20) ) Run the simulation above several times, noting how the density plot changes. What do the vertical lines represent? Try changing the values of n, mean, and sd. 14.5.3.2 T-test t.test(x, y, alternative, mu, paired) Use a t-test to compare the mean of one distribution to a null hypothesis (one-sample t-test), compare the means of two samples (independent-samples t-test), or compare pairs of values (paired-samples t-test). You can run a one-sample t-test comparing the mean of your data to mu. Here is a simulated distribution with a mean of 0.5 and an SD of 1, creating an effect size of 0.5 SD when tested against a mu of 0. Run the simulation a few times to see how often the t-test returns a significant p-value (or run it in the shiny app). sim_norm &lt;- rnorm(100, 0.5, 1) t.test(sim_norm, mu = 0) ## ## One Sample t-test ## ## data: sim_norm ## t = 4.6516, df = 99, p-value = 1.021e-05 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 0.2835165 0.7053189 ## sample estimates: ## mean of x ## 0.4944177 Run an independent-samples t-test by comparing two lists of values. a &lt;- rnorm(100, 0.5, 1) b &lt;- rnorm(100, 0.7, 1) t_ind &lt;- t.test(a, b, paired = FALSE) t_ind ## ## Welch Two Sample t-test ## ## data: a and b ## t = -0.026993, df = 197.98, p-value = 0.9785 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.2991671 0.2910878 ## sample estimates: ## mean of x mean of y ## 0.7097529 0.7137925 The paired argument defaults to FALSE, but it’s good practice to always explicitly set it so you are never confused about what type of test you are performing. 14.5.3.3 Sampling function We can use the names() function to find out the names of all the t.test parameters and use this to just get one type of data, like the test statistic (e.g., t-value). names(t_ind) ## [1] &quot;statistic&quot; &quot;parameter&quot; &quot;p.value&quot; &quot;conf.int&quot; &quot;estimate&quot; ## [6] &quot;null.value&quot; &quot;alternative&quot; &quot;method&quot; &quot;data.name&quot; t_ind$statistic ## t ## -0.02699261 Alternatively, use broom::tidy() to convert the output into a tidy table. broom::tidy(t_ind) ## # A tibble: 1 x 10 ## estimate estimate1 estimate2 statistic p.value parameter conf.low ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.00404 0.710 0.714 -0.0270 0.978 198. -0.299 ## # ... with 3 more variables: conf.high &lt;dbl&gt;, method &lt;chr&gt;, ## # alternative &lt;chr&gt; If you want to run the simulation many times and record information each time, first you need to turn your simulation into a function. sim_t_ind &lt;- function(n, m1, sd1, m2, sd2) { v1 &lt;- rnorm(n, m1, sd1) v2 &lt;- rnorm(n, m2, sd2) t_ind &lt;- t.test(v1, v2, paired = FALSE) return(t_ind$p.value) } Run it a few times to check that it gives you sensible values. sim_t_ind(100, 0.7, 1, 0.5, 1) ## [1] 0.8309888 Now replicate the simulation 1000 times. my_reps &lt;- replicate(1e4, sim_t_ind(100, 0.7, 1, 0.5, 1)) alpha &lt;- 0.05 power &lt;- mean(my_reps &lt; alpha) power ## [1] 0.2924 Run the code above several times. How much does the power value fluctuate? How many replications do you need to run to get a reliable estimate of power? Compare your power estimate from simluation to a power calculation using power.t.test(). Here, delta is the difference between m1 and m2 above. power.t.test(n = 100, delta = 0.2, sd = 1, sig.level = alpha, type = &quot;two.sample&quot;) ## ## Two-sample t test power calculation ## ## n = 100 ## delta = 0.2 ## sd = 1 ## sig.level = 0.05 ## power = 0.2902664 ## alternative = two.sided ## ## NOTE: n is number in *each* group You can plot the distribution of p-values. ggplot() + geom_histogram( aes(my_reps), binwidth = 0.05, boundary = 0, fill = &quot;white&quot;, color = &quot;black&quot; ) What do you think the distribution of p-values is when there is no effect (i.e., the means are identical)? Check this yourself. Make sure the boundary argument is set to 0 for p-value histograms. See what happens with a null effect if boundary is not set. 14.5.3.4 Bivariate Normal 14.5.3.4.1 Correlation You can test if two continuous variables are related to each other using the cor() function. Below is a quick and dirty way to generate two correlated variables. x is drawn from a normal distribution, while y is the sum of x and another value drawn from a random normal distribution. We’ll learn later how to generate specific correlations in simulated data. n &lt;- 100 # number of random samples x &lt;- rnorm(n, 0, 1) y &lt;- x + rnorm(n, 0, 1) cor(x, y) ## [1] 0.7542513 cor() defaults to Pearson’s correlations. Set the method argument to use Kendall or Spearman correlations. cor(x, y, method = &quot;spearman&quot;) ## [1] 0.7541674 14.5.3.4.2 Sample distribution What if we want to sample from a population with specific relationships between variables? We can sample from a bivariate normal distribution using the MASS package, n &lt;- 1000 # number of random samples rho &lt;- 0.5 # population correlation between the two variables mu &lt;- c(10, 20) # the means of the samples stdevs &lt;- c(5, 6) # the SDs of the samples # correlation matrix cor_mat &lt;- matrix(c( 1, rho, rho, 1), 2) # create the covariance matrix sigma &lt;- (stdevs %*% t(stdevs)) * cor_mat # sample from bivariate normal distribution bvn &lt;- mvrnorm(n, mu, sigma) cor(bvn) # check correlation matrix ## [,1] [,2] ## [1,] 1.0000000 0.5311651 ## [2,] 0.5311651 1.0000000 Plot your sampled variables to check everything worked like you expect. You need to convert the output of mvnorm into a tibble in order to use it in ggplot. bvn %&gt;% as_tibble() %&gt;% ggplot(aes(V1, V2)) + geom_point(alpha = 0.5) + geom_smooth(method = &quot;lm&quot;) + geom_density2d() 14.5.4 Multivariate Normal 14.5.4.0.1 Sample distribution n &lt;- 200 # number of random samples rho1_2 &lt;- 0.5 # correlation betwen v1 and v2 rho1_3 &lt;- 0 # correlation betwen v1 and v3 rho2_3 &lt;- 0.7 # correlation betwen v2 and v3 mu &lt;- c(10, 20, 30) # the means of the samples stdevs &lt;- c(8, 9, 10) # the SDs of the samples # correlation matrix cor_mat &lt;- matrix(c( 1, rho1_2, rho1_3, rho1_2, 1, rho2_3, rho1_3, rho2_3, 1), 3) sigma &lt;- (stdevs %*% t(stdevs)) * cor_mat bvn3 &lt;- mvrnorm(n, mu, sigma) cor(bvn3) # check correlation matrix ## [,1] [,2] [,3] ## [1,] 1.0000000 0.4184293 0.0168486 ## [2,] 0.4184293 1.0000000 0.7413358 ## [3,] 0.0168486 0.7413358 1.0000000 14.5.4.0.2 3D Plots You can use the plotly library to make a 3D graph. library(plotly) ## ## Attaching package: &#39;plotly&#39; ## The following object is masked from &#39;package:MASS&#39;: ## ## select ## The following object is masked from &#39;package:ggplot2&#39;: ## ## last_plot ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## The following object is masked from &#39;package:graphics&#39;: ## ## layout marker_style = list( color = &quot;#ff0000&quot;, line = list( color = &quot;#444&quot;, width = 1 ), opacity = 0.5, size = 5 ) bvn3 %&gt;% as_tibble() %&gt;% plot_ly(x = ~V1, y = ~V2, z = ~V3, marker = marker_style) %&gt;% add_markers() 14.6 Example This example uses the Growth Chart Data Tables from the US CDC. 14.6.1 Load &amp; wrangle We have to do a little data wrangling first. Have a look at the data after you import it and relabel Sex to male and female instead of 1 and 2. Also convert Agemos (age in months) to years. Relabel the column 0 as mean and calculate a new column named sd as the difference between columns 1 and 0. height_age &lt;- read_csv(&quot;https://www.cdc.gov/growthcharts/data/zscore/zstatage.csv&quot;) %&gt;% filter(Sex %in% c(1,2)) %&gt;% mutate( sex = recode(Sex, &quot;1&quot; = &quot;male&quot;, &quot;2&quot; = &quot;female&quot;), age = as.numeric(Agemos)/12, sd = `1` - `0` ) %&gt;% dplyr::select(sex, age, mean = `0`, sd) ## Parsed with column specification: ## cols( ## Sex = col_character(), ## Agemos = col_character(), ## `-2` = col_double(), ## `-1.5` = col_double(), ## `-1` = col_double(), ## `-0.5` = col_double(), ## `0` = col_double(), ## `0.5` = col_double(), ## `1` = col_double(), ## `1.5` = col_double(), ## `2` = col_double() ## ) If you run the code above without putting dplyr:: before the select() function, you will get an error message. This is because the MASS package also has a function called select() and, since we loaded MASS after tidyverse, the MASS function is the default. When you loaded MASS, you should have seen a warning like “The following object is masked from ‘package:dplyr’: select”. You can use functions with the same name from different packages by specifying the package before the function name, separated by two colons. 14.6.2 Plot Plot your new data frame to see how mean height changes with age for boys and girls. ggplot(height_age, aes(age, mean, color = sex)) + geom_smooth(aes(ymin = mean - sd, ymax = mean + sd), stat=&quot;identity&quot;) 14.6.3 Get means and SDs Create new variables for the means and SDs for 20-year-old men and women. height_sub &lt;- height_age %&gt;% filter(age == 20) m_mean &lt;- height_sub %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(mean) m_sd &lt;- height_sub %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(sd) f_mean &lt;- height_sub %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(mean) f_sd &lt;- height_sub %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(sd) height_sub ## # A tibble: 2 x 4 ## sex age mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 male 20 177. 7.12 ## 2 female 20 163. 6.46 14.6.4 Simulate a population Simulate 50 random male heights and 50 radom female heights using the rnorm() function and the means and SDs above. Plot the data. sim_height &lt;- tibble( male = rnorm(50, m_mean, m_sd), female = rnorm(50, f_mean, f_sd) ) %&gt;% gather(&quot;sex&quot;, &quot;height&quot;, male:female) ggplot(sim_height) + geom_density(aes(height, fill = sex), alpha = 0.5) + xlim(125, 225) Run the simulation above several times, noting how the density plot changes. Try changing the age you’re simulating. 14.6.5 Analyse simulated data Use the sim_t_ind(n, m1, sd1, m2, sd2) function we created above to generate one simulation with a sample size of 50 in each group using the means and SDs of male and female 14-year-olds. height_sub &lt;- height_age %&gt;% filter(age == 14) m_mean &lt;- height_sub %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(mean) m_sd &lt;- height_sub %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(sd) f_mean &lt;- height_sub %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(mean) f_sd &lt;- height_sub %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(sd) sim_t_ind(50, m_mean, m_sd, f_mean, f_sd) ## [1] 0.00789244 14.6.6 Replicate simulation Now replicate this 1e4 times using the replicate() function. This function will save the returned p-values in a list (my_reps). We can then check what proportion of those p-values are less than our alpha value. This is the power of our test. my_reps &lt;- replicate(1e4, sim_t_ind(50, m_mean, m_sd, f_mean, f_sd)) alpha &lt;- 0.05 power &lt;- mean(my_reps &lt; alpha) power ## [1] 0.6507 14.6.7 One-tailed prediction This design has about 65% power to detect the sex difference in height (with a 2-tailed test). Modify the sim_t_ind function for a 1-tailed prediction. You could just set alternative equal to “greater” in the function, but it might be better to add the alternative argument to your function (giving it the same default value as t.test) and change the value of alternative in the function to alternative. sim_t_ind &lt;- function(n, m1, sd1, m2, sd2, alternative = &quot;two.sided&quot;) { v1 &lt;- rnorm(n, m1, sd1) v2 &lt;- rnorm(n, m2, sd2) t_ind &lt;- t.test(v1, v2, paired = FALSE, alternative = alternative) return(t_ind$p.value) } my_reps &lt;- replicate(1e4, sim_t_ind(50, m_mean, m_sd, f_mean, f_sd, &quot;greater&quot;)) mean(my_reps &lt; alpha) ## [1] 0.7606 14.6.8 Range of sample sizes What if we want to find out what sample size will give us 80% power? We can try trial and error. We know the number should be slightly larger than 50. But you can search more systematically by repeating your power calculation for a range of sample sizes. This might seem like overkill for a t-test, where you can easily look up sample size calculators online, but it is a valuable skill to learn for when your analyses become more complicated. Start with a relatively low number of replications and/or more spread-out samples to estimate where you should be looking more specifically. Then you can repeat with a narrower/denser range of sample sizes and more iterations. alpha &lt;- 0.05 power_table &lt;- tibble( n = seq(20, 100, by = 5) ) %&gt;% mutate(power = map_dbl(n, function(n) { ps &lt;- replicate(1e3, sim_t_ind(n, m_mean, m_sd, f_mean, f_sd, &quot;greater&quot;)) mean(ps &lt; alpha) })) ggplot(power_table, aes(n, power)) + geom_smooth() + geom_point() + geom_hline(yintercept = 0.8) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Now we can narrow down our search to values around 55 (plus or minus 5) and increase the number of replications from 1e3 to 1e4. power_table &lt;- tibble( n = seq(50, 60) ) %&gt;% mutate(power = map_dbl(n, function(n) { ps &lt;- replicate(1e3, sim_t_ind(n, m_mean, m_sd, f_mean, f_sd, &quot;greater&quot;)) mean(ps &lt; alpha) })) ##ggplot(power_table, aes(n, power)) + ## geom_smooth() + ## geom_point() + ## geom_hline(yintercept = 0.8) + ## scale_x_continuous(breaks = sample_size) "],
["glm.html", "Chapter 15 Introduction to GLM 15.1 Learning Objectives 15.2 Resources 15.3 Class Notes 15.4 Additional Take-Home Formative Exercises 15.5 In-Class Exercises", " Chapter 15 Introduction to GLM 15.1 Learning Objectives 15.1.1 Basic Prove to yourself the correspondence between two-sample t-test, one-way ANOVA, and linear regression with dummy coding Given data and a GLM, generate a decomposition matrix and calculate sums of squares, mean squares, and F ratios 15.2 Resources Jeff Miller and Patricia Haden, Statistical Analysis with the Linear Model (free online textbook.) 15.3 Class Notes lecture slides introducing the General Linear Model GLM shiny app F distribution 15.4 Additional Take-Home Formative Exercises Download the formative exercises. See the answers only after you’ve attempted all the questions. 15.5 In-Class Exercises In the code block below, you are given the two_sample() function which you will use to generate random datasets. # libraries needed for these examples library(tidyverse) ## ── Attaching packages ──────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.8 ## ✔ tidyr 0.8.2 ✔ stringr 1.3.1 ## ✔ readr 1.3.0 ✔ forcats 0.3.0 ## ── Conflicts ─────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() two_sample &lt;- function(diff = 0.5, n_per_group = 20) { tibble(Y = c(rnorm(n_per_group, -.5 * diff, sd = 1), rnorm(n_per_group, .5 * diff, sd = 1)), grp = factor(rep(c(&quot;a&quot;, &quot;b&quot;), each = n_per_group)), grp_d = rep(c(0, 1), each = n_per_group)) } 15.5.1 Relationship between t-test, ANOVA, and linear regression Generate a single random dataset using two_sample(). Then run (1) a t-test (with var.equal = TRUE); (2) an ANOVA (using aov()); and (3) linear regression (using lm()) on the data. Compare and contrast the results. 15.5.2 Understanding decomposition matrices Now use two_sample() to create a dataset dat with N=5 per group. Then use the estimation equations for a one-factor ANOVA to calculate the model components mu_hat (\\(\\hat{\\mu}\\)), and a_hat (\\(\\hat{A_i}\\)). ’mu_hat&quot; should be a single value and a_hat should be a table with two rows and columns grp and a (the estimated effect for that group). Hint mu_hat &lt;- dat %&gt;% summarise(????) %&gt;% pull(????) a_hat &lt;- dat %&gt;% group_by(???) %&gt;% summarise(????) Calculate residuals (err or \\(\\widehat{S(A)_{ij}}\\)) and generate a decomposition matrix of Y in dat, such as seen slides 10-12 from the lecture. (Despite being called a matrix, your decomposition matrix should be a tibble not a matrix, and you don’t need to include the last line with SS yet.) Hint It might be easier to calculate the residuals after you get everything else in the table. Another Hint Use select() on dat to get Y and grp, and inner_join() to add in the \\(A_i\\)s. Yet Another Hint decomp &lt;- dat %&gt;% select(Y, grp) %&gt;% mutate(mu = mu_hat) %&gt;% inner_join(a_hat, &quot;grp&quot;) # %&gt;% ...etc Calculate sums of squares for Y, a, and err. The resulting table should be called all_ss with columns SS_Y, SS_a, and SS_err respectively. Hint Use the summarise() function. You can declare more than one summary values as separate arguments to the function. Divide each sum of squares by its corresponding df to calculate mean squares. The calculate an F-ratio, and get the p-value using the pf() function. Hint Use lower.tail = FALSE with pf(). See ?pf Now run a one-way ANOVA on your results and compare it to what you obtained in your calculations. "],
["repro.html", "Chapter 16 Reproducible Workflows 16.1 Learning Objectives 16.2 Prep 16.3 Resources 16.4 Class Notes 16.5 References", " Chapter 16 Reproducible Workflows 16.1 Learning Objectives 16.1.1 Basic Create a reproducible script in R Markdown Edit the YAML header to add table of contents and other options Include a table Include a figure Use source() to include code form an external file Report the output of an analysis using inline R 16.1.2 Intermediate Output doc and PDF formats Add a bibliography and in-line citations Format tables using kableExtra 16.1.3 Advanced Create a computationally reproducible project in Code Ocean 16.2 Prep Chapter 27: R Markdown in R for Data Science 16.3 Resources R Markdown Cheat Sheet R Markdown reference Guide R Markdown Tutorial R Markdown: The Definitive Guide by Yihui Xie, J. J. Allaire, &amp; Garrett Grolemund Papaja Reproducible APA Manuscripts Code Ocean for Computational Reproducibility 16.4 Class Notes 16.4.1 R Markdown By now you should be pretty comfortable working with R Markdown files from the weekly formative exercises and set exercises. Here, we’ll explore some of the more advanced options and create an R Markdown document that produces a reproducible manuscript. First, make a new R Markdown document. 16.4.2 knitr options When you create a new R Markdown file in RStudio, a setup chunk is automatically created. &#96;&#96;&#96;{r setup, include=FALSE} knitr::opts_chunk$set(echo = TRUE) &#96;&#96;&#96; You can set more default options for code chunks here. See the knitr options documentation for explanations of the possible options. &#96;&#96;&#96;{r setup, include=FALSE} knitr::opts_chunk$set( fig.width = 8, fig.height = 5, fig.path = 'images/', echo = FALSE, warning = TRUE, message = FALSE, cache = FALSE ) &#96;&#96;&#96; The code above sets the following options: fig.width = 8 : figure width is 8 inches fig.height = 5 : figure height is 5 inches fig.path = 'images/' : figures are saved in the directory “images” echo = FALSE : do not show code chunks in the rendered document warning = FALSE : do not show any function warnings message = FALSE : do not show any function messages cache = FALSE : run all the code to create all of the images and objects each time you knit (set to TRUE if you have time-consuming code) 16.4.3 YAML Header The YAML header is where you can set several options. --- title: &quot;My Demo Document&quot; author: &quot;Me&quot; output: html_document: theme: spacelab highlight: tango toc: true toc_float: collapsed: false smooth_scroll: false toc_depth: 3 number_sections: false --- The built-in themes are: “cerulean”, “cosmo”, “flatly”, “journal”, “lumen”, “paper”, “readable”, “sandstone”, “simplex”, “spacelab”, “united”, and “yeti”. You can view and download more themes. Try changing the values from false to true to see what the options do. 16.4.4 TOC and Document Headers If you include a table of contents (toc), it is created from your document headers. Headers in markdown are created by prefacing the header title with one or more hashes (#). Add a typical paper structure to your document like the one below. ## Abstract My abstract here... ## Introduction What&#39;s the question; why is it interesting? ## Methods ### Participants How many participants and why? Do your power calculation here. ### Procedure What will they do? ### Analysis Describe the analysis plan... ## Results Demo results for simulated data... ## Discussion What does it all mean? ## References 16.4.5 Code Chunks You can include code chunks that create and display images, tables, or computations to include in your text. Let’s start by simulating some data. First, create a code chunk in your document. You can put this before the abstract, since we won’t be showing the code in this document. We’ll use a modified version of the two_sample function from the GLM lecture to create two groups with a difference of 0.75 and 100 observations per group. This function was modified to add sex and effect-code both sex and group. Using the recode function to set effect or difference coding makes it clearer which value corresponds to which level. There is no effect of sex or interaction with group in these simulated data. two_sample &lt;- function(diff = 0.5, n_per_group = 20) { tibble(Y = c(rnorm(n_per_group, -.5 * diff, sd = 1), rnorm(n_per_group, .5 * diff, sd = 1)), grp = factor(rep(c(&quot;a&quot;, &quot;b&quot;), each = n_per_group)), sex = factor(rep(c(&quot;female&quot;, &quot;male&quot;), times = n_per_group)) ) %&gt;% mutate( grp_e = recode(grp, &quot;a&quot; = -0.5, &quot;b&quot; = 0.5), sex_e = recode(sex, &quot;female&quot; = -0.5, &quot;male&quot; = 0.5) ) } This function requires the tibble and dplyr packages, so remember to load the whole tidyverse package at the top of this script (e.g., in the setup chunk). Now we can make a separate code chunk to create our simulated dataset dat. set.seed(90210) dat &lt;- two_sample(diff = 0.75, n_per_group = 100) You can use the set.seed function to make sure that you get the same random data back each time. Make sure you don’t ever do this inside of a simulation function, or you will just simulate the exact same data over and over again. 16.4.5.1 Tables Next, create a code chunk where you want to display a table of the descriptives (e.g., Participants section of the Methods). We’ll use tidyverse functions you learned in the data wrangling lectures to create summary statistics for each group. &#96;&#96;&#96;{r, results='asis'} dat %>% group_by(grp, sex) %>% summarise(n = n(), Mean = mean(Y), SD = sd(Y)) %>% rename(group = grp) %>% mutate_if(is.numeric, round, 3) %>% knitr::kable() &#96;&#96;&#96; group sex n Mean SD a female 50 -0.268 1.059 a male 50 -0.563 1.163 b female 50 0.305 1.031 b male 50 0.324 1.049 Notice that the r chunk specifies the option results='asis'. This lets you format the table using the kable() function from knitr. You can also use more specialised functions from papaja or kableExtra to format your tables. 16.4.5.2 Images Next, create a code chunk where you want to display the image in your document. Let’s put it in the Results section. Use what you learned in the data visualisation lecture to show violin-boxplots for the two groups. &#96;&#96;&#96;{r, fig1, fig.cap=\"Figure 1. Scores by group and sex.\"} ggplot(dat, aes(grp, Y, fill = sex)) + geom_violin(alpha = 0.5) + geom_boxplot(width = 0.25, position = position_dodge(width = 0.9), show.legend = FALSE) + scale_fill_manual(values = c(\"orange\", \"purple\")) + xlab(\"Group\") + ylab(\"Score\") + theme(text = element_text(size = 30, family = \"Times\")) &#96;&#96;&#96; The last line changes the default text size and font, which can be useful for generating figures that meet a journal’s requirements. Figure 16.1: Figure 1. Scores by group and sex. You can also include images that you did not create in R using the typical markdown syntax for images: ![All the Things](images/x-all-the-things.png) All the Things 16.4.5.3 In-line R Now let’s use what you learned in the GLM lecture to analyse our simulated data. The document is getting a little cluttered, so let’s move this code to external scripts. Create a new R script called “functions.R” Move the library(tidyverse) line and the two_sample() function definition to this file. Create a new R script called “analysis.R” Move the code for creating dat to this file. Add the following code to the end of the setup chunk: source(&quot;functions.R&quot;) source(&quot;analysis.R&quot;) The source function lets you include code from an external file. This is really useful for making your documents readable. Just make sure you call your source files in the right order (e.g., include function definitions before you use the functions). In the “analysis.R” file, we’re going to run the analysis code and save any numbers we might want to use in our manuscript to variables. grp_lm &lt;- lm(Y ~ grp_e * sex_e, data = dat) stats &lt;- grp_lm %&gt;% broom::tidy() %&gt;% mutate_if(is.numeric, round, 3) The code above runs our analysis predicting Y from the effect-coded group variable grp_e, the effect-coded sex variable sex_e and their intereaction. The tidy function from the broom package turns the output into a tidy table. The mutate_if function uses the function is.numeric to check if each column should be mutated, adn if it is numeric, applies the round function with the digits argument set to 3. If you want to report the results of the analysis in a paragraph istead of a table, you need to know how to refer to each number in the table. Like with everything in R, there are many wways to do this. One is by specifying the column and row number like this: stats$p.value[2] ## [1] 0 Another way is to create variables for each row like this: grp_stats &lt;- filter(stats, term == &quot;grp_e&quot;) sex_stats &lt;- filter(stats, term == &quot;sex_e&quot;) ixn_stats &lt;- filter(stats, term == &quot;grp_e:sex_e&quot;) Add the above code to the end of your analysis.R file. Then you can refer to columns by name like this: grp_stats$p.value ## [1] 0 sex_stats$statistic ## [1] -0.907 ixn_stats$estimate ## [1] 0.315 You can insert these numbers into a paragraph with inline R code that looks like this: Scores were higher in group B than group A (B = &#96;r grp_stats$estimate&#96;, t = &#96;r grp_stats$statistic&#96;, p = &#96;r grp_stats$p.value&#96;). There was no significant difference between men and women (B = &#96;r sex_statsestimate&#96;, t = &#96;r sex_stats$statistic&#96;, p = &#96;r sex_stats$p.value&#96;) and the effect of group was not qualified by an interaction with sex (B = &#96;r ixn_stats$estimate&#96;, t = &#96;r ixn_stats$statistic&#96;, p = &#96;r ixn_stats$p.value&#96;). Rendered text: Scores were higher in group B than group A (B = 0.73, t = 4.792, p = 0). There was no significant difference between men and women (B = -0.138, t = -0.907, p = 0.365) and the effect of group was not qualified by an interaction with sex (B = 0.315, t = 1.035, p = 0.302). Remember, line breaks are ignored when you render the file (unless you add two spaces at the end of lines), so you can use line breaks to make it easier to read your text with inline R code. The p-values aren’t formatted in APA style. We wrote a function to deal with this in the function lecture. Add this function to the “functions.R” file and change the inline text to use the report_p function. report_p &lt;- function(p, digits = 3) { if (!is.numeric(p)) stop(&quot;p must be a number&quot;) if (p &lt;= 0) warning(&quot;p-values are normally greater than 0&quot;) if (p &gt;= 1) warning(&quot;p-values are normally less than 1&quot;) if (p &lt; .001) { reported = &quot;p &lt; .001&quot; } else { roundp &lt;- round(p, digits) fmt &lt;- paste0(&quot;p = %.&quot;, digits, &quot;f&quot;) reported = sprintf(fmt, roundp) } reported } Scores were higher in group B than group A (B = &#96;r grp_stats$estimate&#96;, t = &#96;r grp_stats$statistic&#96;, &#96;r report_p(grp_stats$p.value, 3)&#96;). There was no significant difference between men and women (B = &#96;r sex_stats$estimate&#96;, t = &#96;r sex_stats$statistic&#96;, &#96;r report_p(sex_stats$p.value, 3)&#96;) and the effect of group was not qualified by an interaction with sex (B = &#96;r ixn_stats$estimate&#96;, t = &#96;r ixn_stats$statistic&#96;, &#96;r report_p(ixn_stats$p.value, 3)&#96;). Rendered text: Scores were higher in group B than group A (B = 0.73, t = 4.792, p &lt; .001). There was no significant difference between men and women (B = -0.138, t = -0.907, p = 0.365) and the effect of group was not qualified by an interaction with sex (B = 0.315, t = 1.035, p = 0.302). You might also want to report the statistics for the regression. There are a lot of numbers to format and insert, so it is easier to do this in the analysis script using sprintf for formatting. s &lt;- summary(grp_lm) # calculate p value from fstatistic fstat.p &lt;- pf(s$fstatistic[1], s$fstatistic[2], s$fstatistic[3], lower=FALSE) adj_r &lt;- sprintf( &quot;The regression equation had an adjusted $R^{2}$ of %.3f ($F_{(%i, %i)}$ = %.3f, %s).&quot;, round(s$adj.r.squared, 3), s$fstatistic[2], s$fstatistic[3], round(s$fstatistic[1], 3), report_p(fstat.p, 3) ) Then you can just insert the text in your masnuscript like this: ` adj_r`: The regression equation had an adjusted \\(R^{2}\\) of 0.099 (\\(F_{(3, 196)}\\) = 8.287, p &lt; .001). 16.4.6 Bibliography There are several ways to do in-text citations and automatically generate a bibliography in RMarkdown. 16.4.6.1 Create a BibTeX File Manually You can just make a BibTeX file and add citations manually. Make a new Text File in RStudio called “bibliography.bib”. Next, add the line bibliography: bibliography.bib to your YAML header. You can add citations in the following format: @article{shortname, author = {Author One and Author Two and Author Three}, title = {Paper Title}, journal = {Journal Title}, volume = {vol}, number = {issue}, pages = {startpage--endpage}, year = {year}, doi = {doi} } 16.4.6.2 Citing R packages You can get the citation for an R package using the function citation. You can paste the bibtex entry into your bibliography.bib file. Make sure to add a short name (e.g., “rmarkdown”) before the first comma to refer to the reference. citation(package=&quot;rmarkdown&quot;) ## ## To cite the &#39;rmarkdown&#39; package in publications, please use: ## ## JJ Allaire and Yihui Xie and Jonathan McPherson and Javier ## Luraschi and Kevin Ushey and Aron Atkins and Hadley Wickham and ## Joe Cheng and Winston Chang and Richard Iannone (2018). ## rmarkdown: Dynamic Documents for R. R package version 1.11. URL ## https://rmarkdown.rstudio.com. ## ## Yihui Xie and J.J. Allaire and Garrett Grolemund (2018). R ## Markdown: The Definitive Guide. Chapman and Hall/CRC. ISBN ## 9781138359338. URL https://bookdown.org/yihui/rmarkdown. ## ## To see these entries in BibTeX format, use &#39;print(&lt;citation&gt;, ## bibtex=TRUE)&#39;, &#39;toBibtex(.)&#39;, or set ## &#39;options(citation.bibtex.max=999)&#39;. 16.4.6.3 Download Citation Info You can get the BibTeX formatted citation from most publisher websites. For example, go to the publisher’s page for Equivalence Testing for Psychological Research: A Tutorial, click on the Cite button (in the sidebar or under the bottom Explore More menu), choose BibTeX format, and download the citation. You can open up the file in a text editor and copy the text. It should look like this: @article{doi:10.1177/2515245918770963, author = {Daniël Lakens and Anne M. Scheel and Peder M. Isager}, title ={Equivalence Testing for Psychological Research: A Tutorial}, journal = {Advances in Methods and Practices in Psychological Science}, volume = {1}, number = {2}, pages = {259-269}, year = {2018}, doi = {10.1177/2515245918770963}, URL = { https://doi.org/10.1177/2515245918770963 }, eprint = { https://doi.org/10.1177/2515245918770963 } , abstract = { Psychologists must be able to test both for the presence of an effect and for the absence of an effect. In addition to testing against zero, researchers can use the two one-sided tests (TOST) procedure to test for equivalence and reject the presence of a smallest effect size of interest (SESOI). The TOST procedure can be used to determine if an observed effect is surprisingly small, given that a true effect at least as extreme as the SESOI exists. We explain a range of approaches to determine the SESOI in psychological science and provide detailed examples of how equivalence tests should be performed and reported. Equivalence tests are an important extension of the statistical tools psychologists currently use and enable researchers to falsify predictions about the presence, and declare the absence, of meaningful effects. } } Paste the reference into your bibliography.bib file. Change doi:10.1177/2515245918770963 in the first line of the reference to a short string you will use to cite the reference in your manuscript. We’ll use TOSTtutorial. 16.4.6.4 Converting from reference software Most reference software like EndNote, Zotero or mendeley have exporting options that can export to BibTeX format. You just need to check the shortnames in the resulting file. 16.4.6.5 In-text citations You can cite reference in text like this: This tutorial uses several R packages [@tidyverse;@rmarkdown]. This tutorial uses several R packages (???; ???). Put a minus in front of the @ if you just want the year: Lakens, Scheel and Isengar [-@TOSTtutorial] wrote a tutorial explaining how to test for the absence of an effect. Lakens, Scheel and Isengar (???) wrote a tutorial explaining how to test for the absence of an effect. 16.4.6.6 Citation Styles You can search a list of style files for various journals and download a file that will format your bibliography for a specific journal’s style. You’ll need to add the line csl: filename.csl to your YAML header. Add some citations to your bibliography.bib file, reference them in your text, and render your manuscript to see the automatically generated reference section. Try a few different citation style files. 16.4.7 Output Formats You can knit your file to PDF or Word if you have the right packages installed on your computer. 16.4.8 Computational Reproducibility Computational reproducibility refers to making all aspects of your analysis reproducible, including specifics of the software you used to run the code you wrote. R packages get updated periodically and some of these updates may break your code. Using a computational reproducibility platform guards against this by always running your code in the same environment. Code Ocean is a new platform that lets you run your code in the cloud via a web browser. 16.5 References "]
]
