[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"book provides overview skills needed reproducible research open science using statistical programming language R tidyverse packages. covers data visualisation, data tidying wrangling, archiving, iteration functions, probability data simulations, general linear models, reproducible workflows.book also available ePub Kindle formats.","code":""},{"path":"index.html","id":"course-resources","chapter":"Overview","heading":"Course Resources","text":"Data Skills Videos\nchapter several short video lectures main learning outcomes. videos captioned watching captioning useful way learn jargon computational reproducibility. access YouTube, videos available request. book chapters changed order version 2, playlist yet order book, chapter links relevant playlist videos.Data Skills Videos\nchapter several short video lectures main learning outcomes. videos captioned watching captioning useful way learn jargon computational reproducibility. access YouTube, videos available request. book chapters changed order version 2, playlist yet order book, chapter links relevant playlist videos.reprores\ncustom R package course. can install code . download packages used book, along offline copy book, shiny apps used book, exercises.\n\ndevtools::install_github(\"psyteachr/reprores-v2\")reprores\ncustom R package course. can install code . download packages used book, along offline copy book, shiny apps used book, exercises.glossary\nCoding statistics lot specialist terms. Throughout book, jargon linked glossary.glossary\nCoding statistics lot specialist terms. Throughout book, jargon linked glossary.","code":"\ndevtools::install_github(\"psyteachr/reprores-v2\")"},{"path":"index.html","id":"i-found-a-bug","chapter":"Overview","heading":"I found a bug!","text":"book work progress, might find errors. Please help fix ! best way open issue github describes error, can also mention class Teams forum email Lisa.","code":""},{"path":"index.html","id":"other-resources","chapter":"Overview","heading":"Other Resources","text":"RStudio Cheat SheetsLearning Statistics R NavarroR Data Science Grolemund WickhamImproving statistical inferences CourseraswirlR Reproducible Scientific Analysiscodeschool.comdatacampStyle guide R programming#rstats twitter highly recommended!","code":""},{"path":"intro.html","id":"intro","chapter":"1 Getting Started","heading":"1 Getting Started","text":"","code":""},{"path":"intro.html","id":"ilo-intro","chapter":"1 Getting Started","heading":"1.1 Learning Objectives","text":"Understand components RStudio IDE (video)Type commands console (video)Understand function syntax (video)Install package (video)","code":""},{"path":"intro.html","id":"resources-intro","chapter":"1 Getting Started","heading":"1.2 Resources","text":"Chapter 1: Introduction R Data ScienceRStudio IDE CheatsheetIntroduction R MarkdownR Markdown CheatsheetR Markdown ReferenceRStudio Cloud","code":""},{"path":"intro.html","id":"what-is-r","chapter":"1 Getting Started","heading":"1.3 What is R?","text":"R programming environment data processing statistical analysis. use R Psychology University Glasgow promote reproducible research. refers able document reproduce steps raw data results. R allows write scripts combine data files, clean data, run analyses. many ways , including writing SPSS syntax files, find R useful tool free, open source, commonly used research psychologists.See Appendix information install R associated programs.","code":""},{"path":"intro.html","id":"rconsole","chapter":"1 Getting Started","heading":"1.3.1 The Base R Console","text":"open application called R, see \"R Console\" window looks something like .\nFigure 1.1: R Console window.\ncan close R never open . working entirely RStudio class.ALWAYS REMEMBER: Launch R though RStudio IDELaunch  (RStudio.app),  (R.app).","code":""},{"path":"intro.html","id":"rstudio_ide","chapter":"1 Getting Started","heading":"1.3.2 RStudio","text":"RStudio Integrated Development Environment (IDE). program serves text editor, file manager, provides many functions help read write R code.\nFigure 1.2: RStudio IDE\nRStudio arranged four window panes. default, upper left pane source pane, view edit source code files. bottom left pane usually console pane, can type commands view output messages. right panes several different tabs show information code. can change location panes tabs shown Preferences > Pane Layout.","code":""},{"path":"intro.html","id":"configure-rstudio","chapter":"1 Getting Started","heading":"1.3.3 Configure RStudio","text":"class, learning reproducible research. involves writing scripts completely transparently perform analysis start finish way yields result different people using software different computers. Transparency key value science, embodied \"trust verify\" motto.things reproducibly, others can understand check work. benefits science, selfish reason, : important person benefit reproducible script future self. return analysis two weeks vacation, thank earlier self things transparent, reproducible way, can easily pick right left .two tweaks RStudio installation maximize reproducibility. Go Global Options... Tools menu (Cmd-,), uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.\nFigure 1.3: Alter settings increased reproducibility.\nsettings :Restore .RData workspace startup: CheckedNot CheckedSave workspace .RData exit: AlwaysNeverAsk","code":""},{"path":"intro.html","id":"getting-started","chapter":"1 Getting Started","heading":"1.4 Getting Started","text":"","code":""},{"path":"intro.html","id":"console","chapter":"1 Getting Started","heading":"1.4.1 Console commands","text":"first going learn interact console. general, developing R scripts R Markdown files, rather working directly console window. However, can consider console kind \"sandbox\" can try lines code adapt get want. can copy back script editor.Mostly, however, typing script editor window (either R script R Markdown file) sending commands console placing cursor line holding Ctrl key press Enter. Ctrl+Enter key sequence sends command script console.One simple way learn R console use calculator. Enter lines code see results match. prepared make lots typos (first).R console remembers history commands typed past. Use arrow keys keyboard scroll backwards forwards history. lot faster re-typing.can break mathematical expressions multiple lines; R waits complete expression processing .Text inside quotes called string.can break text multiple lines; R waits close quote processing . want include double quote inside quoted string, escape backslash.","code":"\n1 + 1## [1] 2\n1 + 1 + 3## [1] 5\n## here comes a long expression\n## let's break it over multiple lines\n1 + 2 + 3 + 4 + 5 + 6 +\n    7 + 8 + 9 +\n    10## [1] 55\n\"Good afternoon\"## [1] \"Good afternoon\"\nafrica <- \"I hear the drums echoing tonight  \nBut she hears only whispers of some quiet conversation  \nShe's coming in, 12:30 flight  \nThe moonlit wings reflect the stars that guide me towards salvation  \nI stopped an old man along the way  \nHoping to find some old forgotten words or ancient melodies  \nHe turned to me as if to say, \\\"Hurry boy, it's waiting there for you\\\"\n\n- Toto\"\n\ncat(africa) # cat() prints the string## I hear the drums echoing tonight  \n## But she hears only whispers of some quiet conversation  \n## She's coming in, 12:30 flight  \n## The moonlit wings reflect the stars that guide me towards salvation  \n## I stopped an old man along the way  \n## Hoping to find some old forgotten words or ancient melodies  \n## He turned to me as if to say, \"Hurry boy, it's waiting there for you\"\n## \n## - Toto"},{"path":"intro.html","id":"vars","chapter":"1 Getting Started","heading":"1.4.2 Objects","text":"Often want store result computation later use. can store object (also sometimes called variable). object R:contains letters, numbers, full stops, underscoresstarts letter full stop letterdistinguishes uppercase lowercase letters (rickastley RickAstley)following valid different objects:songdataSongDatasong_datasong.data.song.datanever_gonna_give_you_up_never_gonna_let_you_downThe following valid objects:_song_data1song.1songsong datasong-dataUse assignment operator<-` assign value right object named left.Now set x value, can something :Note print result back stored. view result, just type object name blank line.object assigned value, value change unless reassign object, even objects used calculate change. Predict code test :code run:this_year = 4344197620192020my_birth_year = 4344197620192020my_age = 4344197620192020","code":"\n## use the assignment operator '<-'\n## R stores the number in the object\nx <- 5\nx * 2\n\n## R evaluates the expression and stores the result in the object boring_calculation\nboring_calculation <- 2 + 2## [1] 10\nboring_calculation## [1] 4\nthis_year <- 2019\nmy_birth_year <- 1976\nmy_age <- this_year - my_birth_year\nthis_year <- 2020"},{"path":"intro.html","id":"the-environment","chapter":"1 Getting Started","heading":"1.4.3 The environment","text":"Anytime assign something new object, R creates new entry global environment. Objects global environment exist end session; disappear forever (unless save ).Look Environment tab upper right pane. lists objects created. Click broom icon clear objects start fresh. can also use following functions console view objects, remove one object, remove objects.upper right corner Environment tab, change List Grid. Now can see type, length, size objects, reorder list attributes.","code":"\nls()            # print the objects in the global environment\nrm(\"x\")         # remove the object named x from the global environment\nrm(list = ls()) # clear out the global environment"},{"path":"intro.html","id":"whitespace","chapter":"1 Getting Started","heading":"1.4.4 Whitespace","text":"R mostly ignores whitespace: spaces, tabs, line breaks. means can use whitespace help organise code.see > beginning line, means R waiting start new command. However, see + instead > start line, means R waiting finish command started previous line. want cancel whatever command started, just press Esc key console window get back > command prompt.often useful break long functions onto several lines.","code":"\n# a and b are identical\na <- list(ctl = \"Control Condition\", exp1 = \"Experimental Condition 1\", exp2 = \"Experimental Condition 2\")\n\n# but b is much easier to read\nb <- list(ctl  = \"Control Condition\", \n          exp1 = \"Experimental Condition 1\", \n          exp2 = \"Experimental Condition 2\")\n# R waits until next line for evaluation\n(3 + 2) *\n     5## [1] 25\ncat(\"3, 6, 9, the goose drank wine\",\n    \"The monkey chewed tobacco on the streetcar line\",\n    \"The line broke, the monkey got choked\",\n    \"And they all went to heaven in a little rowboat\",\n    sep = \"  \\n\")## 3, 6, 9, the goose drank wine  \n## The monkey chewed tobacco on the streetcar line  \n## The line broke, the monkey got choked  \n## And they all went to heaven in a little rowboat"},{"path":"intro.html","id":"function_syx","chapter":"1 Getting Started","heading":"1.4.5 Function syntax","text":"lot R involves calling function storing results. function named section code can reused.example, sd function returns standard deviation vector numbers provide input argument. Functions set like :arguments parentheses can named (e.g., argument1 = 10) can skip names put exact order defined function. can check typing ?sd (whatever function name looking ) console Help pane show default order Usage. can skip arguments default value specified.functions return value, may also produce side effects like printing console.illustrate, function rnorm() generates random numbers standard normal distribution. help page rnorm() (accessed typing ?rnorm console) shows syntaxwhere n number randomly generated numbers want, mean mean distribution, sd standard deviation. default mean 0, default standard deviation 1. default n, means get error specify :want 10 random numbers normal distribution mean 0 standard deviation, can just use defaults.want 10 numbers normal distribution mean 100:equivalent less efficient way calling function:need name arguments R recognize intended fill first second arguments position function call. However, want change default argument coming later list, need name . instance, wanted keep default mean = 0 change standard deviation 100, way:functions give list options argument; means default value first option. usage entry power.t.test() function looks like :default value sd? NULL10.05two.sampleWhat default value type? NULLtwo.sampleone.samplepairedWhich equivalent power.t.test(100, 0.5)? power.t.test(100, 0.5, sig.level = 1, sd = 0.05)power.t.test()power.t.test(n = 100)power.t.test(delta = 0.5, n = 100)","code":"\nfunction_name(argument1, argument2 = \"value\")\nrnorm(n, mean = 0, sd = 1)\nrnorm()## Error in rnorm(): argument \"n\" is missing, with no default\nrnorm(10)##  [1]  1.1105853 -0.5461483 -0.7669323 -1.1512916  1.1129190  0.1476838\n##  [7]  0.7253085  0.1571518 -1.1026573  0.5174352\nrnorm(10, 100)##  [1]  99.94997 100.93326 101.60351  98.75985 100.10601 101.02585  98.97277\n##  [8]  98.19387  98.73396  99.85427\nrnorm(n = 10, mean = 100)##  [1]  99.98911 100.86249 101.38420  97.95455  99.34883  99.83196  99.32835\n##  [8] 100.50277  98.47662  99.73740\nrnorm(10, sd = 100)##  [1]   19.25799  -97.97855   56.74377   13.98058  191.57799  -56.02954\n##  [7]   78.10909  111.67311   16.46722 -392.42907\npower.t.test(n = NULL, delta = NULL, sd = 1, sig.level = 0.05,\n             power = NULL,\n             type = c(\"two.sample\", \"one.sample\", \"paired\"),\n             alternative = c(\"two.sided\", \"one.sided\"),\n             strict = FALSE, tol = .Machine$double.eps^0.25)"},{"path":"intro.html","id":"help","chapter":"1 Getting Started","heading":"1.4.6 Getting help","text":"Start help browser using function help.start().function base R loaded package, can use help(\"function_name\") function ?function_name shortcut access help file. package loaded, specify package name second argument help function.package loaded sure package function , use shortcut ??function_name.first argument mean function? trimna.rmmeanxWhat package read_excel ? readrreadxlbasestats","code":"\n# these methods are all equivalent ways of getting help\nhelp(\"rnorm\")\n?rnorm\nhelp(\"rnorm\", package=\"stats\") "},{"path":"intro.html","id":"install-package","chapter":"1 Getting Started","heading":"1.5 Add-on packages","text":"One great things R user extensible: anyone can create new add-software package extends functionality. currently thousands add-packages R users created solve many different kinds problems, just simply fun. packages data visualisation, machine learning, neuroimaging, eyetracking, web scraping, playing games Sudoku.Add-packages distributed base R, downloaded installed archive, way , instance, download install fitness app smartphone.main repository packages reside called CRAN, Comprehensive R Archive Network. package pass strict tests devised R core team allowed part CRAN archive. can install CRAN archive R using install.packages() function.important distinction installing package loading package.","code":""},{"path":"intro.html","id":"installing-a-package","chapter":"1 Getting Started","heading":"1.5.1 Installing a package","text":"done using install.packages(). like installing app phone: app remain installed remove . instance, want use PokemonGo phone, install App Store Play Store, re-install time want use . launch app, run background close restart phone. Likewise, install package, package available (loaded) every time open R.may able permanently install packages using R system; may able public workstations lack appropriate privileges.Install ggExtra package system. package lets create plots marginal histograms.already packages like ggplot2 shiny installed, also install dependencies . get error message end, installation successful.","code":"\ninstall.packages(\"ggExtra\")"},{"path":"intro.html","id":"loading-a-package","chapter":"1 Getting Started","heading":"1.5.2 Loading a package","text":"done using library(packagename). like launching app phone: functionality app launched remains close app restart. Likewise, run library(packagename) within session, functionality package referred packagename made available R session. next time start R, need run library() function want access functionality.can load functions ggExtra current R session follows:might get red text load package, normal. usually warning package functions name packages already loaded.can use convention package::function() indicate add-package function resides. instance, see readr::read_csv(), refers function read_csv() readr add-package.Now can run function ggExtra::runExample(), runs interactive example marginal plots using shiny.","code":"\nlibrary(ggExtra)\nggExtra::runExample()"},{"path":"intro.html","id":"install-from-github","chapter":"1 Getting Started","heading":"1.5.3 Install from GitHub","text":"Many R packages yet CRAN still development. Increasingly, datasets code papers available packages can download github. need install devtools package able install packages github. Check package installed trying load (e.g., devtools installed, library(\"devtools\") display error message) searching packages tab lower right pane. listed packages installed; checked packages currently loaded.\nFigure 1.4: Check installed loaded packages packages tab lower right pane.\ninstall reprores package, load using library() function. can try functions .many different ways can find discover functions available reprores package?Reprores contains datasets using future lessons. getdata() creates directory called \"data\" class datasets.","code":"\n# install devtools if you get\n# Error in loadNamespace(name) : there is no package called ‘devtools’\n# install.packages(\"devtools\")\ndevtools::install_github(\"psyteachr/reprores-v2\")\nlibrary(reprores)\n\n# opens a local copy of this book in your web browser\nbook()\n\n# opens a shiny app that lets you see how simulated data would look in different plot styles\napp(\"plotdemo\")\n\n# creates and opens a file containing the exercises for this chapter\nexercise(1)\n# loads the disgust dataset\ndata(\"disgust\")\n\n# shows the documentation for the built-in dataset `disgust`\n?disgust\n\n# saves datasets into a \"data\" folder in your working directory\ngetdata(\"data\")"},{"path":"intro.html","id":"glossaryintro","chapter":"1 Getting Started","heading":"1.6 Glossary","text":"chapter ends glossary table defining jargon introduced chapter. links take glossary book, can also download offline use devtools::install_github(\"psyteachr/glossary\") access glossary offline glossary::book().","code":""},{"path":"intro.html","id":"exercises-intro","chapter":"1 Getting Started","heading":"1.7 Exercises","text":"Download first set exercises. See answers attempted questions.","code":"\n# run this to access the exercise\nreprores::exercise(1)\n\n# run this to access the answers\nreprores::exercise(1, answers = TRUE)"},{"path":"repro.html","id":"repro","chapter":"2 Reproducible Workflows","heading":"2 Reproducible Workflows","text":"","code":""},{"path":"repro.html","id":"ilo-repro","chapter":"2 Reproducible Workflows","heading":"2.1 Learning Objectives","text":"","code":""},{"path":"repro.html","id":"basic","chapter":"2 Reproducible Workflows","heading":"2.1.1 Basic","text":"Organise project (video)Create compile Rmarkdown document (video)Edit YAML header add table contents optionsInclude tableInclude figureReport output analysis using inline RAdd bibliography -line citations","code":""},{"path":"repro.html","id":"intermediate","chapter":"2 Reproducible Workflows","heading":"2.1.2 Intermediate","text":"Output doc PDF formatsFormat tables using kableExtra","code":""},{"path":"repro.html","id":"resources-repro","chapter":"2 Reproducible Workflows","heading":"2.2 Resources","text":"Chapter 27: R Markdown R Data ScienceR Markdown Cheat SheetR Markdown reference GuideR Markdown TutorialR Markdown: Definitive Guide Yihui Xie, J. J. Allaire, & Garrett GrolemundPapaja Reproducible APA ManuscriptsCode Ocean Computational Reproducibility","code":""},{"path":"repro.html","id":"setup-repro","chapter":"2 Reproducible Workflows","heading":"2.3 Setup","text":"","code":"\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(broom)\nset.seed(8675309)"},{"path":"repro.html","id":"why-learn-reproducible-reports","chapter":"2 Reproducible Workflows","heading":"2.4 Why learn reproducible reports?","text":"ever worked report, creating summary table demographics, making beautiful plots, getting analysis just right, copying relevant numbers manuscript, find forgot exclude test run redo everything?R Markdown document produces reproducible report fixes problem. Although requires bit extra effort start, pay back allowing update entire report push button whenever anything changes.Studies also show many, , papers scientific literature reporting errors. example, half 250,000 psychology papers published 1985 2013 least one value statistically incompatible (e.g., p-value possible given t-value degrees freedom) (Nuijten et al. 2016). Reproducible reports help avoid transcription rounding errors.make reproducible reports following principles literate programming. basic idea text report together single document along code needed perform analyses generate tables. report \"compiled\" original format , portable format, HTML PDF. different traditional cutting pasting approaches , instance, create graph Microsoft Excel statistics program like SPSS paste Microsoft Word.","code":""},{"path":"repro.html","id":"projects","chapter":"2 Reproducible Workflows","heading":"2.5 Organising a project","text":"First, need get orgainsed.Projects RStudio way group files need one project. projects include scripts, data files, output files like PDF version script images.Make new directory keep materials class. using lab computer, make sure make directory network drive can access computers.Choose New Project... File menu create new project called 01-repro directory.","code":""},{"path":"repro.html","id":"working-directory","chapter":"2 Reproducible Workflows","heading":"2.5.1 Working Directory","text":"put files? developing analysis, usually want scripts data files one subtree computer's directory structure. Usually single working directory data scripts stored.script reference files three locations, using appropriate format.Never set change working directory script.working R Markdown file, automatically use directory .Rmd file working directory.working R scripts, store main script file top-level directory manually set working directory location. reset working directory time open RStudio, unless create project access script project.instance, Windows machine data scripts directory C:\\Carla's_files\\thesis2\\my_thesis\\new_analysis, set working directory one two ways: (1) going Session pull menu RStudio choosing Set Working Directory, (2) typing setwd(\"C:\\Carla's_files\\thesis2\\my_thesis\\new_analysis\") console window.tempting make life simple putting setwd() command script. ! Others directory tree (laptop dies get new one, neither ).manually setting working directory, always using Session > Set Working Directory pull-option typing setwd() console.script needs file subdirectory new_analysis, say, data/questionnaire.csv, load using relative path accessible move folder new_analysis another location computer:load using absolute path:Also note convention using forward slashes, unlike Windows-specific convention using backward slashes. make references files platform independent.","code":"\ndat <- read_csv(\"data/questionnaire.csv\")  # correct\ndat <- read_csv(\"C:/Carla's_files/thesis22/my_thesis/new_analysis/data/questionnaire.csv\")   # wrong"},{"path":"repro.html","id":"r-markdown","chapter":"2 Reproducible Workflows","heading":"2.6 R Markdown","text":"lesson, learn make R Markdown document table contents, appropriate headers, code chunks, tables, images, inline R, bibliography.use R Markdown create reproducible reports, enables mixing text code. reproducible script contain sections code code blocks. code block starts ends backtick symbols row, information code curly brackets, {r chunk-name, echo=FALSE} (runs code, show text code block compiled document). text outside code blocks written markdown, way specify formatting, headers, paragraphs, lists, bolding, links.\nFigure 2.1: reproducible script.\nopen new R Markdown file template, see example document several code blocks . create HTML PDF report R Markdown (Rmd) document, compile . Compiling document called knitting RStudio. button looks like ball yarn needles click compile file report.Create new R Markdown file File > New File > R Markdown... menu. Change title author, click knit button create html file.","code":""},{"path":"repro.html","id":"yaml-header","chapter":"2 Reproducible Workflows","heading":"2.6.1 YAML Header","text":"YAML header can set several options.df_print: kable option prints data frames using knitr::kable. learn customise tables.built-themes : \"cerulean\", \"cosmo\", \"flatly\", \"journal\", \"lumen\", \"paper\", \"readable\", \"sandstone\", \"simplex\", \"spacelab\", \"united\", \"yeti\". can view download themes.Try changing values false true see options .","code":"---\ntitle: \"My Demo Document\"\nauthor: \"Me\"\noutput:\n  html_document:\n    df_print: kable\n    theme: spacelab\n    highlight: tango\n    toc: true\n    toc_float:\n      collapsed: false\n      smooth_scroll: false\n    toc_depth: 3\n    number_sections: false\n---"},{"path":"repro.html","id":"setup","chapter":"2 Reproducible Workflows","heading":"2.6.2 Setup","text":"create new R Markdown file RStudio, setup chunk automatically created.```{r setup, include=FALSE}can set default options code chunks . See knitr options documentation explanations possible options.```{r setup, include=FALSE}code sets following options:fig.width  = 8 : default figure width 8 inches (can change individual figures)fig.height = 5 : default figure height 5 inchesfig.path   = 'images/' : figures saved directory \"images\"echo       = FALSE : show code chunks rendered documentwarning    = FALSE : show function warningsmessage    = FALSE : show function messagescache      = FALSE : run code create images objects time knit (set TRUE time-consuming code)Find list current chunk options typing str(knitr::opts_chunk$get()) console.can also add packages need chunk using library(). Often working script, realize need load another add-package. bury call library(package_I_need) way script. Put top, user overview packages needed.using function package tidyverse, load setup chunk.","code":"\nknitr::opts_chunk$set(echo = TRUE)\nknitr::opts_chunk$set(\n  fig.width  = 8, \n  fig.height = 5, \n  fig.path   = 'images/',\n  echo       = FALSE, \n  warning    = TRUE, \n  message    = FALSE,\n  cache      = FALSE\n)"},{"path":"repro.html","id":"structure","chapter":"2 Reproducible Workflows","heading":"2.6.3 Structure","text":"include table contents (toc), created document headers. Headers markdown created prefacing header title one hashes (#).Use following structure developing analysis scripts:load add-packages need usedefine custom functionsload simulate data working withwork datasave anything need saveDelete default text add structure document creating headers subheaders. going load data, create summary table, plot data, analyse .","code":""},{"path":"repro.html","id":"code-chunks","chapter":"2 Reproducible Workflows","heading":"2.6.4 Code Chunks","text":"can include code chunks create display images, tables, computations include text. start loading data.First, create code chunk document. code loads data web.","code":"\npets <- read_csv(\"https://psyteachr.github.io/reprores/data/pets.csv\")## \n## ── Column specification ────────────────────────────────────────────────────────\n## cols(\n##   id = col_character(),\n##   pet = col_character(),\n##   country = col_character(),\n##   score = col_double(),\n##   age = col_double(),\n##   weight = col_double()\n## )"},{"path":"repro.html","id":"comments","chapter":"2 Reproducible Workflows","heading":"2.6.4.1 Comments","text":"can add comments inside R chunks hash symbol (#). R interpreter ignore characters hash end line.usually good practice start code chunk comment explains , especially code explained text report.name objects clearly, often need add clarifying comments. example, named three objects total_pet_n, mean_score sd_score, omit comments.bit art comment code well. best way develop skill read lot people's code others review code.","code":"\n# simulating new data\n\nn <- nrow(pets) # the total number of pet\nmu <- mean(pets$score) # the mean score for all pets\nsd <- sd(pets$score) # the SD for score for all pets\n\nsimulated_scores <- rnorm(n, mu, sd)"},{"path":"repro.html","id":"tables","chapter":"2 Reproducible Workflows","heading":"2.6.4.2 Tables","text":"Next, create code chunk want display table descriptives (e.g., Participants section Methods). use tidyverse functions learn data wrangling lectures create summary statistics group.table OK, reader-friendly changing column labels, rounding means, adding caption. can use knitr::kable() .Table 2.1: Summary statistics pets dataset.Notice r chunk specifies option results='asis'. lets format table using kable() function knitr. can also use specialised functions papaja kableExtra format tables.","code":"\npets %>%\n  group_by(pet) %>%\n  summarise(\n    n = n(),\n    mean_weight = mean(weight),\n    mean_score = mean(score)\n  )\nsummary_table <-pets %>%\n  group_by(pet) %>%\n  summarise(\n    n = n(),\n    mean_weight = mean(weight),\n    mean_score = mean(score)\n  )\n\nnewnames <- c(\"Pet Type\", \"N\", \"Mean Weight\", \"Mean Score\")\n\nknitr::kable(summary_table, \n             digits = 2, \n             col.names = newnames,\n             caption = \"Summary statistics for the pets dataset.\")"},{"path":"repro.html","id":"images","chapter":"2 Reproducible Workflows","heading":"2.6.4.3 Images","text":"Next, create code chunk want display image document. put Results section. use code learn data visualisation lecture show violin-boxplots groups.Notice figure caption formatted chunk options.\nFigure 2.2: Figure 1. Scores pet type country.\nlast line changes default text size font, can useful generating figures meet journal's requirements.can also include images create R using typical markdown syntax images:Things Hyperbole Half","code":"\n```r\nggplot(pets, aes(pet, score, fill = country)) +\n  geom_violin(alpha = 0.5) +\n  geom_boxplot(width = 0.25, \n               position = position_dodge(width = 0.9),\n               show.legend = FALSE) +\n  scale_fill_manual(values = c(\"orange\", \"dodgerblue\")) +\n  xlab(\"\") +\n  ylab(\"Score\") +\n  theme(text = element_text(size = 20, family = \"Times\"))\n```\n\n<div class=\"figure\" style=\"text-align: center\">\n<img src=\"02-repro_files/figure-html/unnamed-chunk-6-1.png\" alt=\"Figure 1. Scores by pet type and country.\" width=\"100%\" />\n<p class=\"caption\">(\\#fig:unnamed-chunk-6)Figure 1. Scores by pet type and country.<\/p>\n<\/div>![All the Things by [Hyperbole and a Half](http://hyperboleandahalf.blogspot.com/)](images/memes/x-all-the-things.png)"},{"path":"repro.html","id":"in-line-r","chapter":"2 Reproducible Workflows","heading":"2.6.4.4 In-line R","text":"Now analyse pets data see cats heavier ferrets. First run analysis code. save numbers might want use manuscript variables round appropriately. Finally, use glue::glue() format results string.can insert results paragraph inline R code looks like :Rendered text:\nCats significantly heavier ferrets (t = 18.42, df = 180.4, p < 0.001).","code":"\n# analysis\ncat_weight <- filter(pets, pet == \"cat\") %>% pull(weight)\nferret_weight <- filter(pets, pet == \"ferret\") %>% pull(weight)\nweight_test <- t.test(cat_weight, ferret_weight)\n\n# round individual values you want to report\nt <- weight_test$statistic %>% round(2)\ndf <- weight_test$parameter %>% round(1)\np <- weight_test$p.value %>% round(3)\n# handle p-values < .001\np_symbol <- ifelse(p < .001, \"<\", \"=\")\nif (p < .001) p <- .001\n\n# format the results string\nweight_result <- glue::glue(\"t = {t}, df = {df}, p {p_symbol} {p}\")Cats were significantly heavier than ferrets (`r weight_result`)."},{"path":"repro.html","id":"bibliography","chapter":"2 Reproducible Workflows","heading":"2.6.5 Bibliography","text":"several ways -text citations automatically generate bibliography RMarkdown.","code":""},{"path":"repro.html","id":"create-a-bibtex-file-manually","chapter":"2 Reproducible Workflows","heading":"2.6.5.1 Create a BibTeX File Manually","text":"can just make BibTeX file add citations manually. Make new Text File RStudio called \"bibliography.bib\".Next, add line bibliography: bibliography.bib YAML header.can add citations following format:","code":"@article{shortname,\n  author = {Author One and Author Two and Author Three},\n  title = {Paper Title},\n  journal = {Journal Title},\n  volume = {vol},\n  number = {issue},\n  pages = {startpage--endpage},\n  year = {year},\n  doi = {doi}\n}"},{"path":"repro.html","id":"citing-r-packages","chapter":"2 Reproducible Workflows","heading":"2.6.5.2 Citing R packages","text":"can get citation R package using functions citation() toBibtex(). can paste bibtex entry bibliography.bib file. Make sure add short name (e.g., \"faux\") first comma refer reference.","code":"\ncitation(package=\"faux\") %>% toBibtex()## @Manual{,\n##   title = {faux: Simulation for Factorial Designs},\n##   author = {Lisa DeBruine},\n##   doi = {10.5281/zenodo.2669586},\n##   publisher = {Zenodo},\n##   year = {2021},\n##   note = {R package version 1.0.0.9004},\n##   url = {https://debruine.github.io/faux/},\n## }"},{"path":"repro.html","id":"download-citation-info","chapter":"2 Reproducible Workflows","heading":"2.6.5.3 Download Citation Info","text":"Google Scholar entries BibTeX citation option. usually easiest way get relevant values, although add DOI .journal websites also let download citations bibtex format.\nexample, go publisher's page Equivalence Testing Psychological Research: Tutorial, click Cite button (sidebar bottom Explore menu), choose BibTeX format, download citation. can open file text editor copy text. look like :Paste reference bibliography.bib file. Change doi:10.1177/2515245918770963 first line reference short string use cite reference manuscript. use TOSTtutorial.","code":"@article{doi:10.1177/2515245918770963,\nauthor = {Daniël Lakens and Anne M. Scheel and Peder M. Isager},\ntitle ={Equivalence Testing for Psychological Research: A Tutorial},\njournal = {Advances in Methods and Practices in Psychological Science},\nvolume = {1},\nnumber = {2},\npages = {259-269},\nyear = {2018},\ndoi = {10.1177/2515245918770963},\n\nURL = { \n        https://doi.org/10.1177/2515245918770963\n    \n},\neprint = { \n        https://doi.org/10.1177/2515245918770963\n    \n}\n,\n    abstract = { Psychologists must be able to test both for the presence of an effect and for the absence of an effect. In addition to testing against zero, researchers can use the two one-sided tests (TOST) procedure to test for equivalence and reject the presence of a smallest effect size of interest (SESOI). The TOST procedure can be used to determine if an observed effect is surprisingly small, given that a true effect at least as extreme as the SESOI exists. We explain a range of approaches to determine the SESOI in psychological science and provide detailed examples of how equivalence tests should be performed and reported. Equivalence tests are an important extension of the statistical tools psychologists currently use and enable researchers to falsify predictions about the presence, and declare the absence, of meaningful effects. }\n}"},{"path":"repro.html","id":"converting-from-reference-software","chapter":"2 Reproducible Workflows","heading":"2.6.5.4 Converting from reference software","text":"reference software like EndNote, Zotero Mendeley exporting options can export BibTeX format. just need check shortnames resulting file.","code":""},{"path":"repro.html","id":"in-text-citations","chapter":"2 Reproducible Workflows","heading":"2.6.5.5 In-text citations","text":"can cite reference text like :tutorial uses several R packages (Wickham 2017; Allaire et al. 2018).Put minus front @ just want year:Lakens, Scheel Isengar (2018) wrote tutorial explaining test absence effect.","code":"This tutorial uses several R packages [@tidyverse;@rmarkdown].Lakens, Scheel and Isengar [-@TOSTtutorial] wrote a tutorial explaining how to test for the absence of an effect."},{"path":"repro.html","id":"citation-styles","chapter":"2 Reproducible Workflows","heading":"2.6.5.6 Citation Styles","text":"can search list style files various journals download file format bibliography specific journal's style. need add line csl: filename.csl YAML header.Add citations bibliography.bib file, reference text, render manuscript see automatically generated reference section. Try different citation style files.","code":""},{"path":"repro.html","id":"output-formats","chapter":"2 Reproducible Workflows","heading":"2.6.6 Output Formats","text":"can knit file PDF Word right packages installed computer. can also create presentations, dashboards, websites, even books R markdown. fact, book reading right now created using R markdown. See RStudio Formats list output types.","code":""},{"path":"repro.html","id":"computational-reproducibility","chapter":"2 Reproducible Workflows","heading":"2.6.7 Computational Reproducibility","text":"Computational reproducibility refers making aspects analysis reproducible, including specifics software used run code wrote. R packages get updated periodically updates may break code. Using computational reproducibility platform guards always running code environment.Code Ocean platform lets run code cloud via web browser.","code":""},{"path":"repro.html","id":"glossary-repro","chapter":"2 Reproducible Workflows","heading":"2.7 Glossary","text":"","code":""},{"path":"repro.html","id":"exercises-repro","chapter":"2 Reproducible Workflows","heading":"2.8 Exercises","text":"Create new project called \"website\".\"website\" project, create new Rmarkdown document called \"index.Rmd\". following document:Edit YAML header output tables using kable use custom theme.Write short paragraph describing research interests.Include bullet-point list links websites useful research.Add image anything relevant.Include code chunk end displays small table fortunes fortunes package.Knit document html.","code":""},{"path":"repro.html","id":"references","chapter":"2 Reproducible Workflows","heading":"2.9 References","text":"","code":""},{"path":"ggplot.html","id":"ggplot","chapter":"3 Data Visualisation","heading":"3 Data Visualisation","text":"","code":""},{"path":"ggplot.html","id":"ilo-ggplot","chapter":"3 Data Visualisation","heading":"3.1 Learning Objectives","text":"","code":""},{"path":"ggplot.html","id":"basic-1","chapter":"3 Data Visualisation","heading":"3.1.1 Basic","text":"Understand types graphs best different types data (video)\n1 discrete\n1 continuous\n2 discrete\n2 continuous\n1 discrete, 1 continuous\n3 continuous\n1 discrete1 continuous2 discrete2 continuous1 discrete, 1 continuous3 continuousCreate common types graphs ggplot2 (video)\ngeom_bar()\ngeom_density()\ngeom_freqpoly()\ngeom_histogram()\ngeom_col()\ngeom_boxplot()\ngeom_violin()\nVertical Intervals\ngeom_crossbar()\ngeom_errorbar()\ngeom_linerange()\ngeom_pointrange()\n\ngeom_point()\ngeom_smooth()\ngeom_bar()geom_density()geom_freqpoly()geom_histogram()geom_col()geom_boxplot()geom_violin()Vertical Intervals\ngeom_crossbar()\ngeom_errorbar()\ngeom_linerange()\ngeom_pointrange()\ngeom_crossbar()geom_errorbar()geom_linerange()geom_pointrange()geom_point()geom_smooth()Set custom size,\nlabels,\ncolours, \nthemes (video)Combine plots plot, facets, grid using patchwork (video)Save plots image file (video)","code":""},{"path":"ggplot.html","id":"intermediate-1","chapter":"3 Data Visualisation","heading":"3.1.2 Intermediate","text":"Add lines graphsDeal overlapping dataCreate less common types graphs\ngeom_tile()\ngeom_density2d()\ngeom_bin2d()\ngeom_hex()\ngeom_count()\ngeom_tile()geom_density2d()geom_bin2d()geom_hex()geom_count()Adjust axes (e.g., flip coordinates, set axis limits)Create interactive graphs plotly","code":""},{"path":"ggplot.html","id":"resources3","chapter":"3 Data Visualisation","heading":"3.2 Resources","text":"Data visualisation using R, researchers use RChapter 3: Data Visualisation R Data Scienceggplot2 cheat sheetChapter 28: Graphics communication R Data ScienceLook Data Data Vizualization Social ScienceHack Data Beautiful workshop University Glasgow postgraduate studentsGraphs Cookbook Rggplot2 documentationThe R Graph Gallery (really useful)Top 50 ggplot2 VisualizationsR Graphics Cookbook Winston Changggplot extensionsplotly creating interactive graphs","code":""},{"path":"ggplot.html","id":"setup_ggplot","chapter":"3 Data Visualisation","heading":"3.3 Setup","text":"","code":"\n# libraries needed for these graphs\nlibrary(tidyverse)\nlibrary(patchwork) \nlibrary(reprores)\nlibrary(plotly)\n\nset.seed(30250) # makes sure random numbers are reproducible"},{"path":"ggplot.html","id":"vartypes","chapter":"3 Data Visualisation","heading":"3.4 Common Variable Combinations","text":"Continuous variables properties can measure, like height. Discrete variables things can count, like number pets . Categorical variables can nominal, categories really order, like cats, dogs ferrets (even though ferrets obviously best). can also ordinal, clear order, distance categories something exactly equate, like points Likert rating scale.Different types visualisations good different types variables.Load pets dataset explore glimpse(pets) View(pets). simulated dataset one random factor (id), two categorical factors (pet, country) three continuous variables (score, age, weight).read ahead, come example type variable combination sketch types graphs best display data.1 categorical1 continuous2 categorical2 continuous1 categorical, 1 continuous3 continuous","code":"\ndata(\"pets\", package = \"reprores\")\n# if you don't have the reprores package, use:\n# pets <- read_csv(\"https://psyteachr.github.io/reprores/data/pets.csv\", col_types = \"cffiid\")\nglimpse(pets)## Rows: 800\n## Columns: 6\n## $ id      <chr> \"S001\", \"S002\", \"S003\", \"S004\", \"S005\", \"S006\", \"S007\", \"S008\"…\n## $ pet     <fct> dog, dog, dog, dog, dog, dog, dog, dog, dog, dog, dog, dog, do…\n## $ country <fct> UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK, UK…\n## $ score   <int> 90, 107, 94, 120, 111, 110, 100, 107, 106, 109, 85, 110, 102, …\n## $ age     <int> 6, 8, 2, 10, 4, 8, 9, 8, 6, 11, 5, 9, 1, 10, 7, 8, 1, 8, 5, 13…\n## $ weight  <dbl> 19.78932, 20.01422, 19.14863, 19.56953, 21.39259, 21.31880, 19…"},{"path":"ggplot.html","id":"basic-plots","chapter":"3 Data Visualisation","heading":"3.5 Basic Plots","text":"R basic plotting functions, difficult use aesthetically nice. can useful quick look data working script, though. function plot() usually defaults sensible type plot, depending whether arguments x y categorical, continuous, missing.\nFigure 3.1: plot() categorical x\n\nFigure 3.2: plot() categorical x continuous y\n\nFigure 3.3: plot() continuous x y\nfunction hist() creates quick histogram can see distribution data. can adjust many columns plotted argument breaks.\nFigure 3.4: hist()\n","code":"\nplot(x = pets$pet)\nplot(x = pets$pet, y = pets$score)\nplot(x = pets$age, y = pets$weight)\nhist(pets$score, breaks = 20)"},{"path":"ggplot.html","id":"ggplots","chapter":"3 Data Visualisation","heading":"3.6 GGplots","text":"functions nice quick visualisations, hard make pretty, publication-ready plots. package ggplot2 (loaded tidyverse) one common packages creating beautiful visualisations.ggplot2 creates plots using \"grammar graphics\" add geoms layers. can complex understand, powerful mental model works.start totally empty plot layer created ggplot() function arguments.\nFigure 3.5: plot base created ggplot()\nfirst argument ggplot() data table want plot. use pets data loaded . second argument mapping columns data table correspond properties plot, x-axis, y-axis, line colour linetype, point shape, object fill. mappings specified aes() function. Just adding ggplot function creates labels ranges x y axes. usually sensible default values, given data, learn change later.\nFigure 3.6: Empty ggplot x y labels\nPeople usually omit argument names just put aes() function directly second argument ggplot. also usually omit x y argument names aes() (name properties).Next can add \"geoms\", plot styles. literally add + symbol. can also add plot attributes, labels, change theme base font size.\nFigure 3.7: Violin plot country represented colour.\n","code":"\nggplot()\nmapping <- aes(x = pet, \n               y = score, \n               colour = country, \n               fill = country)\nggplot(data = pets, mapping = mapping)\nggplot(pets, aes(pet, score, colour = country, fill = country)) +\n  geom_violin(alpha = 0.5) +\n  labs(x = \"Pet type\",\n       y = \"Score on an Important Test\",\n       colour = \"Country of Origin\",\n       fill = \"Country of Origin\",\n       title = \"My first plot!\") +\n  theme_bw(base_size = 15)"},{"path":"ggplot.html","id":"common-plot-types","chapter":"3 Data Visualisation","heading":"3.7 Common Plot Types","text":"many geoms, can take different arguments customise appearance. learn common .","code":""},{"path":"ggplot.html","id":"geom_bar","chapter":"3 Data Visualisation","heading":"3.7.1 Bar plot","text":"Bar plots good categorical data want represent count.\nFigure 3.8: Bar plot\n","code":"\nggplot(pets, aes(pet)) +\n  geom_bar()"},{"path":"ggplot.html","id":"geom_density","chapter":"3 Data Visualisation","heading":"3.7.2 Density plot","text":"Density plots good one continuous variable, fairly large number observations.\nFigure 3.9: Density plot\ncan represent subsets variable assigning category variable argument group, fill, color.\nFigure 3.10: Grouped density plot\nTry changing alpha argument figure .","code":"\nggplot(pets, aes(score)) +\n  geom_density()\nggplot(pets, aes(score, fill = pet)) +\n  geom_density(alpha = 0.5)"},{"path":"ggplot.html","id":"geom_freqpoly","chapter":"3 Data Visualisation","heading":"3.7.3 Frequency polygons","text":"want y-axis represent count rather density, try geom_freqpoly().\nFigure 3.11: Frequency ploygon plot\nTry changing binwidth argument 10 1. figure right value?","code":"\nggplot(pets, aes(score, color = pet)) +\n  geom_freqpoly(binwidth = 5)"},{"path":"ggplot.html","id":"geom_histogram","chapter":"3 Data Visualisation","heading":"3.7.4 Histogram","text":"Histograms also good one continuous variable, work well many observations. Set binwidth control wide bar .\nFigure 3.12: Histogram\nHistograms ggplot look pretty bad unless set fill color.show grouped histograms, also probably want change default position argument.\nFigure 3.13: Grouped Histogram\nTry changing position argument \"identity\", \"fill\", \"dodge\", \"stack\".","code":"\nggplot(pets, aes(score)) +\n  geom_histogram(binwidth = 5, fill = \"white\", color = \"black\")\nggplot(pets, aes(score, fill=pet)) +\n  geom_histogram(binwidth = 5, alpha = 0.5, \n                 position = \"dodge\")"},{"path":"ggplot.html","id":"geom_col","chapter":"3 Data Visualisation","heading":"3.7.5 Column plot","text":"Column plots worst way represent grouped continuous data, also one common. data already aggregated (e.g., rows group columns mean standard error), can use geom_bar geom_col geom_errorbar directly. , can use function stat_summary calculate mean standard error send numbers appropriate geom plotting.\nFigure 3.14: Column plot\nTry changing values coord_cartesian. ?","code":"\nggplot(pets, aes(pet, score, fill=pet)) +\n  stat_summary(fun = mean, geom = \"col\", alpha = 0.5) + \n  stat_summary(fun.data = mean_se, geom = \"errorbar\",\n               width = 0.25) +\n  coord_cartesian(ylim = c(80, 120))"},{"path":"ggplot.html","id":"geom_boxplot","chapter":"3 Data Visualisation","heading":"3.7.6 Boxplot","text":"Boxplots great representing distribution grouped continuous variables. fix problems using bar/column plots continuous data.\nFigure 3.15: Box plot\n","code":"\nggplot(pets, aes(pet, score, fill=pet)) +\n  geom_boxplot(alpha = 0.5)"},{"path":"ggplot.html","id":"geom_violin","chapter":"3 Data Visualisation","heading":"3.7.7 Violin plot","text":"Violin pots like sideways, mirrored density plots. give even information boxplot distribution especially useful non-normal distributions.\nFigure 3.16: Violin plot\nTry changing quantile argument. Set vector numbers 0.1 0.9 steps 0.1.","code":"\nggplot(pets, aes(pet, score, fill=pet)) +\n  geom_violin(draw_quantiles = .5,\n              trim = FALSE, alpha = 0.5,)"},{"path":"ggplot.html","id":"vertical_intervals","chapter":"3 Data Visualisation","heading":"3.7.8 Vertical intervals","text":"Boxplots violin plots always map well onto inferential stats use mean. can represent mean standard error value can calculate., create table means standard errors two groups. learn calculate raw data chapter data wrangling. also create new object called gg sets base plot.trick can useful want represent data different ways. can add different geoms base plot without re-type base plot code.\nFigure 3.17: geom_crossbar()\n\nFigure 3.18: geom_errorbar()\n\nFigure 3.19: geom_linerange()\n\nFigure 3.20: geom_pointrange()\ncan also use function stats_summary calculate mean, standard error, value data display using geom.\nFigure 3.21: Vertical intervals stats_summary()\n","code":"\ndat <- tibble(\n  group = c(\"A\", \"B\"),\n  mean = c(10, 20),\n  se = c(2, 3)\n)\ngg <- ggplot(dat, aes(group, mean, \n                      ymin = mean-se, \n                      ymax = mean+se))\ngg + geom_crossbar()\ngg + geom_errorbar()\ngg + geom_linerange()\ngg + geom_pointrange()\nggplot(pets, aes(pet, score, color=pet)) +\n  stat_summary(fun.data = mean_se, geom = \"crossbar\") +\n  stat_summary(fun.min = function(x) mean(x) - sd(x),\n               fun.max = function(x) mean(x) + sd(x),\n               geom = \"errorbar\", width = 0) +\n  theme(legend.position = \"none\") # gets rid of the legend"},{"path":"ggplot.html","id":"geom_point","chapter":"3 Data Visualisation","heading":"3.7.9 Scatter plot","text":"Scatter plots good way represent relationship two continuous variables.\nFigure 3.22: Scatter plot using geom_point()\n","code":"\nggplot(pets, aes(age, score, color = pet)) +\n  geom_point()"},{"path":"ggplot.html","id":"geom_smooth","chapter":"3 Data Visualisation","heading":"3.7.10 Line graph","text":"often want represent relationship single line.\nFigure 3.23: Line plot using geom_smooth()\noptions method argument geom_smooth? might want use ?can plot functions linear y ~ x. code creates data table x 101 values -10 10. y x squared plus 3*x plus 1. probably recognise algebra quadratic equation. can set formula argument geom_smooth quadratic formula (y ~ x + (x^2)) fit quadratic function data.\nFigure 3.24: Fitting quadratic functions\n","code":"\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\")\nquad <- tibble(\n  x = seq(-10, 10, length.out = 101),\n  y = x^2 + 3*x + 1\n)\n\nggplot(quad, aes(x, y)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x + I(x^2), \n              method=\"lm\")"},{"path":"ggplot.html","id":"customisation","chapter":"3 Data Visualisation","heading":"3.8 Customisation","text":"","code":""},{"path":"ggplot.html","id":"custom-size","chapter":"3 Data Visualisation","heading":"3.8.1 Size and Position","text":"can change size, aspect ratio position plots R Markdown document setup chunk.can change defaults single image using chunk options.```{r fig-pet1, fig.width=10, fig.height=3, .width=\"100%\", fig.align=\"center\", fig.cap=\"10x3 inches 100% width centre aligned.\"}\nFigure 3.25: 10x3 inches 100% width centre aligned.\n```{r fig-pet2, fig.width=5, fig.height=3, .width=\"50%\", fig.align=\"left\", fig.cap=\"5x3 inches 50% width aligned left.\"}\nFigure 3.26: 5x3 inches 50% width aligned left.\n","code":"\nknitr::opts_chunk$set(\n  fig.width  = 8, # figures default to 8 inches wide\n  fig.height = 5, # figures default to 5 inches tall\n  fig.path   = 'images/', # figures saved in images directory\n  out.width = \"90%\", # images take up 90% of page width\n  fig.align = 'center' # centre images\n)\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y~x, method = lm)\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y~x, method = lm)"},{"path":"ggplot.html","id":"custom-labels","chapter":"3 Data Visualisation","heading":"3.8.2 Labels","text":"can set custom titles axis labels different ways.\nFigure 3.27: Set custom labels labs()\n\nFigure 3.28: Set custom labels individual functions\n","code":"\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\") +\n  labs(title = \"Pet score with Age\",\n       x = \"Age (in Years)\",\n       y = \"score Score\",\n       color = \"Pet Type\")\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\") +\n  ggtitle(\"Pet score with Age\") +\n  xlab(\"Age (in Years)\") +\n  ylab(\"score Score\") +\n  scale_color_discrete(name = \"Pet Type\")"},{"path":"ggplot.html","id":"custom-colours","chapter":"3 Data Visualisation","heading":"3.8.3 Colours","text":"can set custom values colour fill using functions like scale_colour_manual() scale_fill_manual(). Colours chapter Cookbook R many ways customise colour.\nFigure 3.29: Set custom colour\n","code":"\nggplot(pets, aes(pet, score, colour = pet, fill = pet)) +\n  geom_violin() +\n  scale_color_manual(values = c(\"darkgreen\", \"dodgerblue\", \"orange\")) +\n  scale_fill_manual(values = c(\"#CCFFCC\", \"#BBDDFF\", \"#FFCC66\"))"},{"path":"ggplot.html","id":"themes","chapter":"3 Data Visualisation","heading":"3.8.4 Themes","text":"GGplot comes several additional themes ability fully customise theme. Type ?theme console see full list. packages cowplot also custom themes. can add custom theme end ggplot object specify new base_size make default fonts lines larger smaller.\nFigure 3.30: Minimal theme 18-point base font size\ncomplicated, can fully customise theme theme(). can save object add end plots make style consistent. Alternatively, can set theme top script theme_set() apply subsequent ggplot plots.\nFigure 3.31: Custom theme\n","code":"\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\") +\n  theme_minimal(base_size = 18)\n# always start with a base theme that is closest to your desired theme\nvampire_theme <- theme_dark() +\n  theme(\n    rect = element_rect(fill = \"black\"),\n    panel.background = element_rect(fill = \"black\"),\n    text = element_text(size = 20, colour = \"white\"),\n    axis.text = element_text(size = 16, colour = \"grey70\"),\n    line = element_line(colour = \"white\", size = 2),\n    panel.grid = element_blank(),\n    axis.line = element_line(colour = \"white\"),\n    axis.ticks = element_blank(),\n    legend.position = \"top\"\n  )\n\ntheme_set(vampire_theme)\n\nggplot(pets, aes(age, score, color = pet)) +\n  geom_smooth(formula = y ~ x, method=\"lm\")"},{"path":"ggplot.html","id":"ggsave","chapter":"3 Data Visualisation","heading":"3.8.5 Save as file","text":"can save ggplot using ggsave(). saves last ggplot made, default, can specify plot want save assigned plot variable.can set width height plot. default units inches, can change units argument \"\", \"cm\", \"mm\".file type set filename suffix, \nspecifying argument device, can take following values:\n\"eps\", \"ps\", \"tex\", \"pdf\", \"jpeg\", \"tiff\", \"png\", \"bmp\", \"svg\" \"wmf\".","code":"\nbox <- ggplot(pets, aes(pet, score, fill=pet)) +\n  geom_boxplot(alpha = 0.5)\n\nviolin <- ggplot(pets, aes(pet, score, fill=pet)) +\n  geom_violin(alpha = 0.5)\n\nggsave(\"demog_violin_plot.png\", width = 5, height = 7)\n\nggsave(\"demog_box_plot.jpg\", plot = box, width = 5, height = 7)"},{"path":"ggplot.html","id":"combo_plots","chapter":"3 Data Visualisation","heading":"3.9 Combination Plots","text":"","code":""},{"path":"ggplot.html","id":"violinbox-plot","chapter":"3 Data Visualisation","heading":"3.9.1 Violinbox plot","text":"combination violin plot show shape distribution boxplot show median interquartile ranges can useful visualisation.\nFigure 3.32: Violin-box plot\nSet show.legend argument FALSE hide legend. x-axis already labels pet types.","code":"\nggplot(pets, aes(pet, score, fill = pet)) +\n  geom_violin(show.legend = FALSE) + \n  geom_boxplot(width = 0.2, fill = \"white\", \n               show.legend = FALSE)"},{"path":"ggplot.html","id":"violin-point-range-plot","chapter":"3 Data Visualisation","heading":"3.9.2 Violin-point-range plot","text":"can use stat_summary() superimpose point-range plot showing mean ± 1 SD. learn write functions lesson Iteration Functions.\nFigure 3.33: Point-range plot using stat_summary()\n","code":"\nggplot(pets, aes(pet, score, fill=pet)) +\n  geom_violin(trim = FALSE, alpha = 0.5) +\n  stat_summary(\n    fun = mean,\n    fun.max = function(x) {mean(x) + sd(x)},\n    fun.min = function(x) {mean(x) - sd(x)},\n    geom=\"pointrange\"\n  )"},{"path":"ggplot.html","id":"violin-jitter-plot","chapter":"3 Data Visualisation","heading":"3.9.3 Violin-jitter plot","text":"lot data points, good represent individually. can use geom_jitter .\nFigure 3.34: Violin-jitter plot\n","code":"\n# sample_n chooses 50 random observations from the dataset\nggplot(sample_n(pets, 50), aes(pet, score, fill=pet)) +\n  geom_violin(\n    trim = FALSE,\n    draw_quantiles = c(0.25, 0.5, 0.75), \n    alpha = 0.5\n  ) + \n  geom_jitter(\n    width = 0.15, # points spread out over 15% of available width\n    height = 0, # do not move position on the y-axis\n    alpha = 0.5, \n    size = 3\n  )"},{"path":"ggplot.html","id":"scatter-line-graph","chapter":"3 Data Visualisation","heading":"3.9.4 Scatter-line graph","text":"graph complicated, good also show individual data points behind line.\nFigure 3.35: Scatter-line plot\n","code":"\nggplot(sample_n(pets, 50), aes(age, weight, colour = pet)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method=\"lm\")"},{"path":"ggplot.html","id":"plot_grid","chapter":"3 Data Visualisation","heading":"3.9.5 Grid of plots","text":"can use patchwork package easily make grids different graphs. First, assign plot name.add plots together.\nFigure 3.36: Default grid plots\ncan use +, |, /, parentheses customise layout.\nFigure 3.37: Custom plot layout.\ncan alter plot layout control number widths plots per row column, add annotation.\nFigure 3.38: Plot annotation.\nCheck help plot_layout() plot_annotation()` see else can .","code":"\ngg <- ggplot(pets, aes(pet, score, colour = pet))\nnolegend <- theme(legend.position = 0)\n\nvp <- gg + geom_violin(alpha = 0.5) + nolegend +\n  ggtitle(\"Violin Plot\")\nbp <- gg + geom_boxplot(alpha = 0.5) + nolegend +\n  ggtitle(\"Box Plot\")\ncp <- gg + stat_summary(fun = mean, geom = \"col\", fill = \"white\") + nolegend +\n  ggtitle(\"Column Plot\")\ndp <- ggplot(pets, aes(score, colour = pet)) + \n  geom_density() + nolegend +\n  ggtitle(\"Density Plot\")\nvp + bp + cp + dp\n(vp | bp | cp) / dp\nvp + bp + cp + \n  plot_layout(nrow = 1, width = c(1,2,1)) +\n  plot_annotation(title = \"Pet Scores\",\n                  subtitle = \"Three plots visualising the same data\",\n                  tag_levels = \"a\")"},{"path":"ggplot.html","id":"overlap","chapter":"3 Data Visualisation","heading":"3.10 Overlapping Discrete Data","text":"","code":""},{"path":"ggplot.html","id":"reducing-opacity","chapter":"3 Data Visualisation","heading":"3.10.1 Reducing Opacity","text":"can deal overlapping data points (common using Likert scales) reducing opacity points. need use trial error adjust look right.\nFigure 3.39: Deal overlapping data using transparency\n","code":"\nggplot(pets, aes(age, score, colour = pet)) +\n  geom_point(alpha = 0.25) +\n  geom_smooth(formula = y ~ x, method=\"lm\")"},{"path":"ggplot.html","id":"geom_count","chapter":"3 Data Visualisation","heading":"3.10.2 Proportional Dot Plots","text":"can set size dot proportional number overlapping observations using geom_count().\nFigure 3.40: Deal overlapping data using geom_count()\nAlternatively, can transform data (learn data wrangling chapter) create count column use count set dot colour.\nFigure 3.41: Deal overlapping data using dot colour\nviridis package changes colour themes easier read people colourblindness print better greyscale. Viridis built ggplot2 since v3.0.0. uses scale_colour_viridis_c() scale_fill_viridis_c() continuous variables scale_colour_viridis_d() scale_fill_viridis_d() discrete variables.","code":"\nggplot(pets, aes(age, score, colour = pet)) +\n  geom_count()\npets %>%\n  group_by(age, score) %>%\n  summarise(count = n(), .groups = \"drop\") %>%\n  ggplot(aes(age, score, color=count)) +\n  geom_point(size = 2) +\n  scale_color_viridis_c()"},{"path":"ggplot.html","id":"overlapping-continuous-data","chapter":"3 Data Visualisation","heading":"3.11 Overlapping Continuous Data","text":"Even variables continuous, overplotting might obscure relationships lots data.\nFigure 3.42: Overplotted data\n","code":"\nggplot(pets, aes(age, score)) +\n  geom_point()"},{"path":"ggplot.html","id":"geom_density2d","chapter":"3 Data Visualisation","heading":"3.11.1 2D Density Plot","text":"Use geom_density2d() create contour map.\nFigure 3.43: Contour map geom_density2d()\ncan use geom_density2d_filled() create heatmap-style density plot.\nFigure 3.44: Heatmap-density plot\nTry geom_density2d_filled(n = 5, h = 10) instead. Play different values n h try guess .","code":"\nggplot(pets, aes(age, score)) +\n  geom_density2d()\nggplot(pets, aes(age, score)) +\n  geom_density2d_filled(n = 5, h = 10)"},{"path":"ggplot.html","id":"geom_bin2d","chapter":"3 Data Visualisation","heading":"3.11.2 2D Histogram","text":"Use geom_bin2d() create rectangular heatmap bin counts. Set binwidth x y dimensions capture box.\nFigure 3.45: Heatmap bin counts\n","code":"\nggplot(pets, aes(age, score)) +\n  geom_bin2d(binwidth = c(1, 5))"},{"path":"ggplot.html","id":"geom_hex","chapter":"3 Data Visualisation","heading":"3.11.3 Hexagonal Heatmap","text":"Use geomhex() create hexagonal heatmap bin counts. Adjust binwidth, xlim(), ylim() /figure dimensions make hexagons less stretched.\nFigure 3.46: Hexagonal heatmap bin counts\n","code":"\nggplot(pets, aes(age, score)) +\n  geom_hex(binwidth = c(1, 5))"},{"path":"ggplot.html","id":"geom_tile","chapter":"3 Data Visualisation","heading":"3.11.4 Correlation Heatmap","text":"included code creating correlation matrix table variables, need understand done yet. cover mutate() gather() functions dplyr tidyr lessons.correlation matrix correct (long) format, easy make heatmap using geom_tile().\nFigure 3.47: Heatmap using geom_tile()\n","code":"\nheatmap <- pets %>%\n  select_if(is.numeric) %>% # get just the numeric columns\n  cor() %>% # create the correlation matrix\n  as_tibble(rownames = \"V1\") %>% # make it a tibble\n  gather(\"V2\", \"r\", 2:ncol(.)) # wide to long (V2)\nggplot(heatmap, aes(V1, V2, fill=r)) +\n  geom_tile() +\n  scale_fill_viridis_c()"},{"path":"ggplot.html","id":"plotly","chapter":"3 Data Visualisation","heading":"3.12 Interactive Plots","text":"can use plotly package make interactive graphs. Just assign ggplot variable use function ggplotly().\nFigure 3.48: Interactive graph using plotly\nHover data points click legend items.","code":"\ndemog_plot <- ggplot(pets, aes(age, score, fill=pet)) +\n  geom_point() +\n  geom_smooth(formula = y~x, method = lm)\n\nggplotly(demog_plot)"},{"path":"ggplot.html","id":"glossary-ggplot","chapter":"3 Data Visualisation","heading":"3.13 Glossary","text":"","code":""},{"path":"ggplot.html","id":"exercises-ggplot","chapter":"3 Data Visualisation","heading":"3.14 Exercises","text":"Download exercises. See plots see plots look like (contain answer code). See answers attempted questions.","code":"\n# run this to access the exercise\nreprores::exercise(3)\n\n# run this to access the answers\nreprores::exercise(3, answers = TRUE)"},{"path":"data.html","id":"data","chapter":"4 Working with Data","heading":"4 Working with Data","text":"","code":""},{"path":"data.html","id":"ilo2","chapter":"4 Working with Data","heading":"4.1 Learning Objectives","text":"Load built-datasets (video)Import data CSV Excel files (video)Create data table (video)Understand use basic data types (video)Understand use basic container types (list, vector) (video)Use vectorized operations (video)able troubleshoot common data import problems (video)","code":""},{"path":"data.html","id":"resources2","chapter":"4 Working with Data","heading":"4.2 Resources","text":"Chapter 11: Data Import R Data ScienceRStudio Data Import Cheatsheet","code":""},{"path":"data.html","id":"setup2","chapter":"4 Working with Data","heading":"4.3 Setup","text":"","code":"\n# libraries needed for these examples\nlibrary(tidyverse)\nlibrary(reprores)"},{"path":"data.html","id":"data-tables","chapter":"4 Working with Data","heading":"4.4 Data tables","text":"","code":""},{"path":"data.html","id":"builtin","chapter":"4 Working with Data","heading":"4.4.1 Built-in data","text":"R comes built-datasets. packages, like tidyr reprores, also contain data. data() function lists datasets available package.Type name dataset console see data. Type ?smalldata console see dataset description.can also use data() function load dataset global environment.Always, always, always, look data created loaded table. Also look step transforms table. three main ways look tibble: print(), glimpse(), View().print() method can run explicitly, commonly called just typing variable name blank line. default print entire table, just first 10 rows. rare print data script; something usually sanity check, just console.look smalldata table made .function glimpse() gives sideways version tibble. useful table wide see columns. also tells data type column angled brackets column name. learn data types .way look table graphical spreadsheet-like version given View() (capital 'V'). can useful console, ever put one script create annoying pop-window user runs .\nNow can click smalldata environment pane open viewer looks bit like Excel.can get quick summary dataset summary() function.can even things like calculate difference means two columns.","code":"\n# lists datasets in reprores\ndata(package = \"reprores\")\nsmalldata\n# loads smalldata into the environment\ndata(\"smalldata\")\nsmalldata\nglimpse(smalldata)## Rows: 10\n## Columns: 4\n## $ id    <chr> \"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", \"S08\", \"S09\", \"…\n## $ group <chr> \"control\", \"control\", \"control\", \"control\", \"control\", \"exp\", \"e…\n## $ pre   <dbl> 98.46606, 104.39774, 105.13377, 92.42574, 123.53268, 97.48676, 8…\n## $ post  <dbl> 106.70508, 89.09030, 123.67230, 70.70178, 124.95526, 101.61697, …\nsummary(smalldata)##       id               group                pre              post       \n##  Length:10          Length:10          Min.   : 77.15   Min.   : 70.70  \n##  Class :character   Class :character   1st Qu.: 93.57   1st Qu.: 92.22  \n##  Mode  :character   Mode  :character   Median : 97.98   Median :107.76  \n##                                        Mean   : 98.57   Mean   :103.79  \n##                                        3rd Qu.:103.88   3rd Qu.:121.19  \n##                                        Max.   :123.53   Max.   :126.30\npre_mean <- mean(smalldata$pre)\npost_mean <- mean(smalldata$post)\npost_mean - pre_mean## [1] 5.223055"},{"path":"data.html","id":"import_data","chapter":"4 Working with Data","heading":"4.4.2 Importing data","text":"Built-data nice examples, probably interested data. many different types files might work data analysis. different file types usually distinguished three letter extension following period end file name. examples different types files functions use read write .double colon means function right comes package left, readr::read_csv() refers read_csv() function readr package, readxl::read_excel() refers function read_excel() package readxl. function rio::import() rio package read almost type data file, including SPSS Matlab. Check help ?rio::import see full list.can get directory data files used class tutorials exercises following code, create directory called \"data\" project directory. Alternatively, can download zip file datasets.Probably common file type encounter .csv (comma-separated values). name suggests, CSV file distinguishes values go variable separating commas, text values sometimes enclosed double quotes. first line file usually provides names variables.example, first lines CSV containing personality scores:six variables dataset, names given first line file: subj_id, O, C, E, , N. can see values variables given order, separated commas, subsequent line file.read CSV files, best practice use readr::read_csv() function. readr package automatically loaded part tidyverse package, using almost every script. Note normally want store result read_csv() function object, :read_csv() read_tsv() functions give information data just read can check column names data types. now, enough know col_double() refers columns numbers col_character() refers columns words. learn toroubleshooting section fix function guesses wrong data type.loaded, can view data using data viewer. upper right hand window RStudio, Environment tab, see object csv_data listed.click View icon, bring table view data loaded top left pane RStudio. allows check data loaded properly. can close tab done looking , remove object.","code":"\npsyteachr::getdata()```\nsubj_id,O,C,E,A,N\nS01,4.428571429,4.5,3.333333333,5.142857143,1.625\nS02,5.714285714,2.9,3.222222222,3,2.625\nS03,5.142857143,2.8,6,3.571428571,2.5\nS04,3.142857143,5.2,1.333333333,1.571428571,3.125\nS05,5.428571429,4.4,2.444444444,4.714285714,1.625\n```\ncsv_data <- read_csv(\"data/5factor.csv\")## \n## ── Column specification ────────────────────────────────────────────────────────\n## cols(\n##   subj_id = col_character(),\n##   O = col_double(),\n##   C = col_double(),\n##   E = col_double(),\n##   A = col_double(),\n##   N = col_double()\n## )\ntsv_data <- read_tsv(\"data/5factor.txt\")\nxls_data <- readxl::read_xls(\"data/5factor.xls\")\n# you can load sheets from excel files by name or number\nrep_data <- readxl::read_xls(\"data/5factor.xls\", sheet = \"replication\")\nspss_data <- rio::import(\"data/5factor.sav\")"},{"path":"data.html","id":"creating-data","chapter":"4 Working with Data","heading":"4.4.3 Creating data","text":"creating data table scratch, can use tibble::tibble() function, type data right . tibble package part tidyverse package loaded start chapter.create small table names three Avatar characters bending type. tibble() function takes arguments names want columns . values vectors list column values order.know value one cells, can enter NA, Sokka bending ability. values column , can just enter one value copied row.","code":"\navatar <- tibble(\n  name = c(\"Katara\", \"Toph\", \"Sokka\"),\n  bends = c(\"water\", \"earth\", NA),\n  friendly = TRUE\n)\n\n# print it\navatar"},{"path":"data.html","id":"writing-data","chapter":"4 Working with Data","heading":"4.4.4 Writing Data","text":"data want save CSV file, use readr::write_csv(), follows.save data CSV format working directory.Create new table called family first name, last name, age family members.Save CSV file called \"family.csv\".Clear object environment restarting R code remove(family).Load data back view .working tabular data lot class, tabular data made vectors, group together data basic data type. following sections explain terminology help understand functions learning process analyse data.","code":"\nwrite_csv(avatar, \"avatar.csv\")"},{"path":"data.html","id":"data_types","chapter":"4 Working with Data","heading":"4.5 Basic data types","text":"Data can numbers, words, true/false values combinations . order understand later concepts, useful basic understanding data types R: numeric, character, logical also specific data type called factor, probably give headache sooner later, can ignore now.","code":""},{"path":"data.html","id":"numeric-data","chapter":"4 Working with Data","heading":"4.5.1 Numeric data","text":"real numbers numeric data types (imaginary numbers \"complex\"). two types numeric data, integer double. Integers whole numbers, like -1, 0 1. Doubles numbers can fractional amounts. just type plain number 10, stored double, even decimal point. want exact integer, use L suffix (10L).ever want know data type something, use typeof function.want know something numeric (double integer), can use function .numeric() tell numeric (TRUE) (FALSE).","code":"\ntypeof(10)   # double\ntypeof(10.0) # double\ntypeof(10L)  # integer\ntypeof(10i)  # complex## [1] \"double\"\n## [1] \"double\"\n## [1] \"integer\"\n## [1] \"complex\"\nis.numeric(10L)\nis.numeric(10.0)\nis.numeric(\"Not a number\")## [1] TRUE\n## [1] TRUE\n## [1] FALSE"},{"path":"data.html","id":"character-data","chapter":"4 Working with Data","heading":"4.5.2 Character data","text":"Character strings text quotation marks.can include quotes, escape using backslash signal quote meant end string.","code":"\ntypeof(\"This is a character string\")\ntypeof('You can use double or single quotes')## [1] \"character\"\n## [1] \"character\"\nmy_string <- \"The instructor said, \\\"R is cool,\\\" and the class agreed.\"\ncat(my_string) # cat() prints the arguments## The instructor said, \"R is cool,\" and the class agreed."},{"path":"data.html","id":"logical-data","chapter":"4 Working with Data","heading":"4.5.3 Logical Data","text":"Logical data (also sometimes called \"boolean\" values) one two values: true false. R, always write uppercase: TRUE FALSE.compare two values operator, checking see 10 greater 5, resulting value logical.might also see logical values abbreviated T F, 0 1. can cause problems road, always spell whole thing.data types :100 integerdoublecharacterlogicalfactor100L integerdoublecharacterlogicalfactor\"100\" integerdoublecharacterlogicalfactor100.0 integerdoublecharacterlogicalfactor-100L integerdoublecharacterlogicalfactorfactor(100) integerdoublecharacterlogicalfactorTRUE integerdoublecharacterlogicalfactor\"TRUE\" integerdoublecharacterlogicalfactorFALSE integerdoublecharacterlogicalfactor1 == 2 integerdoublecharacterlogicalfactor","code":"\nclass(TRUE)\nclass(FALSE)## [1] \"logical\"\n## [1] \"logical\"\nis.logical(10 > 5)## [1] TRUE"},{"path":"data.html","id":"containers","chapter":"4 Working with Data","heading":"4.6 Basic container types","text":"Individual data values can grouped together containers. main types containers work vectors, lists, data tables.","code":""},{"path":"data.html","id":"vectors","chapter":"4 Working with Data","heading":"4.6.1 Vectors","text":"vector R like vector mathematics: set ordered elements. elements vector must data type (numeric, character, logical). can create vector enclosing elements function c().happens mix types? class variable mixed?mix data types vector; elements vector must data type. mix , R \"coerce\" . mix doubles integers, integers changed doubles. mix characters numeric types, numbers coerced characters, 10 turn \"10\".","code":"\n## put information into a vector using c(...)\nc(1, 2, 3, 4)\nc(\"this\", \"is\", \"cool\")\n1:6 # shortcut to make a vector of all integers x:y## [1] 1 2 3 4\n## [1] \"this\" \"is\"   \"cool\"\n## [1] 1 2 3 4 5 6\nmixed <- c(2, \"good\", 2L, \"b\", TRUE)"},{"path":"data.html","id":"selecting-values-from-a-vector","chapter":"4 Working with Data","heading":"4.6.1.1 Selecting values from a vector","text":"wanted pick specific values vector position, can use square brackets (extract operator, []) vector.can select one value vector putting vector numbers inside square brackets. example, can select 18th, 19th, 20th, 21st, 4th, 9th 15th letter built-vector LETTERS (gives uppercase letters Latin alphabet).Can decode secret message?can also create 'named' vectors, element name. example:can access elements name using character vector within square brackets. can put order want, can repeat elements:can get vector names using names() function, can set change using something like names(vec2) <- c(\"n1\", \"n2\", \"n3\").Another way access elements using logical vector within square brackets. pull elements vector corresponding element logical vector TRUE. logical vector length original, repeat. can find long vector using length() function.","code":"\nvalues <- c(10, 20, 30, 40, 50)\nvalues[2] # selects the second value## [1] 20\nword <- c(18, 19, 20, 21, 4, 9, 15)\nLETTERS[word]## [1] \"R\" \"S\" \"T\" \"U\" \"D\" \"I\" \"O\"\nsecret <- c(14, 5, 22, 5, 18, 7, 15, 14, 14, 1, 7, 9, 22, 5, 25, 15, 21, 21, 16)\nvec <- c(first = 77.9, second = -13.2, third = 100.1)\nvec##  first second  third \n##   77.9  -13.2  100.1\nvec[c(\"third\", \"second\", \"second\")]##  third second second \n##  100.1  -13.2  -13.2\nlength(LETTERS)\nLETTERS[c(TRUE, FALSE)]## [1] 26\n##  [1] \"A\" \"C\" \"E\" \"G\" \"I\" \"K\" \"M\" \"O\" \"Q\" \"S\" \"U\" \"W\" \"Y\""},{"path":"data.html","id":"rep_seq","chapter":"4 Working with Data","heading":"4.6.1.2 Repeating Sequences","text":"useful tricks save typing creating vectors.command x:y : operator give sequence number starting x, going y increments 1.want create sequence something integer steps? can use seq() function. Look examples work arguments .want repeat vector many times? either type (painful) use rep() function, can repeat vectors different ways.rep() function useful create vector logical values (TRUE/FALSE 1/0) select values another vector.","code":"\n1:10\n15.3:20.5\n0:-10##  [1]  1  2  3  4  5  6  7  8  9 10\n## [1] 15.3 16.3 17.3 18.3 19.3 20.3\n##  [1]   0  -1  -2  -3  -4  -5  -6  -7  -8  -9 -10\nseq(from = -1, to = 1, by = 0.2)\nseq(0, 100, length.out = 11)\nseq(0, 10, along.with = LETTERS)##  [1] -1.0 -0.8 -0.6 -0.4 -0.2  0.0  0.2  0.4  0.6  0.8  1.0\n##  [1]   0  10  20  30  40  50  60  70  80  90 100\n##  [1]  0.0  0.4  0.8  1.2  1.6  2.0  2.4  2.8  3.2  3.6  4.0  4.4  4.8  5.2  5.6\n## [16]  6.0  6.4  6.8  7.2  7.6  8.0  8.4  8.8  9.2  9.6 10.0\nrep(0, 10)                      # ten zeroes\nrep(c(1L, 3L), times = 7)       # alternating 1 and 3, 7 times\nrep(c(\"A\", \"B\", \"C\"), each = 2) # A to C, 2 times each##  [1] 0 0 0 0 0 0 0 0 0 0\n##  [1] 1 3 1 3 1 3 1 3 1 3 1 3 1 3\n## [1] \"A\" \"A\" \"B\" \"B\" \"C\" \"C\"\n# Get subject IDs in the pattern Y Y N N ...\nsubject_ids <- 1:40\nyynn <- rep(c(TRUE, FALSE), each = 2, \n            length.out = length(subject_ids))\nsubject_ids[yynn]##  [1]  1  2  5  6  9 10 13 14 17 18 21 22 25 26 29 30 33 34 37 38"},{"path":"data.html","id":"vectorized_ops","chapter":"4 Working with Data","heading":"4.6.1.3 Vectorized Operations","text":"R performs calculations vectors special way. look example using \\(z\\)-scores. \\(z\\)-score deviation score(score minus mean) divided standard deviation. say set four IQ scores.want subtract mean four scores, just use following code:subtracts 100 element vector. R automatically assumes wanted ; called vectorized operation makes possible express operations efficiently.calculate \\(z\\)-scores use formula:\\(z = \\frac{X - \\mu}{\\sigma}\\)X scores, \\(\\mu\\) mean, \\(\\sigma\\) standard deviation. can expression formula R follows:can see computed four \\(z\\)-scores single line code. later chapters, use vectorised operations process data, reverse-scoring questionnaire items.","code":"\n## example IQ scores: mu = 100, sigma = 15\niq <- c(86, 101, 127, 99)\niq - 100## [1] -14   1  27  -1\n## z-scores\n(iq - 100) / 15## [1] -0.93333333  0.06666667  1.80000000 -0.06666667"},{"path":"data.html","id":"lists","chapter":"4 Working with Data","heading":"4.6.2 Lists","text":"Recall vectors can contain data one type. want store collection data different data types? purpose use list. Define list using list() function.can refer elements list using square brackets like vector, can also use dollar sign notation ($) list items names.Explore 5 ways shown extract value list. data type object? difference single double brackets? one dollar sign?","code":"\ndata_types <- list(\n  double = 10.0,\n  integer = 10L,\n  character = \"10\",\n  logical = TRUE\n)\n\nstr(data_types) # str() prints lists in a condensed format## List of 4\n##  $ double   : num 10\n##  $ integer  : int 10\n##  $ character: chr \"10\"\n##  $ logical  : logi TRUE\ndata_types$logical## [1] TRUE\nbracket1 <- data_types[1]\nbracket2 <- data_types[[1]]\nname1    <- data_types[\"double\"]\nname2    <- data_types[[\"double\"]]\ndollar   <- data_types$double"},{"path":"data.html","id":"tables-data","chapter":"4 Working with Data","heading":"4.6.3 Tables","text":"built-, imported, created data tabular data, data arranged form table.Tabular data structures allow collection data different types (characters, integers, logical, etc.) subject constraint \"column\" table (element list) must number elements. base R version table called data.frame, 'tidyverse' version called tibble. Tibbles far easier work , using . learn differences two data structures, see vignette(\"tibble\").Tabular data becomes especially important talk tidy data chapter 4, consists set simple principles structuring data.","code":""},{"path":"data.html","id":"creating-a-table","chapter":"4 Working with Data","heading":"4.6.3.1 Creating a table","text":"learned create table importing Excel CSV file, creating table scratch using tibble() function. can also use tibble::tribble() function create table row, rather column. start listing column names, preceded tilde (~), list values column, row row, separated commas (forget comma end row). method can easier data, let use shortcuts, like setting values column value repeating sequence.","code":"\n# by column using tibble\navatar_by_col <- tibble(\n  name = c(\"Katara\", \"Toph\", \"Sokka\", \"Azula\"),\n  bends = c(\"water\", \"earth\", NA, \"fire\"),\n  friendly = rep(c(TRUE, FALSE), c(3, 1))\n)\n\n# by row using tribble\navatar_by_row <- tribble(\n  ~name,    ~bends, ~friendly,\n  \"Katara\", \"water\",       TRUE,\n  \"Toph\",   \"earth\",       TRUE,\n  \"Sokka\",  NA,            TRUE,\n  \"Azula\",  \"fire\",        FALSE\n)"},{"path":"data.html","id":"table-info","chapter":"4 Working with Data","heading":"4.6.3.2 Table info","text":"can get information table using functions ncol() (number columns), nrow() (number rows), dim() (number rows number columns), name() (column names).","code":"\nnrow(avatar) # how many rows?\nncol(avatar) # how many columns?\ndim(avatar)  # what are the table dimensions?\nnames(avatar) # what are the column names?## [1] 3\n## [1] 3\n## [1] 3 3\n## [1] \"name\"     \"bends\"    \"friendly\""},{"path":"data.html","id":"row-col-access","chapter":"4 Working with Data","heading":"4.6.3.3 Accessing rows and columns","text":"various ways accessing specific columns rows table. ones base R useful know , learning easier (readable) ways tidyr dplyr lessons. Examples base R accessing functions provided reference, since might see people's scripts.","code":"\nkatara     <- avatar[1, ] # first row\ntype       <- avatar[, 2] # second column (bends)\nbenders    <- avatar[c(1, 2), ] # selected rows (by number)\nbends_name <- avatar[, c(\"bends\", \"name\")] # selected columns (by name)\nfriendly   <- avatar$friendly  # by column name"},{"path":"data.html","id":"troubleshooting","chapter":"4 Working with Data","heading":"4.7 Troubleshooting","text":"import data guesses wrong column type? common reason numeric column non-numbers somewhere. Maybe someone wrote note otherwise numeric column. Columns one data type, characters, whole column converted character strings, numbers like 1.2 get represented \"1.2\", cause weird errors like \"100\" < \"9\" == TRUE. can catch looking output read_csv() using glimpse() check data.data directory created reprores::getdata() contains file called \"mess.csv\". try loading dataset.get warning many parsing errors mess just single column word \"junk\". View file data/mess.csv clicking File pane, choosing \"View File\". first 10 lines. went wrong?First, file starts note: \"messy dataset\". want skip first two lines. can argument skip read_csv().OK, little better, table still serious mess several ways:junk column needorder integer columngood logical columngood uses kinds different ways record TRUE FALSE valuesmin_max contains two pieces numeric information, character columndate date columnWe'll learn deal mess chapters tidy data data wrangling, can fix things setting col_types argument read_csv() specify column types two columns guessed wrong skip \"junk\" column. argument col_types takes list name item list column name value table . can use function, like col_double() abbreviation, like \"l\". Omitted column names guessed.get message \"1 parsing failure\" run . Warnings look scary first, always start reading message. table tells row (2) column (order) error found , kind data expected (integer), actual value (missing). specifically tell read_csv() import column integer, characters column produce warning like recorded NA. can manually set missing values recorded na argument.Now order integer \"missing\" now NA, good logical value, 0 F converted FALSE 1 T converted TRUE, date date type (adding leading zeros day). learn later chapters fix problems.","code":"\nmess <- read_csv(\"data/mess.csv\")## \n## ── Column specification ────────────────────────────────────────────────────────\n## cols(\n##   `This is my messy dataset` = col_character()\n## )## Warning: 27 parsing failures.\n## row col  expected    actual            file\n##   1  -- 1 columns 7 columns 'data/mess.csv'\n##   2  -- 1 columns 7 columns 'data/mess.csv'\n##   3  -- 1 columns 7 columns 'data/mess.csv'\n##   4  -- 1 columns 7 columns 'data/mess.csv'\n##   5  -- 1 columns 7 columns 'data/mess.csv'\n## ... ... ......... ......... ...............\n## See problems(...) for more details.This is my messy dataset\n\njunk,order,score,letter,good,min_max,date\njunk,1,-1,a,1,1 - 2,2020-01-1\n\njunk,missing,0.72,b,1,2 - 3,2020-01-2\n\njunk,3,-0.62,c,FALSE,3 - 4,2020-01-3\n\njunk,4,2.03,d,T,4 - 5,2020-01-4\nmess <- read_csv(\"data/mess.csv\", skip = 2)## \n## ── Column specification ────────────────────────────────────────────────────────\n## cols(\n##   junk = col_character(),\n##   order = col_character(),\n##   score = col_double(),\n##   letter = col_character(),\n##   good = col_character(),\n##   min_max = col_character(),\n##   date = col_character()\n## )\nmess\n# omitted values are guessed\n# ?col_date for format options\nct <- list(\n  junk = \"-\", # skip this column\n  order = \"i\",\n  good = \"l\",\n  date = col_date(format = \"%Y-%m-%d\")\n)\n\ntidier <- read_csv(\"data/mess.csv\", \n                   skip = 2,\n                   col_types = ct)## Warning: 1 parsing failure.\n## row   col   expected  actual            file\n##   2 order an integer missing 'data/mess.csv'\ntidiest <- read_csv(\"data/mess.csv\", \n                   skip = 2,\n                   na = \"missing\",\n                   col_types = ct)\ntidiest"},{"path":"data.html","id":"glossary-data","chapter":"4 Working with Data","heading":"4.8 Glossary","text":"","code":""},{"path":"data.html","id":"exercises-data","chapter":"4 Working with Data","heading":"4.9 Exercises","text":"Download exercises. See answers attempted questions.","code":"\n# run this to access the exercise\nreprores::exercise(4)\n\n# run this to access the answers\nreprores::exercise(4, answers = TRUE)"},{"path":"joins.html","id":"joins","chapter":"5 Data Relations","heading":"5 Data Relations","text":"","code":""},{"path":"joins.html","id":"ilo-joins","chapter":"5 Data Relations","heading":"5.1 Learning Objectives","text":"able use 4 mutating join verbs: (video)\nleft_join()\nright_join()\ninner_join()\nfull_join()\nleft_join()right_join()inner_join()full_join()able use 2 filtering join verbs: (video)\nsemi_join()\nanti_join()\nsemi_join()anti_join()able use 2 binding join verbs: (video)\nbind_rows()\nbind_cols()\nbind_rows()bind_cols()able use 3 set operations: (video)\nintersect()\nunion()\nsetdiff()\nintersect()union()setdiff()","code":""},{"path":"joins.html","id":"resources6","chapter":"5 Data Relations","heading":"5.2 Resources","text":"Chapter 13: Relational Data R Data ScienceCheatsheet dplyr join functionsLecture slides dplyr two-table verbs","code":""},{"path":"joins.html","id":"setup-joins","chapter":"5 Data Relations","heading":"5.3 Setup","text":"","code":"\n# libraries needed\nlibrary(tidyverse)\nlibrary(reprores)"},{"path":"joins.html","id":"data-1","chapter":"5 Data Relations","heading":"5.4 Data","text":"First, create two small data tables.subject id, gender age subjects 1-5. Age gender missing subject 3.exp subject id score experiment. subjects missing, completed twice, subject table.","code":"\nsubject <- tibble(\n  id = 1:5,\n  gender = c(\"m\", \"m\", NA, \"nb\", \"f\"),\n  age = c(19, 22, NA, 19, 18)\n)\nexp <- tibble(\n  id = c(2, 3, 4, 4, 5, 5, 6, 6, 7),\n  score = c(10, 18, 21, 23, 9, 11, 11, 12, 3)\n)"},{"path":"joins.html","id":"mutating-joins","chapter":"5 Data Relations","heading":"5.5 Mutating Joins","text":"Mutating joins act like mutate() function add new columns one table based values another table.mutating joins basic syntax:****_join(x, y, = NULL, suffix = c(\".x\", \".y\")x = first (left) tabley = second (right) tableby = columns match . leave blank, match columns names two tables.suffix = columns name two tables, joining , get suffix make unambiguous. defaults \".x\" \".y\", can change something meaningful.can leave argument matching columns name, good practice always specify code robust changes loaded data.","code":""},{"path":"joins.html","id":"left_join","chapter":"5 Data Relations","heading":"5.5.1 left_join()","text":"\nFigure 5.1: Left Join\nleft_join keeps data first (left) table joins anything matches second (right) table. right table one match row right table, one row joined table (see ids 4 5).\nFigure 5.2: Left Join (reversed)\norder tables swapped , result rows exp table joined matching rows subject table.","code":"\nleft_join(subject, exp, by = \"id\")\nleft_join(exp, subject, by = \"id\")"},{"path":"joins.html","id":"right_join","chapter":"5 Data Relations","heading":"5.5.2 right_join()","text":"\nFigure 5.3: Right Join\nright_join keeps data second (right) table joins anything matches first (left) table.table information left_join(exp, subject, = \"id\"), columns different order (left table, right table).","code":"\nright_join(subject, exp, by = \"id\")"},{"path":"joins.html","id":"inner_join","chapter":"5 Data Relations","heading":"5.5.3 inner_join()","text":"\nFigure 5.4: Inner Join\ninner_join returns rows match table.","code":"\ninner_join(subject, exp, by = \"id\")"},{"path":"joins.html","id":"full_join","chapter":"5 Data Relations","heading":"5.5.4 full_join()","text":"\nFigure 5.5: Full Join\nfull_join lets join rows two tables keeping information tables. row match table, table's column values set NA.","code":"\nfull_join(subject, exp, by = \"id\")"},{"path":"joins.html","id":"filtering-joins","chapter":"5 Data Relations","heading":"5.6 Filtering Joins","text":"Filtering joins act like filter() function remove rows data one table based values another table. result filtering join contain rows left table number fewer rows left table.","code":""},{"path":"joins.html","id":"semi_join","chapter":"5 Data Relations","heading":"5.6.1 semi_join()","text":"\nFigure 5.6: Semi Join\nsemi_join returns rows left table matching values right table, keeping just columns left table.Unlike inner join, semi join never duplicate rows left table one matching row right table.\nFigure 5.7: Semi Join (Reversed)\nOrder matters semi join.","code":"\nsemi_join(subject, exp, by = \"id\")\nsemi_join(exp, subject, by = \"id\")"},{"path":"joins.html","id":"anti_join","chapter":"5 Data Relations","heading":"5.6.2 anti_join()","text":"\nFigure 5.8: Anti Join\nanti_join return rows left table matching values right table, keeping just columns left table.\nFigure 5.9: Anti Join (Reversed)\nOrder matters anti join.","code":"\nanti_join(subject, exp, by = \"id\")\nanti_join(exp, subject, by = \"id\")"},{"path":"joins.html","id":"binding-joins","chapter":"5 Data Relations","heading":"5.7 Binding Joins","text":"Binding joins bind one table another adding rows columns together.","code":""},{"path":"joins.html","id":"bind_rows","chapter":"5 Data Relations","heading":"5.7.1 bind_rows()","text":"can combine rows two tables bind_rows.add subject data subjects 6-9 bind original subject table.columns just names, order. columns differ two tables just NA values entries table.row duplicated two tables (like id 5 ), row also duplicated resulting table. tables exact columns, can use union() (see ) avoid duplicates.","code":"\nnew_subjects <- tibble(\n  id = 6:9,\n  gender = c(\"nb\", \"m\", \"f\", \"f\"),\n  age = c(19, 16, 20, 19)\n)\n\nbind_rows(subject, new_subjects)\nnew_subjects <- tibble(\n  id = 5:9,\n  age = c(18, 19, 16, 20, 19),\n  gender = c(\"f\", \"nb\", \"m\", \"f\", \"f\"),\n  new = c(1,2,3,4,5)\n)\n\nbind_rows(subject, new_subjects)"},{"path":"joins.html","id":"bind_cols","chapter":"5 Data Relations","heading":"5.7.2 bind_cols()","text":"can merge two tables number rows using bind_cols. useful two tables rows exact order. advantage left join tables IDs join rely solely order.","code":"\nnew_info <- tibble(\n  colour = c(\"red\", \"orange\", \"yellow\", \"green\", \"blue\")\n)\n\nbind_cols(subject, new_info)"},{"path":"joins.html","id":"set-operations","chapter":"5 Data Relations","heading":"5.8 Set Operations","text":"Set operations compare two tables return rows match (intersect), either table (union), one table (setdiff).","code":""},{"path":"joins.html","id":"intersect","chapter":"5 Data Relations","heading":"5.8.1 intersect()","text":"intersect() returns rows two tables match exactly. columns order.forgotten load dplyr tidyverse, base R also intersect() function. error message can confusing looks something like :","code":"\nnew_subjects <- tibble(\n  id = seq(4, 9),\n  age = c(19, 18, 19, 16, 20, 19),\n  gender = c(\"f\", \"f\", \"m\", \"m\", \"f\", \"f\")\n)\n\nintersect(subject, new_subjects)\nbase::intersect(subject, new_subjects)## Error: Must subset rows with a valid subscript vector.\n## ℹ Logical subscripts must match the size of the indexed input.\n## x Input has size 6 but subscript `!duplicated(x, fromLast = fromLast, ...)` has size 0."},{"path":"joins.html","id":"union","chapter":"5 Data Relations","heading":"5.8.2 union()","text":"union() returns rows tables, removing duplicate rows.forgotten load dplyr tidyverse, base R also union() function. usually get error message, output expect.","code":"\nunion(subject, new_subjects)\nbase::union(subject, new_subjects)## [[1]]\n## [1] 1 2 3 4 5\n## \n## [[2]]\n## [1] \"m\"  \"m\"  NA   \"nb\" \"f\" \n## \n## [[3]]\n## [1] 19 22 NA 19 18\n## \n## [[4]]\n## [1] 4 5 6 7 8 9\n## \n## [[5]]\n## [1] 19 18 19 16 20 19\n## \n## [[6]]\n## [1] \"f\" \"f\" \"m\" \"m\" \"f\" \"f\""},{"path":"joins.html","id":"setdiff","chapter":"5 Data Relations","heading":"5.8.3 setdiff()","text":"setdiff returns rows first table, second table.Order matters setdiff.forgotten load dplyr tidyverse, base R also setdiff() function. usually get error message, output might expect base R setdiff() expects columns order, id 5 registers different two tables.","code":"\nsetdiff(subject, new_subjects)\nsetdiff(new_subjects, subject)\nbase::setdiff(subject, new_subjects)"},{"path":"joins.html","id":"glossary-joins","chapter":"5 Data Relations","heading":"5.9 Glossary","text":"","code":""},{"path":"joins.html","id":"exercises-joins","chapter":"5 Data Relations","heading":"5.10 Exercises","text":"Download exercises. See answers attempted questions.","code":"\n# run this to access the exercise\nreprores::exercise(5)\n\n# run this to access the answers\nreprores::exercise(5, answers = TRUE)"},{"path":"tidyr.html","id":"tidyr","chapter":"6 Tidy Data","heading":"6 Tidy Data","text":"","code":""},{"path":"tidyr.html","id":"ilo-tidyr","chapter":"6 Tidy Data","heading":"6.1 Learning Objectives","text":"","code":""},{"path":"tidyr.html","id":"basic-2","chapter":"6 Tidy Data","heading":"6.1.1 Basic","text":"Understand concept tidy data (video)able convert long wide formats using pivot functions (video)\npivot_longer()\npivot_wider()\npivot_longer()pivot_wider()able use 4 basic tidyr verbs (video)\ngather()\nseparate()\nspread()\nunite()\ngather()separate()spread()unite()able chain functions using pipes (video)","code":""},{"path":"tidyr.html","id":"advanced","chapter":"6 Tidy Data","heading":"6.1.2 Advanced","text":"able use regular expressions separate complex columns","code":""},{"path":"tidyr.html","id":"resources-tidyr","chapter":"6 Tidy Data","heading":"6.2 Resources","text":"Tidy DataChapter 12: Tidy Data R Data ScienceChapter 18: Pipes R Data ScienceData wrangling cheat sheet","code":""},{"path":"tidyr.html","id":"setup-tidyr","chapter":"6 Tidy Data","heading":"6.3 Setup","text":"","code":"\n# libraries needed\nlibrary(tidyverse)\nlibrary(reprores)\n\nset.seed(8675309) # makes sure random numbers are reproducible"},{"path":"tidyr.html","id":"tidy-data","chapter":"6 Tidy Data","heading":"6.4 Tidy Data","text":"","code":""},{"path":"tidyr.html","id":"three-rules","chapter":"6 Tidy Data","heading":"6.4.1 Three Rules","text":"variable must columnEach observation must rowEach value must cellThis table three observations per row total_meanRT column contains two values.Table 6.1: Untidy tableThis tidy version.Table 6.1: Tidy table","code":""},{"path":"tidyr.html","id":"wide_long","chapter":"6 Tidy Data","heading":"6.4.2 Wide versus long","text":"Data tables can wide format long format (sometimes mix two). Wide data observations one subject row, long data observation separate row. often need convert formats different types analyses data processing.Imagine study subject completes questionnaire three items. answer observation subject. probably familiar data like wide format, subject id one column, three item responses column.Table 6.2: Wide dataThe data can represented long format creating new column specifies item observation new column specifies value observation.Table 6.3: Long dataCreate long version following table.answer need column headers order.","code":""},{"path":"tidyr.html","id":"pivot","chapter":"6 Tidy Data","heading":"6.5 Pivot Functions","text":"pivot functions allow transform data table wide long long wide one step.","code":""},{"path":"tidyr.html","id":"load-data","chapter":"6 Tidy Data","heading":"6.5.1 Load Data","text":"used dataset personality reprores package (download data personality.csv). data 5-factor (personality) personality questionnaire. question labelled domain (Op = openness, Co = conscientiousness, Ex = extroversion, Ag = agreeableness, Ne = neuroticism) question number.","code":"\ndata(\"personality\", package = \"reprores\")"},{"path":"tidyr.html","id":"pivot_longer","chapter":"6 Tidy Data","heading":"6.5.2 pivot_longer()","text":"pivot_longer() converts wide data table long format converting headers specified columns values new columns, combining values columns new condensed column.cols refers columns want make long can refer names, like col1, col2, col3, col4 col1:col4 numbers, like 8, 9, 10 8:10.names_to want call new columns gathered column headers go ; \"domain\" \"qnumber\" example.names_sep optional argument one value names_to. specifies characters position split values cols headers.values_to want call values columns ...; \"score\" example.can pipe data table glimpse() end quick look . still save object.set names_sep order split cols headers listed results?","code":"\npersonality_long <- pivot_longer(\n  data = personality, \n  cols = Op1:Ex9,                    # columns to make long \n  names_to = c(\"domain\", \"qnumber\"), # new column names for headers\n  names_sep = 2,                     # how to split the headers\n  values_to = \"score\"                # new column name for values\n) %>%\n  glimpse()## Rows: 615,000\n## Columns: 5\n## $ user_id <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n## $ date    <date> 2006-03-23, 2006-03-23, 2006-03-23, 2006-03-23, 2006-03-23, 2…\n## $ domain  <chr> \"Op\", \"Ne\", \"Ne\", \"Op\", \"Ex\", \"Ex\", \"Co\", \"Co\", \"Ne\", \"Ag\", \"A…\n## $ qnumber <chr> \"1\", \"1\", \"2\", \"2\", \"1\", \"2\", \"1\", \"2\", \"3\", \"1\", \"2\", \"4\", \"3…\n## $ score   <dbl> 3, 4, 0, 6, 3, 3, 3, 3, 0, 2, 1, 3, 3, 2, 2, 1, 3, 3, 1, 3, 0,…"},{"path":"tidyr.html","id":"pivot_wider","chapter":"6 Tidy Data","heading":"6.5.3 pivot_wider()","text":"can also go long wide format using pivot_wider() function.names_from columns contain new column headers.values_from column contains values new columns.names_sep character string used join names names_from one column.","code":"\npersonality_wide <- pivot_wider(\n  data = personality_long,\n  names_from = c(domain, qnumber),\n  values_from = score,\n  names_sep = \"\"\n) %>%\n  glimpse()## Rows: 15,000\n## Columns: 43\n## $ user_id <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 94…\n## $ date    <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, 2…\n## $ Op1     <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4,…\n## $ Ne1     <dbl> 4, 0, 0, 4, 1, 2, 3, 4, 0, 3, 3, 3, 2, 1, 1, 3, 4, 5, 2, 4, 5,…\n## $ Ne2     <dbl> 0, 6, 6, 4, 2, 1, 2, 3, 1, 2, 5, 5, 3, 1, 1, 1, 1, 6, 1, 2, 5,…\n## $ Op2     <dbl> 6, 0, 0, 4, 6, 4, 4, 0, 0, 3, 4, 3, 3, 4, 5, 3, 3, 4, 1, 6, 6,…\n## $ Ex1     <dbl> 3, 0, 0, 2, 2, 4, 4, 3, 5, 4, 1, 1, 3, 3, 1, 3, 5, 1, 0, 4, 1,…\n## $ Ex2     <dbl> 3, 0, 0, 3, 3, 4, 5, 2, 5, 3, 4, 1, 3, 2, 1, 6, 5, 3, 4, 4, 1,…\n## $ Co1     <dbl> 3, 0, 0, 3, 5, 4, 3, 4, 5, 3, 3, 3, 1, 5, 5, 4, 4, 5, 6, 4, 2,…\n## $ Co2     <dbl> 3, 0, 0, 3, 4, 3, 3, 4, 5, 3, 5, 3, 3, 4, 5, 1, 5, 4, 5, 2, 5,…\n## $ Ne3     <dbl> 0, 0, 0, 1, 0, 1, 4, 4, 0, 4, 2, 5, 1, 2, 5, 5, 2, 2, 1, 2, 5,…\n## $ Ag1     <dbl> 2, 0, 0, 4, 6, 5, 5, 4, 2, 5, 4, 3, 2, 4, 5, 3, 5, 5, 5, 4, 4,…\n## $ Ag2     <dbl> 1, 6, 6, 0, 5, 4, 5, 3, 4, 3, 5, 1, 5, 4, 2, 6, 5, 5, 5, 5, 2,…\n## $ Ne4     <dbl> 3, 6, 6, 2, 3, 2, 3, 3, 0, 4, 4, 5, 5, 4, 5, 3, 2, 5, 2, 4, 5,…\n## $ Ex3     <dbl> 3, 6, 5, 5, 3, 3, 3, 0, 6, 1, 4, 2, 3, 2, 1, 2, 5, 1, 0, 5, 5,…\n## $ Co3     <dbl> 2, 0, 1, 3, 4, 4, 5, 4, 5, 3, 4, 3, 4, 4, 5, 4, 2, 4, 5, 2, 2,…\n## $ Op3     <dbl> 2, 6, 5, 5, 5, 4, 3, 2, 4, 3, 3, 6, 5, 5, 6, 5, 4, 4, 3, 6, 5,…\n## $ Ex4     <dbl> 1, 0, 1, 3, 3, 3, 4, 3, 5, 3, 2, 0, 3, 3, 1, 2, NA, 4, 4, 4, 1…\n## $ Op4     <dbl> 3, 0, 1, 6, 6, 3, 3, 0, 6, 3, 4, 5, 4, 5, 6, 6, 2, 2, 4, 5, 5,…\n## $ Ex5     <dbl> 3, 0, 1, 6, 3, 3, 4, 2, 5, 2, 2, 4, 2, 3, 0, 4, 5, 2, 3, 1, 1,…\n## $ Ag3     <dbl> 1, 0, 1, 1, 0, 4, 4, 4, 3, 3, 4, 4, 3, 4, 4, 5, 5, 4, 5, 3, 4,…\n## $ Co4     <dbl> 3, 6, 5, 5, 5, 3, 2, 4, 3, 1, 4, 3, 1, 2, 4, 2, NA, 5, 6, 1, 1…\n## $ Co5     <dbl> 0, 6, 5, 5, 5, 3, 3, 1, 5, 1, 2, 4, 4, 4, 2, 1, 6, 4, 3, 1, 3,…\n## $ Ne5     <dbl> 3, 0, 1, 4, 1, 1, 4, 5, 0, 3, 4, 6, 2, 0, 1, 1, 0, 4, 3, 1, 5,…\n## $ Op5     <dbl> 6, 6, 5, 2, 5, 4, 3, 2, 6, 6, 2, 4, 3, 4, 6, 6, 6, 5, 3, 3, 5,…\n## $ Ag4     <dbl> 1, 0, 1, 4, 6, 5, 5, 6, 6, 6, 4, 2, 4, 5, 4, 5, 6, 4, 5, 6, 5,…\n## $ Op6     <dbl> 0, 6, 5, 1, 6, 4, 6, 0, 0, 3, 5, 3, 5, 5, 5, 2, 5, 1, 1, 6, 2,…\n## $ Co6     <dbl> 6, 0, 1, 4, 6, 5, 6, 5, 4, 3, 5, 5, 4, 6, 6, 1, 3, 4, 5, 4, 6,…\n## $ Ex6     <dbl> 3, 6, 5, 3, 0, 4, 3, 1, 6, 3, 2, 1, 4, 2, 1, 5, 6, 2, 1, 2, 1,…\n## $ Ne6     <dbl> 1, 6, 5, 1, 0, 1, 3, 4, 0, 4, 4, 5, 2, 1, 5, 6, 1, 2, 2, 3, 5,…\n## $ Co7     <dbl> 3, 6, 5, 1, 3, 4, NA, 2, 3, 3, 2, 2, 4, 2, 5, 2, 5, 5, 3, 1, 1…\n## $ Ag5     <dbl> 3, 6, 5, 0, 2, 5, 6, 2, 2, 3, 4, 1, 3, 5, 2, 6, 5, 6, 5, 3, 3,…\n## $ Co8     <dbl> 3, 0, 1, 1, 3, 4, 3, 0, 1, 3, 2, 2, 1, 2, 4, 3, 2, 4, 5, 2, 6,…\n## $ Ex7     <dbl> 3, 6, 5, 4, 1, 2, 5, 3, 6, 3, 4, 3, 5, 1, 1, 6, 6, 3, 1, 1, 3,…\n## $ Ne7     <dbl> NA, 0, 1, 2, 0, 2, 4, 4, 0, 3, 2, 5, 1, 2, 5, 2, 2, 4, 1, 3, 5…\n## $ Co9     <dbl> 3, 6, 5, 4, 3, 4, 5, 3, 5, 3, 4, 3, 4, 4, 2, 4, 6, 5, 5, 2, 2,…\n## $ Op7     <dbl> 0, 6, 5, 5, 5, 4, 6, 2, 1, 3, 2, 4, 5, 5, 6, 3, 6, 5, 2, 6, 5,…\n## $ Ne8     <dbl> 2, 0, 1, 1, 1, 1, 5, 4, 0, 4, 4, 5, 1, 2, 5, 2, 1, 5, 1, 2, 5,…\n## $ Ag6     <dbl> NA, 6, 5, 2, 3, 4, 5, 6, 1, 3, 4, 2, 3, 5, 1, 6, 2, 6, 6, 5, 3…\n## $ Ag7     <dbl> 3, 0, 1, 1, 1, 3, 3, 5, 0, 3, 2, 1, 2, 3, 5, 6, 4, 4, 6, 6, 2,…\n## $ Co10    <dbl> 1, 6, 5, 5, 3, 5, 1, 2, 5, 2, 4, 3, 4, 4, 3, 2, 5, 5, 5, 2, 2,…\n## $ Ex8     <dbl> 2, 0, 1, 4, 3, 4, 2, 4, 6, 2, 4, 0, 4, 4, 1, 3, 5, 4, 3, 1, 1,…\n## $ Ex9     <dbl> 4, 6, 5, 5, 5, 2, 3, 3, 6, 3, 3, 4, 4, 3, 2, 5, 5, 4, 4, 0, 4,…"},{"path":"tidyr.html","id":"tidy-verbs","chapter":"6 Tidy Data","heading":"6.6 Tidy Verbs","text":"pivot functions relatively new functions combine four basic tidy verbs. can also convert data long wide formats using functions. Many researchers still use functions older code use pivot functions, useful know interpret .","code":""},{"path":"tidyr.html","id":"gather","chapter":"6 Tidy Data","heading":"6.6.1 gather()","text":"Much like pivot_longer(), gather() makes wide data table long creating column headers column values. main difference turn headers one column.key want call new column gathered column headers go ; \"question\" example. like names_to pivot_longer(), can take one value (multiple values need separated separate()).value want call values gathered columns; \"score\" example. like values_to pivot_longer().... refers columns want gather. like cols pivot_longer().gather() function converts personality wide data table long format, row user/question observation. resulting data table columns: user_id, date, question, score.","code":"\npersonality_gathered <- gather(\n  data = personality, \n  key = \"question\", # new column name for gathered headers\n  value = \"score\",  # new column name for gathered values\n  Op1:Ex9           # columns to gather\n) %>%\n  glimpse()## Rows: 615,000\n## Columns: 4\n## $ user_id  <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 9…\n## $ date     <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, …\n## $ question <chr> \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\", \"Op1\"…\n## $ score    <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4…"},{"path":"tidyr.html","id":"separate","chapter":"6 Tidy Data","heading":"6.6.2 separate()","text":"col column want separateinto vector new column namessep character(s) separate new columns. defaults anything alphanumeric, like .,_-/: like names_sep argument pivot_longer().Split question column two columns: domain qnumber.character split , , can separate column specific number characters setting sep integer. example, split \"abcde\" third character, use sep = 3, results c(\"abc\", \"de\"). can also use negative number split nth character right. example, split column words various lengths 2-digit suffixes (like \"lisa03\"\", \"amanda38\"), can use sep = -2.want separate just full stops, need use sep = \"\\\\.\", sep = \".\". two slashes escape full stop, making interpreted literal full stop regular expression character.","code":"\npersonality_sep <- separate(\n  data = personality_gathered, \n  col = question,                # column to separate\n  into = c(\"domain\", \"qnumber\"), # new column names\n  sep = 2                        # where to separate\n) %>%\n  glimpse()## Rows: 615,000\n## Columns: 5\n## $ user_id <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 94…\n## $ date    <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, 2…\n## $ domain  <chr> \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"Op\", \"O…\n## $ qnumber <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1…\n## $ score   <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4,…"},{"path":"tidyr.html","id":"unite","chapter":"6 Tidy Data","heading":"6.6.3 unite()","text":"col new united column... refers columns want unitesep character(s) separate united columnsPut domain qnumber columns back together new column named domain_n. Make format like \"Op_Q1\".","code":"\npersonality_unite <- unite(\n  data = personality_sep, \n  col = \"domain_n\", # new column name\n  domain, qnumber,  # columns to unite\n  sep = \"_Q\"        # separation characters\n) %>%\n  glimpse()## Rows: 615,000\n## Columns: 4\n## $ user_id  <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 9…\n## $ date     <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, …\n## $ domain_n <chr> \"Op_Q1\", \"Op_Q1\", \"Op_Q1\", \"Op_Q1\", \"Op_Q1\", \"Op_Q1\", \"Op_Q1\"…\n## $ score    <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4…"},{"path":"tidyr.html","id":"spread","chapter":"6 Tidy Data","heading":"6.6.4 spread()","text":"can reverse processes , well. example, can convert data long format wide format.key column contains new column headers. like names_from pivot_wider(), can take one value (multiple values need merged first using unite()).value column contains values new spread columns. like values_from pivot_wider().","code":"\npersonality_spread <- spread(\n  data = personality_unite,\n  key = domain_n, # column that contains new headers\n  value = score   # column that contains new values\n) %>%\n  glimpse()## Rows: 15,000\n## Columns: 43\n## $ user_id <dbl> 0, 1, 2, 5, 8, 108, 233, 298, 426, 436, 685, 807, 871, 881, 94…\n## $ date    <date> 2006-03-23, 2006-02-08, 2005-10-24, 2005-12-07, 2006-07-27, 2…\n## $ Ag_Q1   <dbl> 2, 0, 0, 4, 6, 5, 5, 4, 2, 5, 4, 3, 2, 4, 5, 3, 5, 5, 5, 4, 4,…\n## $ Ag_Q2   <dbl> 1, 6, 6, 0, 5, 4, 5, 3, 4, 3, 5, 1, 5, 4, 2, 6, 5, 5, 5, 5, 2,…\n## $ Ag_Q3   <dbl> 1, 0, 1, 1, 0, 4, 4, 4, 3, 3, 4, 4, 3, 4, 4, 5, 5, 4, 5, 3, 4,…\n## $ Ag_Q4   <dbl> 1, 0, 1, 4, 6, 5, 5, 6, 6, 6, 4, 2, 4, 5, 4, 5, 6, 4, 5, 6, 5,…\n## $ Ag_Q5   <dbl> 3, 6, 5, 0, 2, 5, 6, 2, 2, 3, 4, 1, 3, 5, 2, 6, 5, 6, 5, 3, 3,…\n## $ Ag_Q6   <dbl> NA, 6, 5, 2, 3, 4, 5, 6, 1, 3, 4, 2, 3, 5, 1, 6, 2, 6, 6, 5, 3…\n## $ Ag_Q7   <dbl> 3, 0, 1, 1, 1, 3, 3, 5, 0, 3, 2, 1, 2, 3, 5, 6, 4, 4, 6, 6, 2,…\n## $ Co_Q1   <dbl> 3, 0, 0, 3, 5, 4, 3, 4, 5, 3, 3, 3, 1, 5, 5, 4, 4, 5, 6, 4, 2,…\n## $ Co_Q10  <dbl> 1, 6, 5, 5, 3, 5, 1, 2, 5, 2, 4, 3, 4, 4, 3, 2, 5, 5, 5, 2, 2,…\n## $ Co_Q2   <dbl> 3, 0, 0, 3, 4, 3, 3, 4, 5, 3, 5, 3, 3, 4, 5, 1, 5, 4, 5, 2, 5,…\n## $ Co_Q3   <dbl> 2, 0, 1, 3, 4, 4, 5, 4, 5, 3, 4, 3, 4, 4, 5, 4, 2, 4, 5, 2, 2,…\n## $ Co_Q4   <dbl> 3, 6, 5, 5, 5, 3, 2, 4, 3, 1, 4, 3, 1, 2, 4, 2, NA, 5, 6, 1, 1…\n## $ Co_Q5   <dbl> 0, 6, 5, 5, 5, 3, 3, 1, 5, 1, 2, 4, 4, 4, 2, 1, 6, 4, 3, 1, 3,…\n## $ Co_Q6   <dbl> 6, 0, 1, 4, 6, 5, 6, 5, 4, 3, 5, 5, 4, 6, 6, 1, 3, 4, 5, 4, 6,…\n## $ Co_Q7   <dbl> 3, 6, 5, 1, 3, 4, NA, 2, 3, 3, 2, 2, 4, 2, 5, 2, 5, 5, 3, 1, 1…\n## $ Co_Q8   <dbl> 3, 0, 1, 1, 3, 4, 3, 0, 1, 3, 2, 2, 1, 2, 4, 3, 2, 4, 5, 2, 6,…\n## $ Co_Q9   <dbl> 3, 6, 5, 4, 3, 4, 5, 3, 5, 3, 4, 3, 4, 4, 2, 4, 6, 5, 5, 2, 2,…\n## $ Ex_Q1   <dbl> 3, 0, 0, 2, 2, 4, 4, 3, 5, 4, 1, 1, 3, 3, 1, 3, 5, 1, 0, 4, 1,…\n## $ Ex_Q2   <dbl> 3, 0, 0, 3, 3, 4, 5, 2, 5, 3, 4, 1, 3, 2, 1, 6, 5, 3, 4, 4, 1,…\n## $ Ex_Q3   <dbl> 3, 6, 5, 5, 3, 3, 3, 0, 6, 1, 4, 2, 3, 2, 1, 2, 5, 1, 0, 5, 5,…\n## $ Ex_Q4   <dbl> 1, 0, 1, 3, 3, 3, 4, 3, 5, 3, 2, 0, 3, 3, 1, 2, NA, 4, 4, 4, 1…\n## $ Ex_Q5   <dbl> 3, 0, 1, 6, 3, 3, 4, 2, 5, 2, 2, 4, 2, 3, 0, 4, 5, 2, 3, 1, 1,…\n## $ Ex_Q6   <dbl> 3, 6, 5, 3, 0, 4, 3, 1, 6, 3, 2, 1, 4, 2, 1, 5, 6, 2, 1, 2, 1,…\n## $ Ex_Q7   <dbl> 3, 6, 5, 4, 1, 2, 5, 3, 6, 3, 4, 3, 5, 1, 1, 6, 6, 3, 1, 1, 3,…\n## $ Ex_Q8   <dbl> 2, 0, 1, 4, 3, 4, 2, 4, 6, 2, 4, 0, 4, 4, 1, 3, 5, 4, 3, 1, 1,…\n## $ Ex_Q9   <dbl> 4, 6, 5, 5, 5, 2, 3, 3, 6, 3, 3, 4, 4, 3, 2, 5, 5, 4, 4, 0, 4,…\n## $ Ne_Q1   <dbl> 4, 0, 0, 4, 1, 2, 3, 4, 0, 3, 3, 3, 2, 1, 1, 3, 4, 5, 2, 4, 5,…\n## $ Ne_Q2   <dbl> 0, 6, 6, 4, 2, 1, 2, 3, 1, 2, 5, 5, 3, 1, 1, 1, 1, 6, 1, 2, 5,…\n## $ Ne_Q3   <dbl> 0, 0, 0, 1, 0, 1, 4, 4, 0, 4, 2, 5, 1, 2, 5, 5, 2, 2, 1, 2, 5,…\n## $ Ne_Q4   <dbl> 3, 6, 6, 2, 3, 2, 3, 3, 0, 4, 4, 5, 5, 4, 5, 3, 2, 5, 2, 4, 5,…\n## $ Ne_Q5   <dbl> 3, 0, 1, 4, 1, 1, 4, 5, 0, 3, 4, 6, 2, 0, 1, 1, 0, 4, 3, 1, 5,…\n## $ Ne_Q6   <dbl> 1, 6, 5, 1, 0, 1, 3, 4, 0, 4, 4, 5, 2, 1, 5, 6, 1, 2, 2, 3, 5,…\n## $ Ne_Q7   <dbl> NA, 0, 1, 2, 0, 2, 4, 4, 0, 3, 2, 5, 1, 2, 5, 2, 2, 4, 1, 3, 5…\n## $ Ne_Q8   <dbl> 2, 0, 1, 1, 1, 1, 5, 4, 0, 4, 4, 5, 1, 2, 5, 2, 1, 5, 1, 2, 5,…\n## $ Op_Q1   <dbl> 3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 4, 5, 5, 5, 6, 4, 1, 2, 5, 6, 4,…\n## $ Op_Q2   <dbl> 6, 0, 0, 4, 6, 4, 4, 0, 0, 3, 4, 3, 3, 4, 5, 3, 3, 4, 1, 6, 6,…\n## $ Op_Q3   <dbl> 2, 6, 5, 5, 5, 4, 3, 2, 4, 3, 3, 6, 5, 5, 6, 5, 4, 4, 3, 6, 5,…\n## $ Op_Q4   <dbl> 3, 0, 1, 6, 6, 3, 3, 0, 6, 3, 4, 5, 4, 5, 6, 6, 2, 2, 4, 5, 5,…\n## $ Op_Q5   <dbl> 6, 6, 5, 2, 5, 4, 3, 2, 6, 6, 2, 4, 3, 4, 6, 6, 6, 5, 3, 3, 5,…\n## $ Op_Q6   <dbl> 0, 6, 5, 1, 6, 4, 6, 0, 0, 3, 5, 3, 5, 5, 5, 2, 5, 1, 1, 6, 2,…\n## $ Op_Q7   <dbl> 0, 6, 5, 5, 5, 4, 6, 2, 1, 3, 2, 4, 5, 5, 6, 3, 6, 5, 2, 6, 5,…"},{"path":"tidyr.html","id":"pipes","chapter":"6 Tidy Data","heading":"6.7 Pipes","text":"Pipes way order code readable format.say small data table 10 participant IDs, two columns variable type , 2 columns variable type B. want calculate mean variables mean B variables return table 10 rows (1 participant) 3 columns (id, A_mean B_mean).One way creating new object every step using object next step. pretty clear, created 6 unnecessary data objects environment. can get confusing long scripts.can name object data keep replacing old data object new one step. keep environment clean, recommend makes easy accidentally run code order running line--line development debugging.One way avoid extra objects nest functions, literally replacing data object code generated previous step. can fine short chains.gets extremely confusing long chains:pipe lets \"pipe\" result function next function, allowing put code logical order without creating many extra objects.can read code top bottom follows:Make tibble called data \nid 1 10,\nA1 10 random numbers normal distribution,\nA2 10 random numbers normal distribution,\nB1 10 random numbers normal distribution,\nB2 10 random numbers normal distribution; \nid 1 10,A1 10 random numbers normal distribution,A2 10 random numbers normal distribution,B1 10 random numbers normal distribution,B2 10 random numbers normal distribution; thenGather create variable value column columns A_1 B_2; thenSeparate column variable 2 new columns called varand var_n, separate character 1; thenGroup columns id var; thenSummarise new column called mean mean value column group drop grouping; thenSpread make new columns key names var values mean; thenRename make columns called A_mean (old ) B_mean (old B)can make intermediate objects whenever need break code getting complicated need debug something.can debug pipe highlighting beginning just pipe want stop . Try highlighting data <- end separate function typing cmd-return. data look like now?Chain steps using pipes.","code":"\n# make a data table with 10 subjects\ndata_original <- tibble(\n  id = 1:10,\n  A1 = rnorm(10, 0),\n  A2 = rnorm(10, 1),\n  B1 = rnorm(10, 2),\n  B2 = rnorm(10, 3)\n)\n\n# gather columns A1 to B2 into \"variable\" and \"value\" columns\ndata_gathered <- gather(data_original, variable, value, A1:B2)\n\n# separate the variable column at the _ into \"var\" and \"var_n\" columns\ndata_separated <- separate(data_gathered, variable, c(\"var\", \"var_n\"), sep = 1)\n\n# group the data by id and var\ndata_grouped <- group_by(data_separated, id, var)\n\n# calculate the mean value for each id/var \ndata_summarised <- summarise(data_grouped, mean = mean(value), .groups = \"drop\")\n\n# spread the mean column into A and B columns\ndata_spread <- spread(data_summarised, var, mean)\n\n# rename A and B to A_mean and B_mean\ndata <- rename(data_spread, A_mean = A, B_mean = B)\n\ndata\nmean_petal_width <- round(mean(iris$Petal.Width), 2)\n# do not ever do this!!\ndata <- rename(\n  spread(\n    summarise(\n      group_by(\n        separate(\n          gather(\n            tibble(\n              id = 1:10,\n              A1 = rnorm(10, 0),\n              A2 = rnorm(10, 1),\n              B1 = rnorm(10, 2),\n              B2 = rnorm(10,3)), \n            variable, value, A1:B2), \n          variable, c(\"var\", \"var_n\"), sep = 1), \n        id, var), \n      mean = mean(value), .groups = \"drop\"), \n    var, mean), \n  A_mean = A, B_mean = B)\n# calculate mean of A and B variables for each participant\ndata <- tibble(\n  id = 1:10,\n  A1 = rnorm(10, 0),\n  A2 = rnorm(10, 1),\n  B1 = rnorm(10, 2),\n  B2 = rnorm(10,3)\n) %>%\n  gather(variable, value, A1:B2) %>%\n  separate(variable, c(\"var\", \"var_n\"), sep=1) %>%\n  group_by(id, var) %>%\n  summarise(mean = mean(value), .groups = \"drop\") %>%\n  spread(var, mean) %>%\n  rename(A_mean = A, B_mean = B)\npersonality_reshaped <- personality %>%\n  gather(\"question\", \"score\", Op1:Ex9) %>%\n  separate(question, c(\"domain\", \"qnumber\"), sep = 2) %>%\n  unite(\"domain_n\", domain, qnumber, sep = \"_Q\") %>%\n  spread(domain_n, score)"},{"path":"tidyr.html","id":"more-complex-example","chapter":"6 Tidy Data","heading":"6.8 More Complex Example","text":"","code":""},{"path":"tidyr.html","id":"load-data-1","chapter":"6 Tidy Data","heading":"6.8.1 Load Data","text":"Get data infant maternal mortality rates reprores package. package, can download :infant mortalitymaternal mortality","code":"\ndata(\"infmort\")\nhead(infmort)\ndata(\"matmort\")\nhead(matmort)"},{"path":"tidyr.html","id":"wide-to-long","chapter":"6 Tidy Data","heading":"6.8.2 Wide to Long","text":"matmort wide format, separate column year. Change long format, row Country/Year observation.example complicated column names gather numbers. column names non-standard (e.g., spaces, start numbers, special characters), can enclose backticks (`) like example .can put matmort first argument pivot_longer(); pipe . working data processing often find needing insert rearrange steps constantly introduce errors forgetting take first argument pipe chain, now start original data table pipe .Alternatively, can use gather() function.","code":"\nmatmort_long <- matmort %>%\n  pivot_longer(cols = `1990`:`2015`,\n               names_to = \"Year\",\n               values_to = \"stats\") %>%\n  glimpse()## Rows: 543\n## Columns: 3\n## $ Country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Albania\", \"Alban…\n## $ Year    <chr> \"1990\", \"2000\", \"2015\", \"1990\", \"2000\", \"2015\", \"1990\", \"2000\"…\n## $ stats   <chr> \"1 340 [ 878 - 1 950]\", \"1 100 [ 745 - 1 570]\", \"396 [ 253 -  …\nmatmort_long <- matmort %>%\n  gather(\"Year\", \"stats\", `1990`:`2015`) %>%\n  glimpse()## Rows: 543\n## Columns: 3\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ stats   <chr> \"1 340 [ 878 - 1 950]\", \"71 [ 58 -  88]\", \"216 [ 141 -  327]\",…"},{"path":"tidyr.html","id":"one-piece-of-data-per-column","chapter":"6 Tidy Data","heading":"6.8.3 One Piece of Data per Column","text":"data stats column unusual format sort confidence interval brackets lots extra spaces. need spaces, first remove mutate(), learn next lesson.separate function separate data anything number letter, try first without specifying sep argument. argument list new column names.gsub(pattern, replacement, x) function \nflexible way search replace. example replaces occurances pattern \" \" (space), replacement \"\" (nothing), string x (stats column). Use sub() instead want replace first occurance pattern. used simple pattern , can use complicated regex patterns replace, example, even numbers (e.g., gsub(\"[:02468:]\", \"*\", \"id = 123456\")) occurances word colour US UK spelling\n(e.g., gsub(\"colo(u)?r\", \"***\", \"replace color, colour, colours, collors\")).","code":"\nmatmort_split <- matmort_long %>%\n  mutate(stats = gsub(\" \", \"\", stats)) %>%\n  separate(stats, c(\"rate\", \"ci_low\", \"ci_hi\")) %>%\n  glimpse()## Warning: Expected 3 pieces. Additional pieces discarded in 543 rows [1, 2, 3, 4,\n## 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].## Rows: 543\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ rate    <chr> \"1340\", \"71\", \"216\", \"1160\", \"72\", \"58\", \"8\", \"8\", \"64\", \"46\",…\n## $ ci_low  <chr> \"878\", \"58\", \"141\", \"627\", \"64\", \"51\", \"7\", \"7\", \"56\", \"34\", \"…\n## $ ci_hi   <chr> \"1950\", \"88\", \"327\", \"2020\", \"80\", \"65\", \"9\", \"10\", \"74\", \"61\"…"},{"path":"tidyr.html","id":"extra","chapter":"6 Tidy Data","heading":"6.8.3.1 Handle spare columns with extra","text":"previous example given error warning \n\"Additional pieces discarded 543 rows\". separate splits column brackets dashes, text 100[90-110] split four values c(\"100\", \"90\", \"110\", \"\"), specified 3 new columns. fourth value always empty (just part last bracket), happy drop , separate generates warning accidentally. can turn warning adding extra argument setting \"drop\". Look help ??tidyr::separate see options .","code":"\nmatmort_split <- matmort_long %>%\n  mutate(stats = gsub(\" \", \"\", stats)) %>%\n  separate(stats, c(\"rate\", \"ci_low\", \"ci_hi\"), extra = \"drop\") %>%\n  glimpse()## Rows: 543\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ rate    <chr> \"1340\", \"71\", \"216\", \"1160\", \"72\", \"58\", \"8\", \"8\", \"64\", \"46\",…\n## $ ci_low  <chr> \"878\", \"58\", \"141\", \"627\", \"64\", \"51\", \"7\", \"7\", \"56\", \"34\", \"…\n## $ ci_hi   <chr> \"1950\", \"88\", \"327\", \"2020\", \"80\", \"65\", \"9\", \"10\", \"74\", \"61\"…"},{"path":"tidyr.html","id":"sep","chapter":"6 Tidy Data","heading":"6.8.3.2 Set delimiters with sep","text":"Now infmort. already long format, need use gather, third column ridiculously long name, can just refer column number (3).Wait, work ! split column spaces, brackets, full stops. just want split spaces, brackets dashes. need manually set sep delimiters . Also, arguments specified function, easier read put one argument line.","code":"\ninfmort_split <- infmort %>%\n  separate(3, c(\"rate\", \"ci_low\", \"ci_hi\"), extra = \"drop\") %>%\n  glimpse()## Rows: 5,044\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"A…\n## $ Year    <dbl> 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 20…\n## $ rate    <chr> \"66\", \"68\", \"69\", \"71\", \"73\", \"75\", \"76\", \"78\", \"80\", \"82\", \"8…\n## $ ci_low  <chr> \"3\", \"1\", \"9\", \"7\", \"4\", \"1\", \"8\", \"6\", \"4\", \"3\", \"4\", \"7\", \"0…\n## $ ci_hi   <chr> \"52\", \"55\", \"58\", \"61\", \"64\", \"66\", \"69\", \"71\", \"73\", \"75\", \"7…"},{"path":"tidyr.html","id":"regex","chapter":"6 Tidy Data","heading":"","text":"can use regular expressions\nseparate complex columns. , want separate dashes brackets. can separate list delimiters putting parentheses, separated \"|\". little complicated brackets special meaning regex, need \"escape\" left one two backslashes \"\\\\\".","code":"\ninfmort_split <- infmort %>%\n  separate(\n    col = 3, \n    into = c(\"rate\", \"ci_low\", \"ci_hi\"), \n    extra = \"drop\", \n    sep = \"(\\\\[|-|])\"\n  ) %>%\n  glimpse()## Rows: 5,044\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"A…\n## $ Year    <dbl> 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 20…\n## $ rate    <chr> \"66.3 \", \"68.1 \", \"69.9 \", \"71.7 \", \"73.4 \", \"75.1 \", \"76.8 \",…\n## $ ci_low  <chr> \"52.7\", \"55.7\", \"58.7\", \"61.6\", \"64.4\", \"66.9\", \"69.0\", \"71.2\"…\n## $ ci_hi   <chr> \"83.9\", \"83.6\", \"83.5\", \"83.7\", \"84.2\", \"85.1\", \"86.1\", \"87.3\"…"},{"path":"tidyr.html","id":"convert","chapter":"6 Tidy Data","heading":"6.8.3.3 Fix data types with convert","text":"better. Notice  next Year, rate, ci_low ci_hi. means columns hold characters (like words), numbers integers. can cause problems try thigs like average numbers (average words), can fix adding argument convert setting TRUE.matmort.","code":"\ninfmort_split <- infmort %>%\n  separate(col = 3, \n           into = c(\"rate\", \"ci_low\", \"ci_hi\"), \n           extra = \"drop\", \n           sep = \"(\\\\[|-|])\", \n           convert = TRUE) %>%\n  glimpse()## Rows: 5,044\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"A…\n## $ Year    <dbl> 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 20…\n## $ rate    <dbl> 66.3, 68.1, 69.9, 71.7, 73.4, 75.1, 76.8, 78.6, 80.4, 82.3, 84…\n## $ ci_low  <dbl> 52.7, 55.7, 58.7, 61.6, 64.4, 66.9, 69.0, 71.2, 73.4, 75.5, 77…\n## $ ci_hi   <dbl> 83.9, 83.6, 83.5, 83.7, 84.2, 85.1, 86.1, 87.3, 88.9, 90.7, 92…\nmatmort_split <- matmort_long %>%\n  mutate(stats = gsub(\" \", \"\", stats)) %>%\n  separate(col = stats, \n           into = c(\"rate\", \"ci_low\", \"ci_hi\"), \n           extra = \"drop\", \n           convert = TRUE) %>%\n  glimpse()## Rows: 543\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ rate    <int> 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58, 33, 9,…\n## $ ci_low  <int> 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, 28, 7, 4…\n## $ ci_hi   <int> 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 72, 38, 1…"},{"path":"tidyr.html","id":"all-in-one-step","chapter":"6 Tidy Data","heading":"6.8.4 All in one step","text":"can chain steps matmort together, since need intermediate data tables.","code":"\nmatmort2 <- matmort %>%\n  gather(\"Year\", \"stats\", `1990`:`2015`) %>%\n  mutate(stats = gsub(\" \", \"\", stats)) %>%\n  separate(\n    col = stats, \n    into = c(\"rate\", \"ci_low\", \"ci_hi\"), \n    extra = \"drop\", \n    convert = TRUE\n  ) %>%\n  glimpse()## Rows: 543\n## Columns: 5\n## $ Country <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\", \"A…\n## $ Year    <chr> \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\", \"1990\"…\n## $ rate    <int> 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58, 33, 9,…\n## $ ci_low  <int> 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, 28, 7, 4…\n## $ ci_hi   <int> 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 72, 38, 1…"},{"path":"tidyr.html","id":"columns-by-year","chapter":"6 Tidy Data","heading":"6.8.5 Columns by Year","text":"Spread maternal mortality rate year.Nope, work , really common mistake spreading data. spread matches remaining columns, Afghanistan ci_low 253 treated different observation Afghanistan ci_low 745.pivot_wider() can useful. can set values_from multiple column names names added names_from values.","code":"\nmatmort_wide <- matmort2 %>%\n  spread(key = Year, value = rate) %>%\n  print()## # A tibble: 542 x 6\n##    Country     ci_low ci_hi `1990` `2000` `2015`\n##    <chr>        <int> <int>  <int>  <int>  <int>\n##  1 Afghanistan    253   620     NA     NA    396\n##  2 Afghanistan    745  1570     NA   1100     NA\n##  3 Afghanistan    878  1950   1340     NA     NA\n##  4 Albania         16    46     NA     NA     29\n##  5 Albania         33    56     NA     43     NA\n##  6 Albania         58    88     71     NA     NA\n##  7 Algeria         82   244     NA     NA    140\n##  8 Algeria        118   241     NA    170     NA\n##  9 Algeria        141   327    216     NA     NA\n## 10 Angola         221   988     NA     NA    477\n## # … with 532 more rows\nmatmort_wide <- matmort2 %>%\n  pivot_wider(\n    names_from = Year,\n    values_from = c(rate, ci_low, ci_hi)\n  )\n              \nglimpse(matmort_wide)## Rows: 181\n## Columns: 10\n## $ Country     <chr> \"Afghanistan\", \"Albania\", \"Algeria\", \"Angola\", \"Argentina\"…\n## $ rate_1990   <int> 1340, 71, 216, 1160, 72, 58, 8, 8, 64, 46, 26, 569, 58, 33…\n## $ rate_2000   <int> 1100, 43, 170, 924, 60, 40, 9, 5, 48, 61, 21, 399, 48, 26,…\n## $ rate_2015   <int> 396, 29, 140, 477, 52, 25, 6, 4, 25, 80, 15, 176, 27, 4, 7…\n## $ ci_low_1990 <int> 878, 58, 141, 627, 64, 51, 7, 7, 56, 34, 20, 446, 47, 28, …\n## $ ci_low_2000 <int> 745, 33, 118, 472, 54, 35, 8, 4, 42, 50, 18, 322, 38, 22, …\n## $ ci_low_2015 <int> 253, 16, 82, 221, 44, 21, 5, 3, 17, 53, 12, 125, 19, 3, 5,…\n## $ ci_hi_1990  <int> 1950, 88, 327, 2020, 80, 65, 9, 10, 74, 61, 33, 715, 72, 3…\n## $ ci_hi_2000  <int> 1570, 56, 241, 1730, 65, 46, 10, 6, 55, 74, 26, 496, 58, 3…\n## $ ci_hi_2015  <int> 620, 46, 244, 988, 63, 31, 7, 5, 35, 124, 19, 280, 37, 6, …"},{"path":"tidyr.html","id":"experimentum-data","chapter":"6 Tidy Data","heading":"6.8.6 Experimentum Data","text":"Students Institute Neuroscience Psychology University Glasgow can use online experiment builder platform, Experimentum. platform also open source github anyone can install web server. allows group questionnaires experiments projects randomisation counterbalancing. Data questionnaires experiments downloadable long format, researchers often need put wide format analysis.Look help menu built-dataset experimentum_quests learn column . Subjects asked questions dogs test different questionnaire response types.current: dog? (yes/)past: ever owned dog? (yes/)name: best name dog? (free short text)good: good dogs? (1=pretty good:7=good)country: country borzois come ?good_borzoi: good borzois? (0=pretty good:100=good)text: Write text dogs. (free long text)time: time ? (time)get dataset wide format, question separate column, use following code:responses dv column multiple types (e.g., integer, double, character), represented character strings column. spread data wide format, column given ocrrect data type. function type.convert() makes best guess type new column converts . argument .= TRUE converts columns none numbers decimal places integers.","code":"\nq <- experimentum_quests %>%\n  pivot_wider(id_cols = session_id:user_age,\n              names_from = q_name,\n              values_from = dv) %>%\n  type.convert(as.is = TRUE) %>%\n  print()## # A tibble: 24 x 15\n##    session_id project_id quest_id user_id user_sex user_status user_age current\n##         <int>      <int>    <int>   <int> <chr>    <chr>          <dbl>   <int>\n##  1      34034          1        1   31105 female   guest           28.2       1\n##  2      34104          1        1   31164 male     registered      19.4       1\n##  3      34326          1        1   31392 female   guest           17         0\n##  4      34343          1        1   31397 male     guest           22         1\n##  5      34765          1        1   31770 female   guest           44         1\n##  6      34796          1        1   31796 female   guest           35.9       0\n##  7      34806          1        1   31798 female   guest           35         0\n##  8      34822          1        1   31802 female   guest           58         1\n##  9      34864          1        1   31820 male     guest           20         0\n## 10      35014          1        1   31921 female   student         39.2       1\n## # … with 14 more rows, and 7 more variables: past <int>, name <chr>,\n## #   good <int>, country <chr>, text <chr>, good_borzoi <int>, time <chr>"},{"path":"tidyr.html","id":"glossary-tidyr","chapter":"6 Tidy Data","heading":"6.9 Glossary","text":"","code":""},{"path":"tidyr.html","id":"exercises-tidyr","chapter":"6 Tidy Data","heading":"6.10 Exercises","text":"Download exercises. See answers attempted questions.","code":"\n# run this to access the exercise\nreprores::exercise(6)\n\n# run this to access the answers\nreprores::exercise(6, answers = TRUE)"},{"path":"dplyr.html","id":"dplyr","chapter":"7 Data Wrangling","heading":"7 Data Wrangling","text":"","code":""},{"path":"dplyr.html","id":"ilo-dplyr","chapter":"7 Data Wrangling","heading":"7.1 Learning Objectives","text":"","code":""},{"path":"dplyr.html","id":"basic-3","chapter":"7 Data Wrangling","heading":"7.1.1 Basic","text":"able use 6 main dplyr one-table verbs: (video)\nselect()\nfilter()\narrange()\nmutate()\nsummarise()\ngroup_by()\nselect()filter()arrange()mutate()summarise()group_by()able wrangle data chaining tidyr dplyr functions (video)able use additional one-table verbs: (video)\nrename()\ndistinct()\ncount()\nslice()\npull()\nrename()distinct()count()slice()pull()","code":""},{"path":"dplyr.html","id":"intermediate-2","chapter":"7 Data Wrangling","heading":"7.1.2 Intermediate","text":"Fine control select() operations (video)Use window functions (video)","code":""},{"path":"dplyr.html","id":"resources5","chapter":"7 Data Wrangling","heading":"7.2 Resources","text":"Chapter 5: Data Transformation R Data ScienceData transformation cheat sheetChapter 16: Date times R Data Science","code":""},{"path":"dplyr.html","id":"setup-dplyr","chapter":"7 Data Wrangling","heading":"7.3 Setup","text":"","code":"\n# libraries needed for these examples\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(reprores)\nset.seed(8675309) # makes sure random numbers are reproducible"},{"path":"dplyr.html","id":"data-disgust","chapter":"7 Data Wrangling","heading":"7.3.1 The disgust dataset","text":"examples use data reprores::disgust, contains data Three Domain Disgust Scale. participant identified unique user_id questionnaire completion unique id. Look Help dataset see individual questions.","code":"\ndata(\"disgust\", package = \"reprores\")\n\n#disgust <- read_csv(\"https://psyteachr.github.io/reprores/data/disgust.csv\")"},{"path":"dplyr.html","id":"six-main-dplyr-verbs","chapter":"7 Data Wrangling","heading":"7.4 Six main dplyr verbs","text":"data wrangling want psychological data involve tidyr functions learned Chapter 4 six main dplyr verbs: select, filter, arrange, mutate, summarise, group_by.","code":""},{"path":"dplyr.html","id":"select","chapter":"7 Data Wrangling","heading":"7.4.1 select()","text":"Select columns name number.can select column individually, separated commas (e.g., col1, col2). can also select columns two columns separating colon (e.g., start_col:end_col).can select columns number, useful column names long complicated.can use minus symbol unselect columns, leaving columns. want exclude span columns, put parentheses around span first (e.g., -(moral1:moral7), -moral1:moral7).","code":"\nmoral <- disgust %>% select(user_id, moral1:moral7)\nnames(moral)## [1] \"user_id\" \"moral1\"  \"moral2\"  \"moral3\"  \"moral4\"  \"moral5\"  \"moral6\" \n## [8] \"moral7\"\nsexual <- disgust %>% select(2, 11:17)\nnames(sexual)## [1] \"user_id\" \"sexual1\" \"sexual2\" \"sexual3\" \"sexual4\" \"sexual5\" \"sexual6\"\n## [8] \"sexual7\"\npathogen <- disgust %>% select(-id, -date, -(moral1:sexual7))\nnames(pathogen)## [1] \"user_id\"   \"pathogen1\" \"pathogen2\" \"pathogen3\" \"pathogen4\" \"pathogen5\"\n## [7] \"pathogen6\" \"pathogen7\""},{"path":"dplyr.html","id":"select_helpers","chapter":"7 Data Wrangling","heading":"7.4.1.1 Select helpers","text":"can select columns based criteria column names.","code":""},{"path":"dplyr.html","id":"starts_with","chapter":"7 Data Wrangling","heading":"7.4.1.1.1 starts_with()","text":"Select columns start character string.","code":"\nu <- disgust %>% select(starts_with(\"u\"))\nnames(u)## [1] \"user_id\""},{"path":"dplyr.html","id":"ends_with","chapter":"7 Data Wrangling","heading":"7.4.1.1.2 ends_with()","text":"Select columns end character string.","code":"\nfirstq <- disgust %>% select(ends_with(\"1\"))\nnames(firstq)## [1] \"moral1\"    \"sexual1\"   \"pathogen1\""},{"path":"dplyr.html","id":"contains","chapter":"7 Data Wrangling","heading":"7.4.1.1.3 contains()","text":"Select columns contain character string.","code":"\npathogen <- disgust %>% select(contains(\"pathogen\"))\nnames(pathogen)## [1] \"pathogen1\" \"pathogen2\" \"pathogen3\" \"pathogen4\" \"pathogen5\" \"pathogen6\"\n## [7] \"pathogen7\""},{"path":"dplyr.html","id":"num_range","chapter":"7 Data Wrangling","heading":"7.4.1.1.4 num_range()","text":"Select columns name matches pattern prefix.Use width set number digits leading\nzeros. example, num_range('var_', 8:10, width=2) selects columns var_08, var_09, var_10.","code":"\nmoral2_4 <- disgust %>% select(num_range(\"moral\", 2:4))\nnames(moral2_4)## [1] \"moral2\" \"moral3\" \"moral4\""},{"path":"dplyr.html","id":"filter","chapter":"7 Data Wrangling","heading":"7.4.2 filter()","text":"Select rows matching column criteria.Select rows user_id 1 (Lisa).Remember use == = check two things equivalent. single = assigns righthand value lefthand variable (usually) evaluates TRUE.can select multiple criteria separating commas.can use symbols &, |, ! mean \"\", \"\", \"\". can also use operators make equations.","code":"\ndisgust %>% filter(user_id == 1)\namoral <- disgust %>% filter(\n  moral1 == 0, \n  moral2 == 0,\n  moral3 == 0, \n  moral4 == 0,\n  moral5 == 0,\n  moral6 == 0,\n  moral7 == 0\n)\n# everyone who chose either 0 or 7 for question moral1\nmoral_extremes <- disgust %>% \n  filter(moral1 == 0 | moral1 == 7)\n\n# everyone who chose the same answer for all moral questions\nmoral_consistent <- disgust %>% \n  filter(\n    moral2 == moral1 & \n    moral3 == moral1 & \n    moral4 == moral1 &\n    moral5 == moral1 &\n    moral6 == moral1 &\n    moral7 == moral1\n  )\n\n# everyone who did not answer 7 for all 7 moral questions\nmoral_no_ceiling <- disgust %>%\n  filter(moral1+moral2+moral3+moral4+moral5+moral6+moral7 != 7*7)"},{"path":"dplyr.html","id":"match-operator","chapter":"7 Data Wrangling","heading":"7.4.2.1 Match operator (%in%)","text":"Sometimes need exclude participant IDs reasons described code. match operator (%%) useful testing column value list. Surround equation parentheses put ! front test value list.","code":"\nno_researchers <- disgust %>%\n  filter(!(user_id %in% c(1,2)))"},{"path":"dplyr.html","id":"dates","chapter":"7 Data Wrangling","heading":"7.4.2.2 Dates","text":"can use lubridate package work dates. example, can use year() function return just year date column select data collected 2010.Table 7.1: Rows 1-6 disgust2010Or select data least 5 years ago. can use range function check minimum maximum dates resulting dataset.","code":"\ndisgust2010 <- disgust %>%\n  filter(year(date) == 2010)\ndisgust_5ago <- disgust %>%\n  filter(date < today() - dyears(5))\n\nrange(disgust_5ago$date)## [1] \"2008-07-10\" \"2016-08-04\""},{"path":"dplyr.html","id":"arrange","chapter":"7 Data Wrangling","heading":"7.4.3 arrange()","text":"Sort dataset using arrange(). find needing sort data R much less Excel, since need rows next order , example, calculate group means. arrange() can useful preparing data display tables.Table 7.2: Rows 1-6 disgust_orderReverse order using desc()Table 7.3: Rows 1-6 disgust_order_desc","code":"\ndisgust_order <- disgust %>%\n  arrange(date, moral1)\ndisgust_order_desc <- disgust %>%\n  arrange(desc(date))"},{"path":"dplyr.html","id":"mutate","chapter":"7 Data Wrangling","heading":"7.4.4 mutate()","text":"Add new columns. one useful functions tidyverse.Refer columns names (unquoted). can add one column mutate function, just separate columns comma. make new column, can use column definitions e.g., total ).Table 7.4: Rows 1-6 disgust_totalYou can overwrite column giving new column name old column (see user_id) . Make sure mean trying use old column value redefine .","code":"\ndisgust_total <- disgust %>%\n  mutate(\n    pathogen = pathogen1 + pathogen2 + pathogen3 + pathogen4 + pathogen5 + pathogen6 + pathogen7,\n    moral = moral1 + moral2 + moral3 + moral4 + moral5 + moral6 + moral7,\n    sexual = sexual1 + sexual2 + sexual3 + sexual4 + sexual5 + sexual6 + sexual7,\n    total = pathogen + moral + sexual,\n    user_id = paste0(\"U\", user_id)\n  )"},{"path":"dplyr.html","id":"summarise","chapter":"7 Data Wrangling","heading":"7.4.5 summarise()","text":"Create summary statistics dataset. Check Data Wrangling Cheat Sheet Data Transformation Cheat Sheet various summary functions. common ones : mean(), sd(), n(), sum(), quantile().Table 7.5: rows disgust_summary","code":"\ndisgust_summary<- disgust_total %>%\n  summarise(\n    n = n(),\n    q25 = quantile(total, .25, na.rm = TRUE),\n    q50 = quantile(total, .50, na.rm = TRUE),\n    q75 = quantile(total, .75, na.rm = TRUE),\n    avg_total = mean(total, na.rm = TRUE),\n    sd_total  = sd(total, na.rm = TRUE),\n    min_total = min(total, na.rm = TRUE),\n    max_total = max(total, na.rm = TRUE)\n  )"},{"path":"dplyr.html","id":"group_by","chapter":"7 Data Wrangling","heading":"7.4.6 group_by()","text":"Create subsets data. can use create summaries,\nlike mean value experimental groups., use mutate create new column called year, group year, calculate average scores.Table 7.6: rows disgust_groupsIf add .groups = \"drop\" end summarise() function, get following message: \"summarise() ungrouping output (override .groups argument)\". just reminds groups still effect functions also grouped.Older versions dplyr , older code generate warning run newer version dplyr. Older code might ungroup() summarise() indicate groupings dropped. default behaviour usually correct, need worry, best explicitly set .groups summarise() function group_by() want \"keep\" \"drop\" groupings.can use filter group_by. following example returns lowest total score year (.e., row rank() value column total equivalent 1).Table 7.7: rows disgust_lowestYou can also use mutate group_by. following example calculates subject-mean-centered scores grouping scores user_id subtracting group-specific mean score. Note use gather tidy data long format first.Use ungroup() soon done grouped functions, otherwise data table still grouped use future.Table 7.8: Rows 1-6 disgust_smc","code":"\ndisgust_groups <- disgust_total %>%\n  mutate(year = year(date)) %>%\n  group_by(year) %>%\n  summarise(\n    n = n(),\n    avg_total = mean(total, na.rm = TRUE),\n    sd_total  = sd(total, na.rm = TRUE),\n    min_total = min(total, na.rm = TRUE),\n    max_total = max(total, na.rm = TRUE),\n    .groups = \"drop\"\n  )\ndisgust_lowest <- disgust_total %>%\n  mutate(year = year(date)) %>%\n  select(user_id, year, total) %>%\n  group_by(year) %>%\n  filter(rank(total) == 1) %>%\n  arrange(year)\ndisgust_smc <- disgust %>%\n  gather(\"question\", \"score\", moral1:pathogen7) %>%\n  group_by(user_id) %>%\n  mutate(score_smc = score - mean(score, na.rm = TRUE)) %>% \n  ungroup()"},{"path":"dplyr.html","id":"all-together","chapter":"7 Data Wrangling","heading":"7.4.7 All Together","text":"lot easier data tidy, first. can use group_by calculate domain scores., can spread 3 domains, calculate total score, remove rows missing (NA) total, calculate mean values year.Table 7.9: Rows 1-6 disgust_tidyTable 7.10: Rows 1-6 disgust_scoredTable 7.11: Rows 1-6 disgust_summarised","code":"\ndisgust_tidy <- reprores::disgust %>%\n  gather(\"question\", \"score\", moral1:pathogen7) %>%\n  separate(question, c(\"domain\",\"q_num\"), sep = -1) %>%\n  group_by(id, user_id, date, domain) %>%\n  summarise(score = mean(score), .groups = \"drop\")\ndisgust_scored <- disgust_tidy %>%\n  spread(domain, score) %>%\n  mutate(\n    total = moral + sexual + pathogen,\n    year = year(date)\n  ) %>%\n  filter(!is.na(total)) %>%\n  arrange(user_id) \ndisgust_summarised <- disgust_scored %>%\n  group_by(year) %>%\n  summarise(\n    n = n(),\n    avg_pathogen = mean(pathogen),\n    avg_moral = mean(moral),\n    avg_sexual = mean(sexual),\n    first_user = first(user_id),\n    last_user = last(user_id),\n    .groups = \"drop\"\n  )"},{"path":"dplyr.html","id":"additional-dplyr-one-table-verbs","chapter":"7 Data Wrangling","heading":"7.5 Additional dplyr one-table verbs","text":"Use code examples help pages figure following one-table verbs . pretty self-explanatory names.","code":""},{"path":"dplyr.html","id":"rename","chapter":"7 Data Wrangling","heading":"7.5.1 rename()","text":"can rename columns rename(). Set argument name new name, value old name. need put name quotes backticks follow rules good variable name (contains letter, numbers, underscores, full stops; start number).Almost everyone gets confused point rename() tries put original names left new names right. Try see error message looks like.","code":"\nsw <- starwars %>%\n  rename(Name = name,\n         Height = height,\n         Mass = mass,\n         `Hair Colour` = hair_color,\n         `Skin Colour` = skin_color,\n         `Eye Colour` = eye_color,\n         `Birth Year` = birth_year)\n\nnames(sw)##  [1] \"Name\"        \"Height\"      \"Mass\"        \"Hair Colour\" \"Skin Colour\"\n##  [6] \"Eye Colour\"  \"Birth Year\"  \"sex\"         \"gender\"      \"homeworld\"  \n## [11] \"species\"     \"films\"       \"vehicles\"    \"starships\""},{"path":"dplyr.html","id":"distinct","chapter":"7 Data Wrangling","heading":"7.5.2 distinct()","text":"Get rid exactly duplicate rows distinct(). can helpful , example, merging data multiple computers data got copied one computer another, creating duplicate rows.","code":"\n# create a data table with duplicated values\ndupes <- tibble(\n  id = c( 1,   2,   1,   2,   1,   2),\n  dv = c(\"A\", \"B\", \"C\", \"D\", \"A\", \"B\")\n)\n\ndistinct(dupes)"},{"path":"dplyr.html","id":"count","chapter":"7 Data Wrangling","heading":"7.5.3 count()","text":"function count() quick shortcut common combination group_by() summarise() used count number rows per group.","code":"\nstarwars %>%\n  group_by(sex) %>%\n  summarise(n = n(), .groups = \"drop\")\ncount(starwars, sex)"},{"path":"dplyr.html","id":"slice","chapter":"7 Data Wrangling","heading":"7.5.4 slice()","text":"","code":"\nslice(starwars, 1:3, 10)"},{"path":"dplyr.html","id":"pull","chapter":"7 Data Wrangling","heading":"7.5.5 pull()","text":"","code":"\nstarwars %>%\n  filter(species == \"Droid\") %>%\n  pull(name)## [1] \"C-3PO\"  \"R2-D2\"  \"R5-D4\"  \"IG-88\"  \"R4-P17\" \"BB8\""},{"path":"dplyr.html","id":"window","chapter":"7 Data Wrangling","heading":"7.6 Window functions","text":"Window functions use order rows calculate values. can use things require ranking ordering, like choose top scores class, accessing previous next rows, like calculating cumulative sums means.dplyr window functions vignette good detailed explanations functions, described useful ones .","code":""},{"path":"dplyr.html","id":"ranking-functions","chapter":"7 Data Wrangling","heading":"7.6.1 Ranking functions","text":"Table 6.1: rows gradesWhat differences among row_number(), rank(), min_rank(), dense_rank(), ntile()?row_number() need argument?happen gave argument grade class?think happen removed group_by(class) line ?added id grouping?happens change order rows?second argument ntile() ?can use window functions group data quantiles.Table 7.12: rows sw_massWhy row NA values? get rid ?","code":"\ngrades <- tibble(\n  id = 1:5,\n  \"Data Skills\" = c(16, 17, 17, 19, 20), \n  \"Statistics\"  = c(14, 16, 18, 18, 19)\n) %>%\n  gather(class, grade, 2:3) %>%\n  group_by(class) %>%\n  mutate(row_number = row_number(),\n         rank       = rank(grade),\n         min_rank   = min_rank(grade),\n         dense_rank = dense_rank(grade),\n         quartile   = ntile(grade, 4),\n         percentile = ntile(grade, 100))\nsw_mass <- starwars %>%\n  group_by(tertile = ntile(mass, 3)) %>%\n  summarise(min = min(mass),\n            max = max(mass),\n            mean = mean(mass),\n            .groups = \"drop\")"},{"path":"dplyr.html","id":"offset-functions","chapter":"7 Data Wrangling","heading":"7.6.2 Offset functions","text":"function lag() gives previous row's value. defaults 1 row back, can change n argument. function lead() gives values ahead current row.Table 7.13: rows lag_leadYou can use offset functions calculate change trials value changes. Use order_by argument specify order rows. Alternatively, can use arrange() offset functions.Table 7.14: rows trialsLook help pages lag() lead().happens remove order_by argument change cond?default argument ?Can think circumstances data might need use lag() lead()?","code":"\nlag_lead <- tibble(x = 1:6) %>%\n  mutate(lag = lag(x),\n         lag2 = lag(x, n = 2),\n         lead = lead(x, default = 0))\ntrials <- tibble(\n  trial = sample(1:10, 10),\n  cond = sample(c(\"exp\", \"ctrl\"), 10, T),\n  score = rpois(10, 4)\n) %>%\n  mutate(\n    score_change = score - lag(score, order_by = trial),\n    change_cond = cond != lag(cond, order_by = trial, \n                              default = \"no condition\")\n  ) %>%\n  arrange(trial)"},{"path":"dplyr.html","id":"cumulative-aggregates","chapter":"7 Data Wrangling","heading":"7.6.3 Cumulative aggregates","text":"cumsum(), cummin(), cummax() base R functions calculating cumulative means, minimums, maximums. dplyr package introduces cumany() cumall(), return TRUE previous values meet criteria.Table 7.15: rows cumulativeWhat happen change cumany(obs == 3) cumany(obs > 2)?happen change cumall(obs < 4) cumall(obs < 2)?Can think circumstances data might need use cumany() cumall()?","code":"\ncumulative <- tibble(\n  time = 1:10,\n  obs = c(2, 2, 1, 2, 4, 3, 1, 0, 3, 5)\n) %>%\n  mutate(\n    cumsum = cumsum(obs),\n    cummin = cummin(obs),\n    cummax = cummax(obs),\n    cumany = cumany(obs == 3),\n    cumall = cumall(obs < 4)\n  )"},{"path":"dplyr.html","id":"glossary-dplyr","chapter":"7 Data Wrangling","heading":"7.7 Glossary","text":"","code":""},{"path":"dplyr.html","id":"exercises-dplyr","chapter":"7 Data Wrangling","heading":"7.8 Exercises","text":"Download exercises. See answers attempted questions.","code":"\n# run this to access the exercise\nreprores::exercise(7)\n\n# run this to access the answers\nreprores::exercise(7, answers = TRUE)"},{"path":"glm.html","id":"glm","chapter":"8 Introduction to GLM","heading":"8 Introduction to GLM","text":"","code":""},{"path":"glm.html","id":"ilo9","chapter":"8 Introduction to GLM","heading":"8.1 Learning Objectives","text":"","code":""},{"path":"glm.html","id":"basic-4","chapter":"8 Introduction to GLM","heading":"8.1.1 Basic","text":"Define components GLMSimulate data using GLM equations (video)Identify model parameters correspond data-generation parametersUnderstand plot residuals (video)Predict new values using model (video)Explain differences among coding schemes (video)","code":""},{"path":"glm.html","id":"intermediate-3","chapter":"8 Introduction to GLM","heading":"8.1.2 Intermediate","text":"Demonstrate relationships among two-sample t-test, one-way ANOVA, linear regressionGiven data GLM, generate decomposition matrix calculate sums squares, mean squares, F ratios one-way ANOVA","code":""},{"path":"glm.html","id":"resources9","chapter":"8 Introduction to GLM","heading":"8.2 Resources","text":"Jeff Miller Patricia Haden, Statistical Analysis Linear Model (free online textbook)lecture slides introducing General Linear ModelGLM shiny appF distribution","code":""},{"path":"glm.html","id":"setup9","chapter":"8 Introduction to GLM","heading":"8.3 Setup","text":"","code":"\n# libraries needed for these examples\nlibrary(tidyverse)\nlibrary(broom)\nset.seed(30250) # makes sure random numbers are reproducible"},{"path":"glm.html","id":"glm-1","chapter":"8 Introduction to GLM","heading":"8.4 GLM","text":"","code":""},{"path":"glm.html","id":"what-is-the-glm","chapter":"8 Introduction to GLM","heading":"8.4.1 What is the GLM?","text":"General Linear Model (GLM) general mathematical framework expressing relationships among variables can express test linear relationships numerical dependent variable combination categorical continuous independent variables.","code":""},{"path":"glm.html","id":"glm-components","chapter":"8 Introduction to GLM","heading":"8.4.2 Components","text":"mathematical conventions need learn understand equations representing linear models. understand , learning GLM get much easier.linear equation predicts dependent variable (\\(Y\\)) sum grand average value \\(Y\\) (\\(\\mu\\), also called intercept), main effects predictor variables (\\(+B+C+ \\ldots\\)), interactions among predictor variables (\\(AB, AC, BC, ABC, \\ldots\\)), random error (\\(S(Group)\\)). equation model two predictor variables (\\(\\) \\(B\\)) interaction (\\(AB\\)) written like :\\(Y\\) ~ \\(\\mu++B+AB+S(Group)\\)worry make sense walk concrete example.","code":""},{"path":"glm.html","id":"sim-glm","chapter":"8 Introduction to GLM","heading":"8.4.3 Simulating data from GLM","text":"good way learn linear models simulate data know exactly variables related, analyse simulated data see parameters show analysis.start simple linear model just single categorical factor two levels. say predicting reaction times congruent incongruent trials Stroop task single participant. Average reaction time (mu) 800ms, 50ms faster congruent incongruent trials (effect).factor categorical variable used divide subjects groups, usually draw comparison. Factors composed different levels. confuse factors levels!example , trial type factorlevel, incongrunt factorlevel, congruent factorlevel.need represent categorical factors numbers. numbers, coding scheme choose affect numbers get analysis need interpret . , effect code trial types congruent trials coded +0.5, incongruent trials coded -0.5.person always respond exactly way. might little faster trials others, due random fluctuations attention, learning task, fatigue. can add error term trial. know much specific trial differ, can characterise distribution much trials differ average sample distribution., assume error term sampled normal distribution standard deviation 100 ms (mean error term distribution always 0). also sample 100 trials type, can see range variation.first create variables parameters describe data.simulate data creating data table row trial columns trial type error term (random numbers samples normal distribution SD specified error_sd). categorical variables, include column text labels (trial_type) another column coded version (trial_type.e) make easier check codings mean use graphing. Calculate dependent variable (RT) sum grand mean (mu), coefficient (effect) multiplied effect-coded predictor variable (trial_type.e), error term.!!! (triple bang) code recode(trial_type, !!!trial_types) way expand vector trial_types <- c(\"congruent\" = 0.5, \"incongruent\" = -0.5). equivalent recode(trial_type, \"congruent\" = 0.5, \"incongruent\" = -0.5). pattern avoids making mistakes recoding one place set category code mapping (trial_types vector).Last least, always plot simulated data make sure looks like expect.\nFigure 8.1: Simulated Data\n","code":"\nn_per_grp <- 100\nmu <- 800 # average RT\neffect <- 50 # average difference between congruent and incongruent trials\nerror_sd <- 100 # standard deviation of the error term\ntrial_types <- c(\"congruent\" = 0.5, \"incongruent\" = -0.5) # effect code\ndat <- data.frame(\n  trial_type = rep(names(trial_types), each = n_per_grp)\n) %>%\n  mutate(\n    trial_type.e = recode(trial_type, !!!trial_types),\n    error = rnorm(nrow(.), 0, error_sd),\n    RT = mu + effect*trial_type.e + error\n  )\nggplot(dat, aes(trial_type, RT)) + \n  geom_violin() +\n  geom_boxplot(aes(fill = trial_type), \n               width = 0.25, show.legend = FALSE)"},{"path":"glm.html","id":"linear-regression","chapter":"8 Introduction to GLM","heading":"8.4.4 Linear Regression","text":"Now can analyse data simulated using function lm(). takes formula first argument. data-generating equation, can omit error term (implied), takes data table second argument. Use summary() function see statistical summary.Notice estimate (Intercept) close value set mu estimate trial_type.e close value set effect.Change values mu effect, resimulate data, re-run linear model. happens estimates?","code":"\nmy_lm <- lm(RT ~ trial_type.e, data = dat)\nsummary(my_lm)## \n## Call:\n## lm(formula = RT ~ trial_type.e, data = dat)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -302.110  -70.052    0.948   68.262  246.220 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   788.192      7.206 109.376  < 2e-16 ***\n## trial_type.e   61.938     14.413   4.297 2.71e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 101.9 on 198 degrees of freedom\n## Multiple R-squared:  0.08532,    Adjusted R-squared:  0.0807 \n## F-statistic: 18.47 on 1 and 198 DF,  p-value: 2.707e-05"},{"path":"glm.html","id":"residuals","chapter":"8 Introduction to GLM","heading":"8.4.5 Residuals","text":"can use residuals() function extract error term data point. DV values, minus estimates intercept trial type. make density plot residuals compare normal distribution used error term.\nFigure 8.2: Model residuals approximately normally distributed group\ncan also compare model residuals simulated error values. model accurate, almost identical. intercept estimate slightly , points slightly black line. estimate effect trial type slightly , small, systematic difference residuals congruent incongruent trials.\nFigure 8.3: Model residuals similar simulated error\nhappens residuals fit model ignores trial type (e.g., lm(Y ~ 1, data = dat))?","code":"\nres <- residuals(my_lm)\nggplot(dat) + \n  stat_function(aes(0), color = \"grey60\",\n                fun = dnorm, n = 101,\n                args = list(mean = 0, sd = error_sd)) +\n  geom_density(aes(res, color = trial_type))\nggplot(dat) +\n  geom_abline(slope = 1) +\n  geom_point(aes(error, res,color = trial_type)) +\n  ylab(\"Model Residuals\") +\n  xlab(\"Simulated Error\")"},{"path":"glm.html","id":"predict","chapter":"8 Introduction to GLM","heading":"8.4.6 Predict New Values","text":"can use estimates model predict new data points, given values model parameters. simple example, just need know trial type make prediction.congruent trials, predict new data point equal intercept estimate plus trial type estimate multiplied 0.5 (effect code congruent trials).can also use predict() function easily. second argument data table columns factors model rows values want use prediction.look function using ?predict, see \"function invokes particular methods depend class first argument.\"\nmeans predict() works differently depending whether predicting output lm() analysis functions. can search help lm version ?predict.lm.","code":"\nint_est <- my_lm$coefficients[[\"(Intercept)\"]]\ntt_est  <- my_lm$coefficients[[\"trial_type.e\"]]\ntt_code <- trial_types[[\"congruent\"]]\nnew_congruent_RT <- int_est + tt_est * tt_code\nnew_congruent_RT## [1] 819.1605\npredict(my_lm, newdata = tibble(trial_type.e = 0.5))##        1 \n## 819.1605"},{"path":"glm.html","id":"coding-schemes","chapter":"8 Introduction to GLM","heading":"8.4.7 Coding Categorical Variables","text":"example , used effect coding trial type. can also use sum coding, assigns +1 -1 levels instead +0.5 -0.5. commonly, might want use treatment coding, assigns 0 one level (usually baseline control condition) 1 level (usually treatment experimental condition).add sum-coded treatment-coded versions trial_type dataset using recode() function.define named vectors levels coding, can use recode() function expand using !!!.coefficients effect-coded version. last analysis.coefficients sum-coded version. give results effect coding, except estimate categorical factor exactly half large, represents difference trial type hypothetical condition 0 (overall mean RT), rather difference two trial types.coefficients treatment-coded version. estimate categorical factor effect-coded version, intercept decrease. equal intercept minus estimate trial type sum-coded version.","code":"\ndat <- dat %>% mutate(\n  trial_type.sum = recode(trial_type, \"congruent\" = +1, \"incongruent\" = -1),\n  trial_type.tr = recode(trial_type, \"congruent\" = 1, \"incongruent\" = 0)\n)\ntt_sum <- c(\"congruent\"   = +1, \n            \"incongruent\" = -1)\ntt_tr <- c(\"congruent\"   = 1, \n           \"incongruent\" = 0)\ndat <- dat %>% mutate(\n  trial_type.sum = recode(trial_type, !!!tt_sum),\n  trial_type.tr = recode(trial_type, !!!tt_tr)\n)\nlm(RT ~ trial_type.e, data = dat)$coefficients##  (Intercept) trial_type.e \n##    788.19166     61.93773\nlm(RT ~ trial_type.sum, data = dat)$coefficients##    (Intercept) trial_type.sum \n##      788.19166       30.96887\nlm(RT ~ trial_type.tr, data = dat)$coefficients##   (Intercept) trial_type.tr \n##     757.22279      61.93773"},{"path":"glm.html","id":"test-rels","chapter":"8 Introduction to GLM","heading":"8.5 Relationships among tests","text":"","code":""},{"path":"glm.html","id":"t-test-t-test-glm","chapter":"8 Introduction to GLM","heading":"8.5.1 T-test {t-test-glm}","text":"t-test just special, limited example general linear model.happens use codings trial type t-test ? coding maps onto results t-test best?","code":"\nt.test(RT ~ trial_type.e, data = dat, var.equal = TRUE)## \n##  Two Sample t-test\n## \n## data:  RT by trial_type.e\n## t = -4.2975, df = 198, p-value = 2.707e-05\n## alternative hypothesis: true difference in means between group -0.5 and group 0.5 is not equal to 0\n## 95 percent confidence interval:\n##  -90.35945 -33.51601\n## sample estimates:\n## mean in group -0.5  mean in group 0.5 \n##           757.2228           819.1605"},{"path":"glm.html","id":"anova","chapter":"8 Introduction to GLM","heading":"8.5.2 ANOVA","text":"ANOVA also special, limited version linear model.easiest way get parameters analysis use broom::tidy() function. returns tidy table can extract numbers interest . , just want get F-value effect trial_type. Compare square root value t-value t-tests .","code":"\nmy_aov <- aov(RT ~ trial_type.e, data = dat)\nsummary(my_aov, intercept = TRUE)##               Df    Sum Sq   Mean Sq  F value   Pr(>F)    \n## (Intercept)    1 124249219 124249219 11963.12  < 2e-16 ***\n## trial_type.e   1    191814    191814    18.47 2.71e-05 ***\n## Residuals    198   2056432     10386                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nf <- broom::tidy(my_aov)$statistic[1]\nsqrt(f)## [1] 4.297498"},{"path":"glm.html","id":"understanding-anova","chapter":"8 Introduction to GLM","heading":"8.6 Understanding ANOVA","text":"walk example one-way ANOVA following equation:\\(Y_{ij} = \\mu + A_i + S()_{ij}\\)means data point (\\(Y_{ij}\\)) predicted sum grand mean (\\(\\mu\\)), plus effect factor (\\(A_i\\)), plus residual error (\\(S()_{ij}\\)).","code":""},{"path":"glm.html","id":"means-variability-and-deviation-scores","chapter":"8 Introduction to GLM","heading":"8.6.1 Means, Variability, and Deviation Scores","text":"create simple simulation function can quickly create two-sample dataset specified Ns, means, SDs.Now use two_sample() create dataset dat N=5 per group, means -2 +2, SDs 1 1 (yes, effect size d = 4).can calculate data point (Y) deviates overall sample mean (\\(\\hat{\\mu}\\)), represented horizontal grey line deviations vertical grey lines. can also calculate different point group-specific mean (\\(\\hat{A_i}\\)), represented horizontal coloured lines deviations coloured vertical lines.\nFigure 8.4: Deviations data point (Y) overall group means\ncan use deviations calculate variability groups within groups. ANOVA tests whether variability groups larger within groups, accounting number groups observations.","code":"\ntwo_sample <- function(n = 10, m1 = 0, m2 = 0, sd1 = 1, sd2 = 1) {\n  s1 <- rnorm(n, m1, sd1)\n  s2 <- rnorm(n, m2, sd2)\n  \n  data.frame(\n    Y = c(s1, s2),\n    grp = rep(c(\"A\", \"B\"), each = n)\n  )\n}\ndat <- two_sample(5, -2, +2, 1, 1)"},{"path":"glm.html","id":"decomp","chapter":"8 Introduction to GLM","heading":"8.6.2 Decomposition matrices","text":"can use estimation equations one-factor ANOVA calculate model components.mu overall meana different group mean overall meanerr residual error, calculated subtracting mu YThis produces decomposition matrix, table columns Y, mu, , err.Calculate sums squares mu, , err.done everything right, SS$mu + SS$+ SS$err equal sum squares Y.Divide sum squares corresponding degrees freedom (df) calculate mean squares. df mu 1, df factor K-1 (K number groups), df err N - K (N number observations).calculate F-ratio mu dividing mean squares error term mean square. Get p-values correspond F-values using pf() function.Put everything data frame display way ANOVA summary function.Now run one-way ANOVA results compare obtained calculations.Using code , write function takes table data returns ANOVA results table like .","code":"\ndecomp <- dat %>% \n  select(Y, grp) %>%\n  mutate(mu = mean(Y)) %>%     # calculate mu_hat\n  group_by(grp) %>%\n  mutate(a = mean(Y) - mu) %>% # calculate a_hat for each grp\n  ungroup() %>%\n  mutate(err = Y - mu - a)     # calculate residual error\nSS <- decomp %>%\n  summarise(mu = sum(mu*mu),\n            a = sum(a*a),\n            err = sum(err*err))\nSS_Y <- sum(decomp$Y^2)\nall.equal(SS_Y, SS$mu + SS$a + SS$err)## [1] TRUE\nK <- n_distinct(dat$grp)\nN <- nrow(dat)\ndf <- c(mu = 1, a = K - 1, err = N - K)\nMS <- SS / df\nF_mu <- MS$mu / MS$err\nF_a  <- MS$a  / MS$err\np_mu <- pf(F_mu, df1 = df['mu'], df2 = df['err'], lower.tail = FALSE)\np_a  <- pf(F_a,  df1 = df['a'],  df2 = df['err'], lower.tail = FALSE)\nmy_calcs <- data.frame(\n  term = c(\"Intercept\", \"grp\", \"Residuals\"),\n  Df = df,\n  SS = c(SS$mu, SS$a, SS$err),\n  MS = c(MS$mu, MS$a, MS$err),\n  F = c(F_mu, F_a, NA),\n  p = c(p_mu, p_a, NA)\n)\naov(Y ~ grp, data = dat) %>% summary(intercept = TRUE)##             Df Sum Sq Mean Sq F value  Pr(>F)   \n## (Intercept)  1  0.146   0.146   0.144 0.71427   \n## grp          1 23.516  23.516  23.214 0.00132 **\n## Residuals    8  8.104   1.013                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"glm.html","id":"glossary-glm","chapter":"8 Introduction to GLM","heading":"8.7 Glossary","text":"","code":""},{"path":"glm.html","id":"exercises-glm","chapter":"8 Introduction to GLM","heading":"8.8 Exercises","text":"Download exercises. See answers attempted questions.","code":"\n# run this to access the exercise\nreprores::exercise(8)\n\n# run this to access the answers\nreprores::exercise(8, answers = TRUE)"},{"path":"func.html","id":"func","chapter":"9 Iteration & Functions","heading":"9 Iteration & Functions","text":"","code":""},{"path":"func.html","id":"ilo7","chapter":"9 Iteration & Functions","heading":"9.1 Learning Objectives","text":"learn functions iteration using simulation calculate power analysis independent samples t-test.","code":""},{"path":"func.html","id":"basic-5","chapter":"9 Iteration & Functions","heading":"9.1.1 Basic","text":"Work basic iteration functions rep, seq, replicate (video)Use map() apply() functions (video)Write custom functions function() (video)Set default values arguments functions","code":""},{"path":"func.html","id":"intermediate-4","chapter":"9 Iteration & Functions","heading":"9.1.2 Intermediate","text":"Understand scopeUse error handling warnings function","code":""},{"path":"func.html","id":"advanced-1","chapter":"9 Iteration & Functions","heading":"9.1.3 Advanced","text":"topics (yet) covered materials, directions independent learning.Repeat commands multiple arguments using purrr::map2_*() purrr::pmap_*()Create nested data frames using dplyr::group_by() tidyr::nest()Work nested data frames dplyrCapture deal errors using 'adverb' functions purrr::safely() purrr::possibly()","code":""},{"path":"func.html","id":"resources7","chapter":"9 Iteration & Functions","heading":"9.2 Resources","text":"Chapters 19 21 R Data ScienceRStudio Apply Functions CheatsheetIn next two lectures, going learn iteration (commands ) custom functions data simulation exercise, also lead us traditional statistical topics.","code":""},{"path":"func.html","id":"setup7","chapter":"9 Iteration & Functions","heading":"9.3 Setup","text":"","code":"\n# libraries needed for these examples\nlibrary(tidyverse)  ## contains purrr, tidyr, dplyr\nlibrary(broom) ## converts test output to tidy tables\n\nset.seed(8675309) # makes sure random numbers are reproducible"},{"path":"func.html","id":"iteration-functions","chapter":"9 Iteration & Functions","heading":"9.4 Iteration functions","text":"first learned two basic iteration functions, rep() seq() Working Data chapter.","code":""},{"path":"func.html","id":"rep","chapter":"9 Iteration & Functions","heading":"9.4.1 rep()","text":"function rep() lets repeat first argument number times.Use rep() create vector alternating \"\" \"B\" values length 24.specify second argument , defaults times, repeating vector first argument many times. Make vector , setting second argument explicitly.second argument vector length first argument, element first vector repeated many times. Use rep() create vector 11 \"\" values followed 3 \"B\" values.can repeat element vector sepcified number times using argument, Use rep() create vector 12 \"\" values followed 12 \"B\" values.think happen set times 3 2?","code":"\nrep(c(\"A\", \"B\"), 12)##  [1] \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\"\n## [20] \"B\" \"A\" \"B\" \"A\" \"B\"\nrep(c(\"A\", \"B\"), times = 12)##  [1] \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\" \"B\" \"A\"\n## [20] \"B\" \"A\" \"B\" \"A\" \"B\"\nrep(c(\"A\", \"B\"), c(11, 3))##  [1] \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"B\"\nrep(c(\"A\", \"B\"), each = 12)##  [1] \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\" \"B\"\n## [20] \"B\" \"B\" \"B\" \"B\" \"B\"\nrep(c(\"A\", \"B\"), times = 3, each = 2)##  [1] \"A\" \"A\" \"B\" \"B\" \"A\" \"A\" \"B\" \"B\" \"A\" \"A\" \"B\" \"B\""},{"path":"func.html","id":"seq","chapter":"9 Iteration & Functions","heading":"9.4.2 seq()","text":"function seq() useful generating sequence numbers pattern.Use seq() create vector integers 0 10.can set argument count numbers 1 (default). Use seq() create vector numbers 0 100 10s.argument length.useful know many steps want divide something . Use seq() create vector starts 0, ends 100, 12 equally spaced steps (hint: many numbers vector 2 steps?).","code":"\nseq(0, 10)##  [1]  0  1  2  3  4  5  6  7  8  9 10\nseq(0, 100, by = 10)##  [1]   0  10  20  30  40  50  60  70  80  90 100\nseq(0, 100, length.out = 13)##  [1]   0.000000   8.333333  16.666667  25.000000  33.333333  41.666667\n##  [7]  50.000000  58.333333  66.666667  75.000000  83.333333  91.666667\n## [13] 100.000000"},{"path":"func.html","id":"replicate","chapter":"9 Iteration & Functions","heading":"9.4.3 replicate()","text":"can use replicate() function run function n times.example, can get 3 sets 5 numbers random normal distribution setting n 3 expr rnorm(5).default, replicate() simplifies result matrix easy convert table function returns vectors length. rather list vectors, set simplify = FALSE.","code":"\nreplicate(n = 3, expr = rnorm(5))##            [,1]       [,2]       [,3]\n## [1,] -0.9965824 0.98721974 -1.5495524\n## [2,]  0.7218241 0.02745393  1.0226378\n## [3,] -0.6172088 0.67287232  0.1500832\n## [4,]  2.0293916 0.57206650 -0.6599640\n## [5,]  1.0654161 0.90367770 -0.9945890\nreplicate(n = 3, expr = rnorm(5), simplify = FALSE)## [[1]]\n## [1]  1.9724587 -0.4418016 -0.9006372 -0.1505882 -0.8278942\n## \n## [[2]]\n## [1]  1.98582582  0.04400503 -0.40428231 -0.47299855 -0.41482324\n## \n## [[3]]\n## [1]  0.6832342  0.6902011  0.5334919 -0.1861048  0.3829458"},{"path":"func.html","id":"map-apply","chapter":"9 Iteration & Functions","heading":"9.4.4 map() and apply() functions","text":"purrr::map() lapply() return list length vector list, element result applying function corresponding element. function much , purrr functions optimisations working tidyverse. working mostly purrr functions course, apply functions common code might see examples web.Imagine want calculate power two-sample t-test mean difference 0.2 SD 1, sample sizes 100 1000 (100s). run power.t.test() function 20 times extract values \"power\" resulting list put table.However, apply() map() functions allow perform function item vector list. First make object n vector sample sizes want test, use lapply() map() run function power.t.test() item. can set arguments power.t.test() function argument.functions return list item result power.t.test(), returns list results includes named item \"power\". special list summary format just print directly:can see individual items using str() function.sapply() version lapply() returns vector array instead list, appropriate. corresponding purrr functions map_dbl(), map_chr(), map_int() map_lgl(), return vectors corresponding data type.can extract value list function [[. usually see written pcalc[[1]], put inside backticks, can use apply map functions.use map_dbl() value \"power\" double.can use map() functions inside mutate() function run power.t.test() function value n row table, extract value \"power\", delete column power calculations.\nFigure 9.1: Power two-sample t-test d = 0.2\n","code":"\np100 <- power.t.test(n = 100, delta = 0.2, sd = 1, type=\"two.sample\")\n# 18 more lines\np1000 <- power.t.test(n = 500, delta = 0.2, sd = 1, type=\"two.sample\")\n\ntibble(\n  n = c(100, \"...\", 1000),\n  power = c(p100$power, \"...\", p1000$power)\n)\nn <- seq(100, 1000, 100)\npcalc <- lapply(n, power.t.test, \n                delta = 0.2, sd = 1, type=\"two.sample\")\n# or\npcalc <- purrr::map(n, power.t.test, \n                delta = 0.2, sd = 1, type=\"two.sample\")\npcalc[[1]]## \n##      Two-sample t test power calculation \n## \n##               n = 100\n##           delta = 0.2\n##              sd = 1\n##       sig.level = 0.05\n##           power = 0.2902664\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group\npcalc[[1]] %>% str()## List of 8\n##  $ n          : num 100\n##  $ delta      : num 0.2\n##  $ sd         : num 1\n##  $ sig.level  : num 0.05\n##  $ power      : num 0.29\n##  $ alternative: chr \"two.sided\"\n##  $ note       : chr \"n is number in *each* group\"\n##  $ method     : chr \"Two-sample t test power calculation\"\n##  - attr(*, \"class\")= chr \"power.htest\"\nsapply(pcalc, `[[`, \"power\")##  [1] 0.2902664 0.5140434 0.6863712 0.8064964 0.8847884 0.9333687 0.9623901\n##  [8] 0.9792066 0.9887083 0.9939638\npurrr::map_dbl(pcalc, `[[`, \"power\")##  [1] 0.2902664 0.5140434 0.6863712 0.8064964 0.8847884 0.9333687 0.9623901\n##  [8] 0.9792066 0.9887083 0.9939638\nmypower <- tibble(\n  n = seq(100, 1000, 100)) %>%\n  mutate(pcalc = purrr::map(n, power.t.test, \n                            delta = 0.2, \n                            sd = 1, \n                            type=\"two.sample\"),\n         power = purrr::map_dbl(pcalc, `[[`, \"power\")) %>%\n  select(-pcalc)"},{"path":"func.html","id":"custom-functions","chapter":"9 Iteration & Functions","heading":"9.5 Custom functions","text":"addition built-functions functions can access packages, can also write functions (eventually even packages!).","code":""},{"path":"func.html","id":"structure-function","chapter":"9 Iteration & Functions","heading":"9.5.1 Structuring a function","text":"general structure function follows:simple function. Can guess ?make function reports p-values APA format (\"p = [rounded value]\" p >= .001 \"p < .001\" p < .001).First, name function. can name anything, try duplicate existing functions overwrite . example, call function rep, need use base::rep() access normal rep function. call p-value function report_p set framework function.","code":"\nfunction_name <- function(my_args) {\n  # process the arguments\n  # return some value\n}\nadd1 <- function(my_number) {\n  my_number + 1\n}\n\nadd1(10)## [1] 11\nreport_p <- function() {\n}"},{"path":"func.html","id":"arguments","chapter":"9 Iteration & Functions","heading":"9.5.2 Arguments","text":"need add one argument, p-value want report. names choose arguments private argument, problem conflict variables script. put arguments parentheses function() order want default (just like built-functions used ).","code":"\nreport_p <- function(p) {\n}"},{"path":"func.html","id":"defaults","chapter":"9 Iteration & Functions","heading":"9.5.3 Argument defaults","text":"can add default value argument. argument skipped, function uses default argument. probably make sense run function without specifying p-value, can add second argument called digits defaults 3, can round p-values number digits.Now need write code inside function process input arguments turn returned output. Put output last item function.might also see returned output inside return() function. thing.run code defining function, output anything, makes new object Environment tab Functions. Now can run function.","code":"\nreport_p <- function(p, digits = 3) {\n}\nreport_p <- function(p, digits = 3) {\n  if (p < .001) {\n    reported = \"p < .001\"\n  } else {\n    roundp <- round(p, digits)\n    reported = paste(\"p =\", roundp)\n  }\n  \n  reported\n}\nreport_p <- function(p, digits = 3) {\n  if (p < .001) {\n    reported = \"p < .001\"\n  } else {\n    roundp <- round(p, digits)\n    reported = paste(\"p =\", roundp)\n  }\n  \n  return(reported)\n}\nreport_p(0.04869)\nreport_p(0.0000023)## [1] \"p = 0.049\"\n## [1] \"p < .001\""},{"path":"func.html","id":"scope","chapter":"9 Iteration & Functions","heading":"9.5.4 Scope","text":"happens function stays function. can change value variable passed function, change value variable outside function, even variable name one function.","code":"\nreported <- \"not changed\"\n\n# inside this function, reported == \"p = 0.002\"\nreport_p(0.0023) \n\nreported # still \"not changed\"## [1] \"p = 0.002\"\n## [1] \"not changed\""},{"path":"func.html","id":"warnings-errors","chapter":"9 Iteration & Functions","heading":"9.5.5 Warnings and errors","text":"might want add specific warning stop running function code someone enters value number. can stop() function.someone enters number possible p-value (0-1), might want warn probably intended, still continue function. can warning().","code":"\nreport_p <- function(p, digits = 3) {\n  if (!is.numeric(p)) stop(\"p must be a number\")\n  if (p <= 0) warning(\"p-values are normally greater than 0\")\n  if (p >= 1) warning(\"p-values are normally less than 1\")\n  \n  if (p < .001) {\n    reported = \"p < .001\"\n  } else {\n    roundp <- round(p, digits)\n    reported = paste(\"p =\", roundp)\n  }\n  \n  reported\n}\nreport_p()## Error in report_p(): argument \"p\" is missing, with no default\nreport_p(\"a\")## Error in report_p(\"a\"): p must be a number\nreport_p(-2)## Warning in report_p(-2): p-values are normally greater than 0\nreport_p(2)## Warning in report_p(2): p-values are normally less than 1## [1] \"p < .001\"\n## [1] \"p = 2\""},{"path":"func.html","id":"iterating-your-own-functions","chapter":"9 Iteration & Functions","heading":"9.6 Iterating your own functions","text":"First, build code want iterate.","code":""},{"path":"func.html","id":"rnorm","chapter":"9 Iteration & Functions","heading":"9.6.1 rnorm()","text":"Create vector 20 random numbers drawn normal distribution mean 5 standard deviation 1 using rnorm() function store variable .","code":"\nA <- rnorm(20, mean = 5, sd = 1)"},{"path":"func.html","id":"tibbletibble","chapter":"9 Iteration & Functions","heading":"9.6.2 tibble::tibble()","text":"tibble type table data.frame. function tibble::tibble() creates tibble column argument. argument takes form column_name = data_vector.Create table called dat including two vectors: vector 20 random normally distributed numbers mean 5 SD 1, B vector 20 random normally distributed numbers mean 5.5 SD 1.","code":"\ndat <- tibble(\n  A = rnorm(20, 5, 1),\n  B = rnorm(20, 5.5, 1)\n)"},{"path":"func.html","id":"t.test","chapter":"9 Iteration & Functions","heading":"9.6.3 t.test()","text":"can run Welch two-sample t-test including two samples made first two arguments function t.test. can reference one column table names using format table_name$column_nameYou can also convert table long format using gather function specify t-test using format dv_column~grouping_column.","code":"\nt.test(dat$A, dat$B)## \n##  Welch Two Sample t-test\n## \n## data:  dat$A and dat$B\n## t = -1.7716, df = 36.244, p-value = 0.08487\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -1.2445818  0.0838683\n## sample estimates:\n## mean of x mean of y \n##  4.886096  5.466453\nlongdat <- gather(dat, group, score, A:B)\n\nt.test(score~group, data = longdat) ## \n##  Welch Two Sample t-test\n## \n## data:  score by group\n## t = -1.7716, df = 36.244, p-value = 0.08487\n## alternative hypothesis: true difference in means between group A and group B is not equal to 0\n## 95 percent confidence interval:\n##  -1.2445818  0.0838683\n## sample estimates:\n## mean in group A mean in group B \n##        4.886096        5.466453"},{"path":"func.html","id":"broomtidy","chapter":"9 Iteration & Functions","heading":"9.6.4 broom::tidy()","text":"can use function broom::tidy() extract data statistical test table format. example pipes everything together.pipeline , t.test(score~group, data = .) uses . notation change location piped-data table default position first argument different position.Finally, can extract single value results table using pull().","code":"\ntibble(\n  A = rnorm(20, 5, 1),\n  B = rnorm(20, 5.5, 1)\n) %>%\n  gather(group, score, A:B) %>%\n  t.test(score~group, data = .) %>%\n  broom::tidy()\ntibble(\n  A = rnorm(20, 5, 1),\n  B = rnorm(20, 5.5, 1)\n) %>%\n  gather(group, score, A:B) %>%\n  t.test(score~group, data = .) %>%\n  broom::tidy() %>%\n  pull(p.value)## [1] 0.7075268"},{"path":"func.html","id":"custom-function-t_sim","chapter":"9 Iteration & Functions","heading":"9.6.5 Custom function: t_sim()","text":"First, name function t_sim wrap code function arguments.Run times see happens.","code":"\nt_sim <- function() {\n  tibble(\n    A = rnorm(20, 5, 1),\n    B = rnorm(20, 5.5, 1)\n  ) %>%\n    gather(group, score, A:B) %>%\n    t.test(score~group, data = .) %>%\n    broom::tidy() %>%\n    pull(p.value) \n}\nt_sim()## [1] 0.00997552"},{"path":"func.html","id":"iterate-t_sim","chapter":"9 Iteration & Functions","heading":"9.6.6 Iterate t_sim()","text":"run t_sim function 1000 times, assign resulting p-values vector called reps, check proportion p-values lower alpha (e.g., .05). number power analysis.","code":"\nreps <- replicate(1000, t_sim())\nalpha <- .05\npower <- mean(reps < alpha)\npower## [1] 0.328"},{"path":"func.html","id":"seed","chapter":"9 Iteration & Functions","heading":"9.6.7 Set seed","text":"can use set.seed function run function uses random numbers make sure get random data back time. can use integer like seed.Make sure ever use set.seed() inside simulation function, just simulate exact data .\nFigure 9.2: @KellyBodwin\n","code":"\nset.seed(90201)"},{"path":"func.html","id":"add-arguments","chapter":"9 Iteration & Functions","heading":"9.6.8 Add arguments","text":"can just edit function time want cacluate power different sample n, efficent build fuction arguments. Redefine t_sim, setting arguments mean SD group , mean SD group B, number subjects per group. Give default values.Test function different values see results make sense.Use replicate calculate power 100 subjects/group effect size 0.2 (e.g., : m = 0, SD = 1; B: m = 0.2, SD = 1). Use 1000 replications.Compare power calculated power.t.test function.Calculate power via simulation power.t.test following tests:20 subjects/group, : m = 0, SD = 1; B: m = 0.2, SD = 140 subjects/group, : m = 0, SD = 1; B: m = 0.2, SD = 120 subjects/group, : m = 10, SD = 1; B: m = 12, SD = 1.5","code":"\nt_sim <- function(n = 10, m1=0, sd1=1, m2=0, sd2=1) {\n  tibble(\n    A = rnorm(n, m1, sd1),\n    B = rnorm(n, m2, sd2)\n  ) %>%\n    gather(group, score, A:B) %>%\n    t.test(score~group, data = .) %>%\n    broom::tidy() %>%\n    pull(p.value) \n}\nt_sim(100)\nt_sim(100, 0, 1, 0.5, 1)## [1] 0.5065619\n## [1] 0.001844064\nreps <- replicate(1000, t_sim(100, 0, 1, 0.2, 1))\npower <- mean(reps < .05)\npower## [1] 0.268\npower.t.test(n = 100, delta = 0.2, sd = 1, type=\"two.sample\")## \n##      Two-sample t test power calculation \n## \n##               n = 100\n##           delta = 0.2\n##              sd = 1\n##       sig.level = 0.05\n##           power = 0.2902664\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group"},{"path":"func.html","id":"glossary-func","chapter":"9 Iteration & Functions","heading":"9.7 Glossary","text":"","code":""},{"path":"func.html","id":"exercises-func","chapter":"9 Iteration & Functions","heading":"9.8 Exercises","text":"Download exercises. See answers attempted questions.","code":"\n# run this to access the exercise\nreprores::exercise(9)\n\n# run this to access the answers\nreprores::exercise(9, answers = TRUE)"},{"path":"sim.html","id":"sim","chapter":"10 Probability & Simulation","heading":"10 Probability & Simulation","text":"","code":""},{"path":"sim.html","id":"ilo-sim","chapter":"10 Probability & Simulation","heading":"10.1 Learning Objectives","text":"","code":""},{"path":"sim.html","id":"basic-6","chapter":"10 Probability & Simulation","heading":"10.1.1 Basic","text":"Generate plot data randomly sampled common distributions (video)\nuniform\nbinomial\nnormal\npoisson\nuniformbinomialnormalpoissonGenerate related variables multivariate distribution (video)Define following statistical terms:\np-value\nalpha\npower\nsmallest effect size interest (SESOI)\nfalse positive (type error)\nfalse negative (type II error)\nconfidence interval (CI)\np-valuealphapowersmallest effect size interest (SESOI)false positive (type error)false negative (type II error)confidence interval (CI)Test sampled distributions null hypothesis (video)\nexact binomial test\nt-test (1-sample, independent samples, paired samples)\ncorrelation (pearson, kendall spearman)\nexact binomial testt-test (1-sample, independent samples, paired samples)correlation (pearson, kendall spearman)Calculate power using iteration sampling function","code":""},{"path":"sim.html","id":"intermediate-5","chapter":"10 Probability & Simulation","heading":"10.1.2 Intermediate","text":"Calculate minimum sample size specific power level design","code":""},{"path":"sim.html","id":"resources8","chapter":"10 Probability & Simulation","heading":"10.2 Resources","text":"Distribution Shiny App (run reprores::app(\"simulate\")Simulation tutorialsChapter 21: Iteration R Data ScienceImproving statistical inferences Coursera (week 1)Faux package data simulationSimulation-Based Power-Analysis Factorial ANOVA Designs (Daniel Lakens Caldwell 2019)Understanding mixed effects models data simulation (DeBruine Barr 2019)","code":""},{"path":"sim.html","id":"setup8","chapter":"10 Probability & Simulation","heading":"10.3 Setup","text":"Simulating data powerful way test understanding statistical concepts. going use simulations learn basics probability.","code":"\n# libraries needed for these examples\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(faux)\n\nset.seed(8675309) # makes sure random numbers are reproducible"},{"path":"sim.html","id":"univariate-distributions","chapter":"10 Probability & Simulation","heading":"10.4 Univariate Distributions","text":"First, need understand different ways data might distributed simulate data distributions. univariate distribution distribution single variable.","code":""},{"path":"sim.html","id":"uniform","chapter":"10 Probability & Simulation","heading":"10.4.1 Uniform Distribution","text":"uniform distribution simplest distribution. numbers range equal probability sampled.Take minute think things research uniformly distributed.","code":""},{"path":"sim.html","id":"continuous-distribution","chapter":"10 Probability & Simulation","heading":"10.4.1.1 Continuous distribution","text":"runif(n, min=0, max=1)Use runif() sample continuous uniform distribution.","code":"\nu <- runif(100000, min = 0, max = 1)\n\n# plot to visualise\nggplot() + \n  geom_histogram(aes(u), binwidth = 0.05, boundary = 0,\n                 fill = \"white\", colour = \"black\")"},{"path":"sim.html","id":"discrete","chapter":"10 Probability & Simulation","heading":"10.4.1.2 Discrete","text":"sample(x, size, replace = FALSE, prob = NULL)Use sample() sample discrete distribution.can use sample() simulate events like rolling dice choosing deck cards. code simulates rolling 6-sided die 10000 times. set replace TRUE event independent. See happens set replace FALSE.\nFigure 10.1: Distribution dice rolls.\ncan also use sample sample list named outcomes.Ferrets much less common pet cats dogs, sample realistic. can set probabilities item list prob argument.","code":"\nrolls <- sample(1:6, 10000, replace = TRUE)\n\n# plot the results\nggplot() + \n  geom_histogram(aes(rolls), binwidth = 1, \n                 fill = \"white\", color = \"black\")\npet_types <- c(\"cat\", \"dog\", \"ferret\", \"bird\", \"fish\")\nsample(pet_types, 10, replace = TRUE)##  [1] \"cat\"    \"cat\"    \"cat\"    \"cat\"    \"ferret\" \"dog\"    \"bird\"   \"cat\"   \n##  [9] \"dog\"    \"fish\"\npet_types <- c(\"cat\", \"dog\", \"ferret\", \"bird\", \"fish\")\npet_prob <- c(0.3, 0.4, 0.1, 0.1, 0.1)\nsample(pet_types, 10, replace = TRUE, prob = pet_prob)##  [1] \"fish\" \"dog\"  \"cat\"  \"dog\"  \"cat\"  \"dog\"  \"fish\" \"dog\"  \"cat\"  \"fish\""},{"path":"sim.html","id":"binomial","chapter":"10 Probability & Simulation","heading":"10.4.2 Binomial Distribution","text":"binomial distribution useful modelling binary data, observation can one two outcomes, like success/failure, yes/head/tails.rbinom(n, size, prob)rbinom function generate random binomial distribution.n = number observationssize = number trialsprob = probability success trialCoin flips typical example binomial distribution, can assign heads 1 tails 0.can generate total number heads 1 set 20 coin flips setting size 20 n 1.can generate sets 20 coin flips increasing n.always check randomly generated data check makes sense. large samples, easiest graphically. histogram usually best choice plotting binomial data.Run simulation several times, noting histogram changes. Try changing values n, size, prob.","code":"\n# 20 individual coin flips of a fair coin\nrbinom(20, 1, 0.5)##  [1] 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 0 1 0 0 0\n# 20 individual coin flips of a baised (0.75) coin\nrbinom(20, 1, 0.75)##  [1] 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1\nrbinom(1, 20, 0.75)## [1] 13\nrbinom(10, 20, 0.5)##  [1] 10 14 11  7 11 13  6 10  9  9\nflips <- rbinom(1000, 20, 0.5)\n\nggplot() +\n  geom_histogram(\n    aes(flips), \n    binwidth = 1, \n    fill = \"white\", \n    color = \"black\"\n  )"},{"path":"sim.html","id":"normal","chapter":"10 Probability & Simulation","heading":"10.4.3 Normal Distribution","text":"rnorm(n, mean, sd)can simulate normal distribution size n know mean standard deviation (sd). density plot usually best way visualise type data n large.Run simulation several times, noting density plot changes. vertical lines represent? Try changing values n, mean, sd.","code":"\ndv <- rnorm(1e5, 10, 2)\n\n# proportions of normally-distributed data \n# within 1, 2, or 3 SD of the mean\nsd1 <- .6827 \nsd2 <- .9545\nsd3 <- .9973\n\nggplot() +\n  geom_density(aes(dv), fill = \"white\") +\n  geom_vline(xintercept = mean(dv), color = \"red\") +\n  geom_vline(xintercept = quantile(dv, .5 - sd1/2), color = \"darkgreen\") +\n  geom_vline(xintercept = quantile(dv, .5 + sd1/2), color = \"darkgreen\") +\n  geom_vline(xintercept = quantile(dv, .5 - sd2/2), color = \"blue\") +\n  geom_vline(xintercept = quantile(dv, .5 + sd2/2), color = \"blue\") +\n  geom_vline(xintercept = quantile(dv, .5 - sd3/2), color = \"purple\") +\n  geom_vline(xintercept = quantile(dv, .5 + sd3/2), color = \"purple\") +\n  scale_x_continuous(\n    limits = c(0,20), \n    breaks = seq(0,20)\n  )"},{"path":"sim.html","id":"poisson","chapter":"10 Probability & Simulation","heading":"10.4.4 Poisson Distribution","text":"Poisson distribution useful modelling events, like many times something happens unit time, long events independent (e.g., event happened one time period make less likely happen next).rpois(n, lambda)rpois function generate random Poisson distribution.n = number observationslambda = mean number events per observationLet's say want model many texts get day whole. know get average 20 texts per day. set n = 365 lambda = 20. Lambda parameter describes Poisson distribution, just like mean standard deviation parameters describe normal distribution.can see year, unlikely get fewer 5 texts day, 35 (although impossible).","code":"\ntexts <- rpois(n = 365, lambda = 20)\n\nggplot() +\n  geom_histogram(\n    aes(texts), \n    binwidth = 1, \n    fill = \"white\", \n    color = \"black\"\n  )"},{"path":"sim.html","id":"mvdist","chapter":"10 Probability & Simulation","heading":"10.5 Multivariate Distributions","text":"","code":""},{"path":"sim.html","id":"bvn","chapter":"10 Probability & Simulation","heading":"10.5.1 Bivariate Normal","text":"bivariate normal distribution two normally distributed vectors specified relationship, correlation .want sample population specific relationships variables? can sample bivariate normal distribution using mvrnorm() MASS package.load MASS library() function create conflict select() function dplyr always need preface dplyr::. Just use MASS::mvrnorm().need know many observations want simulate (n) means two variables (mu) need calculate covariance matrix (sigma) correlation variables (rho) standard deviations (sd).Plot sampled variables check everything worked like expect. easiest convert output mvnorm tibble order use ggplot.","code":"\nn   <- 1000 # number of random samples\n# name the mu values to give the resulting columns names\nmu     <- c(x = 10, y = 20) # the means of the samples\nsd <- c(5, 6)   # the SDs of the samples\n\nrho <- 0.5  # population correlation between the two variables\n\n# correlation matrix\ncor_mat <- matrix(c(  1, rho, \n                    rho,   1), 2) \n\n# create the covariance matrix\nsigma <- (sd %*% t(sd)) * cor_mat\n\n# sample from bivariate normal distribution\nbvn <- MASS::mvrnorm(n, mu, sigma) \nbvn %>%\n  as_tibble() %>%\n  ggplot(aes(x, y)) +\n    geom_point(alpha = 0.5) + \n    geom_smooth(method = \"lm\") +\n    geom_density2d()## `geom_smooth()` using formula 'y ~ x'"},{"path":"sim.html","id":"mvnorm","chapter":"10 Probability & Simulation","heading":"10.5.2 Multivariate Normal","text":"can generate 2 correlated variables, gets little trickier create correlation matrix.can use plotly library make 3D graph.","code":"\nn      <- 200 # number of random samples\nmu     <- c(x = 10, y = 20, z = 30) # the means of the samples\nsd <- c(8, 9, 10)   # the SDs of the samples\n\nrho1_2 <- 0.5 # correlation between x and y\nrho1_3 <- 0   # correlation between x and z\nrho2_3 <- 0.7 # correlation between y and z\n\n# correlation matrix\ncor_mat <- matrix(c(     1, rho1_2, rho1_3, \n                    rho1_2,      1, rho2_3,\n                    rho1_3, rho2_3,      1), 3) \n\nsigma <- (sd %*% t(sd)) * cor_mat\nbvn3 <- MASS::mvrnorm(n, mu, sigma)\n\ncor(bvn3) # check correlation matrix##           x         y         z\n## x 1.0000000 0.5896674 0.1513108\n## y 0.5896674 1.0000000 0.7468737\n## z 0.1513108 0.7468737 1.0000000\n#set up the marker style\nmarker_style = list(\n    color = \"#ff0000\", \n    line = list(\n      color = \"#444\", \n      width = 1\n    ), \n    opacity = 0.5,\n    size = 5\n  )\n\n# convert bvn3 to a tibble, plot and add markers\nbvn3 %>%\n  as_tibble() %>%\n  plot_ly(x = ~x, y = ~y, z = ~z, marker = marker_style) %>%\n  add_markers()"},{"path":"sim.html","id":"faux","chapter":"10 Probability & Simulation","heading":"10.5.3 Faux","text":"Alternatively, can use package faux generate number correlated variables. also function checking parameters new simulated data (check_sim_stats()).can also use faux simulate data factorial designs. Set -subject within-subject factors lists levels (named) vectors. Means standard deviations can included vectors data frames. function calculates sigma , structures dataset, outputs plot design.can use check_sim_stats() function, need set argument vector -subject factor columns.See faux website detailed tutorials.","code":"\nbvn3 <- rnorm_multi(\n  n = n, \n  vars = 3,\n  mu = mu, \n  sd = sd,\n  r = c(rho1_2, rho1_3, rho2_3),\n  varnames = c(\"x\", \"y\", \"z\")\n)\n\ncheck_sim_stats(bvn3)\nb <- list(pet = c(cat = \"Cat Owners\",\n                  dog = \"Dog Owners\"))\nw <- list(time = c(\"morning\",\n                   \"noon\",\n                   \"night\"))\nmu <- data.frame(\n  cat    = c(10, 12, 14),\n  dog    = c(10, 15, 20),\n  row.names = w$time\n)\nsd <- c(3, 3, 3, 5, 5, 5)\n\npet_data <- sim_design(\n  within = w, \n  between = b,\n  n = 100, \n  mu = mu,\n  sd = sd, \n  r = .5)\ncheck_sim_stats(pet_data, between = \"pet\")"},{"path":"sim.html","id":"stat-terms","chapter":"10 Probability & Simulation","heading":"10.6 Statistical terms","text":"review important statistical terms review tests distributions.","code":""},{"path":"sim.html","id":"effect","chapter":"10 Probability & Simulation","heading":"10.6.1 Effect","text":"effect measure data. depend type data type statistical test using. example, flipped coin 100 times landed heads 66 times, effect 66/100. can use exact binomial test compare effect null effect expect fair coin (50/100) effect choose. effect size refers difference effect data null effect (usually chance value).","code":""},{"path":"sim.html","id":"p-value","chapter":"10 Probability & Simulation","heading":"10.6.2 P-value","text":"p-value test probability seeing effect least extreme , real effect value testing (e.g., null effect). used binomial test test chance probability 1/6 (e.g., probability rolling 1 6-sided die), p-value 0.17 means expect see effects least extreme data 17% time just chance alone.","code":""},{"path":"sim.html","id":"alpha","chapter":"10 Probability & Simulation","heading":"10.6.3 Alpha","text":"using null hypothesis significance testing (NHST), need decide cutoff value (alpha) making decision reject null hypothesis. call p-values alpha cutoff significant. psychology, alpha traditionally set 0.05, good arguments setting different criterion circumstances.","code":""},{"path":"sim.html","id":"false-pos","chapter":"10 Probability & Simulation","heading":"10.6.4 False Positive/Negative","text":"probability test concludes effect really effect (e.g., concludes fair coin biased) called false positive rate (Type Error Rate). alpha false positive rate accept test. probability test concludes effect really one (e.g., concludes biased coin fair) called false negative rate (Type II Error Rate). beta false negative rate accept test.false positive rate overall probability getting false positive, probability false positive null hypothesis. Similarly, false negative rate probability false negative alternative hypothesis. Unless know probability testing null effect, say anything overall probability false positives negatives. 100% hypotheses test false, significant effects false positives, hypotheses test true, positives true positives overall false positive rate 0.","code":""},{"path":"sim.html","id":"power","chapter":"10 Probability & Simulation","heading":"10.6.5 Power and SESOI","text":"Power equal 1 minus beta (.e., true positive rate), depends effect size, many samples take (n), set alpha . test, specify one values, can calculate last. effect size use power calculations smallest effect size interest (SESOI). See (Daniël Lakens, Scheel, Isager 2018)(https://doi.org/10.1177/2515245918770963) tutorial methods choosing SESOI.say want able detect least 15% difference chance (50%) coin's fairness, want test 5% chance false positives 10% chance false negatives. following values?alpha = beta = false positive rate = false negative rate = power = SESOI = ","code":""},{"path":"sim.html","id":"conf-int","chapter":"10 Probability & Simulation","heading":"10.6.6 Confidence Intervals","text":"confidence interval range around value (mean) probability containing parameter, repeated process many times. Traditionally psychology, use 95% confidence intervals, can calculate CIs percentage.95% CI mean 95% probability true mean lies within range, , repeated study many times calculated CI way every time, expect true mean inside CI 95% studies. seems like subtle distinction, can lead misunderstandings. See (Morey et al. 2016)(https://link.springer.com/article/10.3758/s13423-015-0947-8) detailed discussion.","code":""},{"path":"sim.html","id":"tests","chapter":"10 Probability & Simulation","heading":"10.7 Tests","text":"","code":""},{"path":"sim.html","id":"exact-binom","chapter":"10 Probability & Simulation","heading":"10.7.1 Exact binomial test","text":"binom.test(x, n, p)can test binomial distribution specific probability using exact binomial test.x = number successesn = number trialsp = hypothesised probability successHere can test series 10 coin flips fair coin biased coin hypothesised probability 0.5 (even odds).Run code several times, noting p-values fair biased coins. Alternatively, can simulate coin flips online build graph results p-values.p-value vary fair biased coins?happens confidence intervals increase n 10 100?criterion use tell observed data indicate coin fair biased?often conclude fair coin biased (false positives)?often conclude biased coin fair (false negatives)?","code":"\nn <- 10\nfair_coin <- rbinom(1, n, 0.5)\nbiased_coin <- rbinom(1, n, 0.6)\n\nbinom.test(fair_coin, n, p = 0.5)\nbinom.test(biased_coin, n, p = 0.5)## \n##  Exact binomial test\n## \n## data:  fair_coin and n\n## number of successes = 6, number of trials = 10, p-value = 0.7539\n## alternative hypothesis: true probability of success is not equal to 0.5\n## 95 percent confidence interval:\n##  0.2623781 0.8784477\n## sample estimates:\n## probability of success \n##                    0.6 \n## \n## \n##  Exact binomial test\n## \n## data:  biased_coin and n\n## number of successes = 8, number of trials = 10, p-value = 0.1094\n## alternative hypothesis: true probability of success is not equal to 0.5\n## 95 percent confidence interval:\n##  0.4439045 0.9747893\n## sample estimates:\n## probability of success \n##                    0.8"},{"path":"sim.html","id":"sampling-binom","chapter":"10 Probability & Simulation","heading":"10.7.1.1 Sampling function","text":"estimate rates, need repeat sampling many times. function ideal repeating exact procedure . Set arguments function variables might want change. , want estimate power :different sample sizes (n)different effects (bias)different hypothesised probabilities (p, defaults 0.5)created function, test times, changing values.","code":"\nsim_binom_test <- function(n, bias, p = 0.5) {\n  # simulate 1 coin flip n times with the specified bias\n  coin <- rbinom(1, n, bias)\n  # run a binomial test on the simulated data for the specified p\n  btest <- binom.test(coin, n, p)\n  # return the p-value of this test\n  btest$p.value\n}\nsim_binom_test(100, 0.6)## [1] 0.1332106"},{"path":"sim.html","id":"calc-power-binom","chapter":"10 Probability & Simulation","heading":"10.7.1.2 Calculate power","text":"can use replicate() function run many times save output values. can calculate power analysis checking proportion simulated analyses p-value less alpha (probability rejecting null hypothesis null hypothesis true).1e4 just scientific notation 1 followed 4 zeros (10000). running simulations, usually want run lot . pain keep track whether typed 5 6 zeros (100000 vs 1000000) change running time order magnitude.can plot distribution p-values.","code":"\nmy_reps <- replicate(1e4, sim_binom_test(100, 0.6))\n\nalpha <- 0.05 # this does not always have to be 0.05\n\nmean(my_reps < alpha)## [1] 0.4561\nggplot() + \n  geom_histogram(\n    aes(my_reps), \n    binwidth = 0.05, \n    boundary = 0,\n    fill = \"white\", \n    color = \"black\"\n  )"},{"path":"sim.html","id":"t-test","chapter":"10 Probability & Simulation","heading":"10.7.2 T-test","text":"t.test(x, y, alternative, mu, paired)Use t-test compare mean one distribution null hypothesis (one-sample t-test), compare means two samples (independent-samples t-test), compare pairs values (paired-samples t-test).can run one-sample t-test comparing mean data mu. simulated distribution mean 0.5 SD 1, creating effect size 0.5 SD tested mu 0. Run simulation times see often t-test returns significant p-value (run shiny app).Run independent-samples t-test comparing two lists values.paired argument defaults FALSE, good practice always explicitly set never confused type test performing.","code":"\nsim_norm <- rnorm(100, 0.5, 1)\nt.test(sim_norm, mu = 0)## \n##  One Sample t-test\n## \n## data:  sim_norm\n## t = 6.2874, df = 99, p-value = 8.758e-09\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  0.4049912 0.7784761\n## sample estimates:\n## mean of x \n## 0.5917337\na <- rnorm(100, 0.5, 1)\nb <- rnorm(100, 0.7, 1)\nt_ind <- t.test(a, b, paired = FALSE)\nt_ind## \n##  Welch Two Sample t-test\n## \n## data:  a and b\n## t = -1.8061, df = 197.94, p-value = 0.07243\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -0.54825320  0.02408469\n## sample estimates:\n## mean of x mean of y \n## 0.4585985 0.7206828"},{"path":"sim.html","id":"sampling-t","chapter":"10 Probability & Simulation","heading":"10.7.2.1 Sampling function","text":"can use names() function find names t.test parameters use just get one type data, like test statistic (e.g., t-value).want run simulation many times record information time, first need turn simulation function.Run times check gives sensible values.","code":"\nnames(t_ind)\nt_ind$statistic##  [1] \"statistic\"   \"parameter\"   \"p.value\"     \"conf.int\"    \"estimate\"   \n##  [6] \"null.value\"  \"stderr\"      \"alternative\" \"method\"      \"data.name\"  \n##         t \n## -1.806051\nsim_t_ind <- function(n, m1, sd1, m2, sd2) {\n  # simulate v1\n  v1 <- rnorm(n, m1, sd1)\n  \n  #simulate v2\n  v2 <- rnorm(n, m2, sd2)\n    \n  # compare using an independent samples t-test\n  t_ind <- t.test(v1, v2, paired = FALSE)\n  \n  # return the p-value\n  return(t_ind$p.value)\n}\nsim_t_ind(100, 0.7, 1, 0.5, 1)## [1] 0.362521"},{"path":"sim.html","id":"calc-power-t","chapter":"10 Probability & Simulation","heading":"10.7.2.2 Calculate power","text":"Now replicate simulation 1000 times.Run code several times. much power value fluctuate? many replications need run get reliable estimate power?Compare power estimate simluation power calculation using power.t.test(). , delta difference m1 m2 .can plot distribution p-values.think distribution p-values \neffect (.e., means identical)? Check .Make sure boundary argument set 0 p-value histograms. See happens null effect boundary set.","code":"\nmy_reps <- replicate(1e4, sim_t_ind(100, 0.7, 1, 0.5, 1))\n\nalpha <- 0.05\npower <- mean(my_reps < alpha)\npower## [1] 0.2925\npower.t.test(n = 100, \n             delta = 0.2, \n             sd = 1, \n             sig.level = alpha, \n             type = \"two.sample\")## \n##      Two-sample t test power calculation \n## \n##               n = 100\n##           delta = 0.2\n##              sd = 1\n##       sig.level = 0.05\n##           power = 0.2902664\n##     alternative = two.sided\n## \n## NOTE: n is number in *each* group\nggplot() + \n  geom_histogram(\n    aes(my_reps), \n    binwidth = 0.05, \n    boundary = 0,\n    fill = \"white\", \n    color = \"black\"\n  )"},{"path":"sim.html","id":"correlation","chapter":"10 Probability & Simulation","heading":"10.7.3 Correlation","text":"can test continuous variables related using cor() function. use rnorm_multi() make quick table correlated values.Set n large number like 1e6 correlations less affected chance. Change value mean , x, y. change correlation x y? happens increase decrease sd? Can work rules ?cor() defaults Pearson's correlations. Set method argument use Kendall Spearman correlations.","code":"\ndat <- rnorm_multi(\n  n = 100, \n  vars = 2, \n  r = -0.5,\n  varnames = c(\"x\", \"y\")\n)\n\ncor(dat$x, dat$y)## [1] -0.4960331\ncor(dat$x, dat$y, method = \"spearman\")## [1] -0.4724992"},{"path":"sim.html","id":"sampling-cor","chapter":"10 Probability & Simulation","heading":"10.7.3.1 Sampling function","text":"Create function creates two variables n observations r correlation. Use function cor.test() give p-values correlation.created function, test times, changing values.","code":"\nsim_cor_test <- function(n = 100, r = 0) {\n  dat <- rnorm_multi(\n    n = n, \n    vars = 2, \n    r = r,\n    varnames = c(\"x\", \"y\")\n  )\n\n  ctest <- cor.test(dat$x, dat$y)\n  ctest$p.value\n}\nsim_cor_test(50, .5)## [1] 0.001354836"},{"path":"sim.html","id":"calc-power-cor","chapter":"10 Probability & Simulation","heading":"10.7.3.2 Calculate power","text":"Now replicate simulation 1000 times.Compare value calcuated pwr package.","code":"\nmy_reps <- replicate(1e4, sim_cor_test(50, 0.5))\n\nalpha <- 0.05\npower <- mean(my_reps < alpha)\npower## [1] 0.965\npwr::pwr.r.test(n = 50, r = 0.5)## \n##      approximate correlation power calculation (arctangh transformation) \n## \n##               n = 50\n##               r = 0.5\n##       sig.level = 0.05\n##           power = 0.9669813\n##     alternative = two.sided"},{"path":"sim.html","id":"example","chapter":"10 Probability & Simulation","heading":"10.8 Example","text":"example uses Growth Chart Data Tables US CDC. data consist height centimeters z-scores –2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2 sex (1=male; 2=female) half-month age (24.0 240.5 months).","code":""},{"path":"sim.html","id":"load-wrangle","chapter":"10 Probability & Simulation","heading":"10.8.1 Load & wrangle","text":"little data wrangling first. look data import relabel Sex male female instead 1 2. Also convert Agemos (age months) years. Relabel column 0 mean calculate new column named sd difference columns 1 0.","code":"\norig_height_age <- read_csv(\"https://www.cdc.gov/growthcharts/data/zscore/zstatage.csv\") ## \n## ── Column specification ────────────────────────────────────────────────────────\n## cols(\n##   Sex = col_character(),\n##   Agemos = col_character(),\n##   `-2` = col_double(),\n##   `-1.5` = col_double(),\n##   `-1` = col_double(),\n##   `-0.5` = col_double(),\n##   `0` = col_double(),\n##   `0.5` = col_double(),\n##   `1` = col_double(),\n##   `1.5` = col_double(),\n##   `2` = col_double()\n## )\nheight_age <- orig_height_age %>%\n  filter(Sex %in% c(1,2)) %>%\n  mutate(\n    sex = recode(Sex, \"1\" = \"male\", \"2\" = \"female\"),\n    age = as.numeric(Agemos)/12,\n    sd = `1` - `0`\n  ) %>%\n  select(sex, age, mean = `0`, sd)"},{"path":"sim.html","id":"plot","chapter":"10 Probability & Simulation","heading":"10.8.2 Plot","text":"Plot new data frame see mean height changes age boys girls.","code":"\nggplot(height_age, aes(age, mean, color = sex)) +\n  geom_smooth(aes(ymin = mean - sd, \n                  ymax = mean + sd),\n              stat=\"identity\")"},{"path":"sim.html","id":"simulate-a-population","chapter":"10 Probability & Simulation","heading":"10.8.3 Simulate a population","text":"Simulate 50 random male heights 50 random female heights 20-year-olds using rnorm() function means SDs height_age table. Plot data.Run simulation several times, noting density plot changes. Try changing age simulating.","code":"\nage_filter <- 20\nm <- filter(height_age, age == age_filter, sex == \"male\")\nf <- filter(height_age, age == age_filter, sex == \"female\")\n\nsim_height <- tibble(\n  male = rnorm(50, m$mean, m$sd),\n  female = rnorm(50, f$mean, f$sd)\n) %>%\n  gather(\"sex\", \"height\", male:female)\n\nggplot(sim_height) +\n  geom_density(aes(height, fill = sex), alpha = 0.5) +\n  xlim(125, 225)"},{"path":"sim.html","id":"analyse-simulated-data","chapter":"10 Probability & Simulation","heading":"10.8.4 Analyse simulated data","text":"Use sim_t_ind(n, m1, sd1, m2, sd2) function created generate one simulation sample size 50 group using means SDs male female 14-year-olds.","code":"\nage_filter <- 14\nm <- filter(height_age, age == age_filter, sex == \"male\")\nf <- filter(height_age, age == age_filter, sex == \"female\")\n\nsim_t_ind(50, m$mean, m$sd, f$mean, f$sd)## [1] 0.0005255744"},{"path":"sim.html","id":"replicate-simulation","chapter":"10 Probability & Simulation","heading":"10.8.5 Replicate simulation","text":"Now replicate 1e4 times using replicate() function. function save returned p-values list (my_reps). can check proportion p-values less alpha value. power test.","code":"\nmy_reps <- replicate(1e4, sim_t_ind(50, m$mean, m$sd, f$mean, f$sd))\n\nalpha <- 0.05\npower <- mean(my_reps < alpha)\npower## [1] 0.6403"},{"path":"sim.html","id":"one-tailed-prediction","chapter":"10 Probability & Simulation","heading":"10.8.6 One-tailed prediction","text":"design 65% power detect sex difference height (2-tailed test). Modify sim_t_ind function 1-tailed prediction.just set alternative equal \"greater\" function, might better add alt argument function (giving default value t.test) change value alternative function alt.","code":"\nsim_t_ind <- function(n, m1, sd1, m2, sd2, alt = \"two.sided\") {\n  v1 <- rnorm(n, m1, sd1)\n  v2 <- rnorm(n, m2, sd2)\n  t_ind <- t.test(v1, v2, paired = FALSE, alternative = alt)\n  \n  return(t_ind$p.value)\n}\n\nalpha <- 0.05\nmy_reps <- replicate(1e4, sim_t_ind(50, m$mean, m$sd, f$mean, f$sd, \"greater\"))\nmean(my_reps < alpha)## [1] 0.752"},{"path":"sim.html","id":"range-of-sample-sizes","chapter":"10 Probability & Simulation","heading":"10.8.7 Range of sample sizes","text":"want find sample size give us 80% power? can try trial error. know number slightly larger 50. can search systematically repeating power calculation range sample sizes.might seem like overkill t-test, can easily look sample size calculators online, valuable skill learn analyses become complicated.Start relatively low number replications /spread-samples estimate looking specifically. can repeat narrower/denser range sample sizes iterations.Now can narrow search values around 55 (plus minus 5) increase number replications 1e3 1e4.","code":"\n# make another custom function to return power\npwr_func <- function(n, reps = 100, alpha = 0.05) {\n  ps <- replicate(reps, sim_t_ind(n, m$mean, m$sd, f$mean, f$sd, \"greater\"))\n  mean(ps < alpha)\n}\n\n# make a table of the n values you want to check\npower_table <- tibble(\n  n = seq(20, 100, by = 5)\n) %>%\n  # run the power function for each n\n  mutate(power = map_dbl(n, pwr_func))\n\n# plot the results\nggplot(power_table, aes(n, power)) +\n  geom_smooth() +\n  geom_point() +\n  geom_hline(yintercept = 0.8)## `geom_smooth()` using method = 'loess' and formula 'y ~ x'\npower_table <- tibble(\n  n = seq(50, 60)\n) %>%\n  mutate(power = map_dbl(n, pwr_func, reps = 1e4))\n\nggplot(power_table, aes(n, power)) +\n geom_smooth() +\n geom_point() +\n geom_hline(yintercept = 0.8)## `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"sim.html","id":"glossary-sim","chapter":"10 Probability & Simulation","heading":"10.9 Glossary","text":"","code":""},{"path":"sim.html","id":"exercises-sim","chapter":"10 Probability & Simulation","heading":"10.10 Exercises","text":"Download exercises. See answers attempted questions.","code":"\n# run this to access the exercise\nreprores::exercise(10)\n\n# run this to access the answers\nreprores::exercise(10, answers = TRUE)"},{"path":"acknowledgements.html","id":"acknowledgements","chapter":"Acknowledgements","heading":"Acknowledgements","text":"whole psyTeachR team University Glasgow School Psychology deserves enormous thanks making possible rewarding teach methods focus reproducibility open science. Particularly\nHeather Cleland Woods,\nPhil McAleer,\nHelena Paterson,\nEmily Nordmann,\nCarolina Keuper-Tetzel, \nNiamh Stack.greatly appreciate Iris Holzleitner's volunteer -class assistance first year course. ever lucky get Rebecca Lai teaching assistant second year; kind patient approach teaching technical skills inspiration. Benedict Jones made invaluable contributions ethos reproducible research Glasgow. Thanks Daniël Lakens many inspirational discussions resources.","code":""},{"path":"acknowledgements.html","id":"contributors","chapter":"Acknowledgements","heading":"10.11 Contributors","text":"Several people contributed testing materials.Rebecca LaiRichard MoreyMossa Merhi Reimert","code":""},{"path":"installingr.html","id":"installingr","chapter":"A Installing R","heading":"A Installing R","text":"Installing R RStudio usually straightforward. sections explain helpful YouTube video .","code":""},{"path":"installingr.html","id":"installing-base-r","chapter":"A Installing R","heading":"A.1 Installing Base R","text":"Install base R https://cran.rstudio.com/. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). install R, also install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page. install R, also install RTools; use \"recommended\" version highlighted near top list.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"installingr.html","id":"installing-rstudio","chapter":"A Installing R","heading":"A.2 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"installingr.html","id":"installing-latex","chapter":"A Installing R","heading":"A.3 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. generate PDF reports, additionally need:pandoc, andLaTeX, typesetting language, available \nWINDOWS: MikTeX\nMac OS: MacTex (3.2GB download) BasicTeX (78MB download, work fine)\nLinux: TeX Live\nWINDOWS: MikTeXMac OS: MacTex (3.2GB download) BasicTeX (78MB download, work fine)Linux: TeX Live","code":""},{"path":"installingr.html","id":"rstudio-online","chapter":"A Installing R","heading":"A.4 RStudio Online","text":"may need access R RStudio online use tablet chromebook install R.Students Institute Neuroscience Psychology University Glasgow can access Glasgow Psychology RStudio GUID password.RStudio Cloud free online service allows access R RStudio.","code":""},{"path":"symbols.html","id":"symbols","chapter":"B Symbols","heading":"B Symbols","text":"","code":""},{"path":"exercise-answers.html","id":"exercise-answers","chapter":"C Exercise Answers","heading":"C Exercise Answers","text":"Download exercises data files ZIP archive. answers included zip file.01 intro (answers): Intro R, functions, R markdown02 ggplot (answers): Data visualisation03 data (answers): Vectors, tabular data, data import, pipes04 tidyr (answers): Tidy Data05 dplyr (answers): Data wrangling06 joins (answers): Data relations07 glm (answers): GLM08 functions (answers): Functions iteration09 simulation (answers): Simulation","code":""},{"path":"datasets.html","id":"datasets","chapter":"D Datasets","heading":"D Datasets","text":"can download zip file datasets access class package getdata(). help files data table describe data column. data table comes codebook Psych-DS format.Country Codes Multiple country, subregion, region codes 249 countries.Three Domain Disgust Questionnaire (correlations) Correlations among questions Three Domain Disgust Questionnaire (Tybur et al.)Three Domain Disgust Questionnaire (scores) dataset containing subscale scores Three Domain Disgust Questionnaire (Tybur et al.), calculated [disgust].Three Domain Disgust Questionnaire (items) dataset containing responses 21 items Three Domain Disgust Questionnaire (Tybur et al.)Parental Attachment (Mothers) Items starting r, p e rejection (r), overprotection (p), emotional warmth (e) subscales.Empathizing Quotient Reverse coded (Q#R) questions coded strongly disagree = 2, slightly disagree = 1, else = 0. questions coded strongly agree = 2, slightly agree = 1, else = 0.Experimentum Project Experiment Data demo experiment Experimentum https://debruine.github.io/experimentum/. Subjects shown pairs upright inverted Mooney faces asked click upright face.Experimentum Project Questionnaires Data demo questionnaire Experimentum https://debruine.github.io/experimentum/. Subjects asked questions dogs test different questionnaire response types. Questions * current: dog? (yes/) * past: ever owned dog? (yes/) * name: best name dog? (free short text) * good: good dogs? (1=pretty good:7=good) * country: country borzois come ? * good_borzoi: good borzois? (0=pretty good:100=good) * text: Write text dogs. (free long text) * time: time ? (time)Descriptions Eyes Participant's written descriptions eyes 50 peopleFamily Composition Responses brief questionnaire family composition.Infant Mortality Infant mortality country year World Health Organisation.Maternal Mortality Maternal mortality country year World Health Organisation.Messy Data dataset missing values, blank rows, incorrect data types, multiple values one column, multiple date types practicing data import.5-Factor Personality Scores Archival data Face Research Lab 5-factor personality questionnaire, factor score calculated [personality].5-Factor Personality Items Archival data Face Research Lab 5-factor personality questionnaire. question labelled domain (Op = openness, Co = conscientiousness, Ex = extroversion, Ag = agreeableness, Ne = neuroticism) question number. Participants rate statement Likert scale 0 (Never) 6 (Always). Questions REV already reverse-coded (0 = Always, 6 = Never).Pets simulated dataset one random factor (id), two categorical factors (pet, country) three continuous variables (score, age, weight). dataset useful practicing plotting.First Impressions Faces (Aggregated) Aggregated data Psychological Science Accelerator project: World Regions Valence-Dominance Model Social Perception Apply? https://psyarxiv.com/n26dy. Mean ratings 13 traits 120 faces shown 10 world regions. Face characteristics [psa001_cfd_faces].Face Characteristics Face stimulus characteristics Psychological Science Accelerator project: World Regions Valence-Dominance Model Social Perception Apply? https://psyarxiv.com/n26dy. used [psa001_agg].Sensation Seeking Scale Zuckerman M. (1984). Sensation seeking: comparative approach human trait. Behavioral Brain Sciences. 7: 413-471.Small Factorial Design: 2w*2b Small simulated dataset (n = 5) one within-subject factor (time) 2 levels (pre post) one beteen-subject factor (group) two levels (control experimental). dataset wide format created faux.Systemizing Quotient Reverse coded (Q#R) questions coded strongly disagree = 2, slightly disagree = 1, else = 0. questions coded strongly agree = 2, slightly agree = 1, else = 0.\nc(\"* Stroop Task 50 simulated subject stroop task viewing combinations word ink colours blue, purple, green, red, brown, 5 times . Subjects respond ink colour. Subjects respond time NA response rt.\", \"* Stroop Task 50 simulated subject stroop task viewing combinations word ink colours blue, purple, green, red, brown, 5 times . Subjects respond ink colour. Subjects respond time NA response rt.\"\n)User Demographics dataset unique participant ID, sex birth year. used conjunction data [disgust], [disgust_scores], [personality], [personality_scores], [users2].User Demographics 2 dataset unique participant ID, birth year, sex. used conjunction data [disgust], [disgust_scores], [personality], [personality_scores], [users].","code":""},{"path":"bookrefs.html","id":"bookrefs","chapter":"E References","heading":"E References","text":"","code":""}]
